--- file: target/debug/build/mime_guess-1426f7b4882ecb31/out/mime_types_generated.rs ---
```rust
```

--- file: target/debug/build/mime_guess-e32f666e986c3aca/out/mime_types_generated.rs ---
```rust
```

--- file: target/debug/build/serde-f38b255d54569d39/out/private.rs ---
```rust
#[doc(hidden)]
pub mod __private228 {
    #[doc(hidden)]
    pub use crate::private::*;
}
use serde_core::__private228 as serde_core_private;
```

--- file: target/debug/build/serde_core-730b54bd8aa491de/out/private.rs ---
```rust
#[doc(hidden)]
pub mod __private228 {
    #[doc(hidden)]
    pub use crate::private::*;
}
```

--- file: target/debug/build/serde_core-b7eb3f0aad7f0e0d/out/private.rs ---
```rust
#[doc(hidden)]
pub mod __private228 {
    #[doc(hidden)]
    pub use crate::private::*;
}
```

--- file: target/debug/build/serde_core-dea4fecf3d308a7b/out/private.rs ---
```rust
#[doc(hidden)]
pub mod __private228 {
    #[doc(hidden)]
    pub use crate::private::*;
}
```

--- file: target/debug/build/thiserror-8d9485f38595e92d/out/private.rs ---
```rust
#[doc(hidden)]
pub mod __private17 {
    #[doc(hidden)]
    pub use crate::private::*;
}
```

--- file: target/debug/build/typenum-f68f558ad7616dfe/out/tests.rs ---
```rust

use typenum::*;
use core::ops::*;
use core::cmp::Ordering;

#[test]
#[allow(non_snake_case)]
fn test_0_BitAnd_0() {
    type A = UTerm;
    type B = UTerm;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0BitAndU0 = <<A as BitAnd<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0BitAndU0 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_BitOr_0() {
    type A = UTerm;
    type B = UTerm;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0BitOrU0 = <<A as BitOr<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0BitOrU0 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_BitXor_0() {
    type A = UTerm;
    type B = UTerm;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0BitXorU0 = <<A as BitXor<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0BitXorU0 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Shl_0() {
    type A = UTerm;
    type B = UTerm;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0ShlU0 = <<A as Shl<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0ShlU0 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Shr_0() {
    type A = UTerm;
    type B = UTerm;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0ShrU0 = <<A as Shr<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0ShrU0 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Add_0() {
    type A = UTerm;
    type B = UTerm;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0AddU0 = <<A as Add<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0AddU0 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Mul_0() {
    type A = UTerm;
    type B = UTerm;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0MulU0 = <<A as Mul<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0MulU0 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Pow_0() {
    type A = UTerm;
    type B = UTerm;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U0PowU0 = <<A as Pow<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U0PowU0 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Min_0() {
    type A = UTerm;
    type B = UTerm;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0MinU0 = <<A as Min<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0MinU0 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Max_0() {
    type A = UTerm;
    type B = UTerm;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0MaxU0 = <<A as Max<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0MaxU0 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Gcd_0() {
    type A = UTerm;
    type B = UTerm;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0GcdU0 = <<A as Gcd<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0GcdU0 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Sub_0() {
    type A = UTerm;
    type B = UTerm;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0SubU0 = <<A as Sub<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0SubU0 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Cmp_0() {
    type A = UTerm;
    type B = UTerm;

    #[allow(non_camel_case_types)]
    type U0CmpU0 = <A as Cmp<B>>::Output;
    assert_eq!(<U0CmpU0 as Ord>::to_ordering(), Ordering::Equal);
}
#[test]
#[allow(non_snake_case)]
fn test_0_BitAnd_1() {
    type A = UTerm;
    type B = UInt<UTerm, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0BitAndU1 = <<A as BitAnd<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0BitAndU1 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_BitOr_1() {
    type A = UTerm;
    type B = UInt<UTerm, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U0BitOrU1 = <<A as BitOr<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U0BitOrU1 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_BitXor_1() {
    type A = UTerm;
    type B = UInt<UTerm, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U0BitXorU1 = <<A as BitXor<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U0BitXorU1 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Shl_1() {
    type A = UTerm;
    type B = UInt<UTerm, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0ShlU1 = <<A as Shl<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0ShlU1 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Shr_1() {
    type A = UTerm;
    type B = UInt<UTerm, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0ShrU1 = <<A as Shr<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0ShrU1 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Add_1() {
    type A = UTerm;
    type B = UInt<UTerm, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U0AddU1 = <<A as Add<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U0AddU1 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Mul_1() {
    type A = UTerm;
    type B = UInt<UTerm, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0MulU1 = <<A as Mul<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0MulU1 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Pow_1() {
    type A = UTerm;
    type B = UInt<UTerm, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0PowU1 = <<A as Pow<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0PowU1 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Min_1() {
    type A = UTerm;
    type B = UInt<UTerm, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0MinU1 = <<A as Min<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0MinU1 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Max_1() {
    type A = UTerm;
    type B = UInt<UTerm, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U0MaxU1 = <<A as Max<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U0MaxU1 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Gcd_1() {
    type A = UTerm;
    type B = UInt<UTerm, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U0GcdU1 = <<A as Gcd<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U0GcdU1 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Div_1() {
    type A = UTerm;
    type B = UInt<UTerm, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0DivU1 = <<A as Div<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0DivU1 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Rem_1() {
    type A = UTerm;
    type B = UInt<UTerm, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0RemU1 = <<A as Rem<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0RemU1 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_PartialDiv_1() {
    type A = UTerm;
    type B = UInt<UTerm, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0PartialDivU1 = <<A as PartialDiv<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0PartialDivU1 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Cmp_1() {
    type A = UTerm;
    type B = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U0CmpU1 = <A as Cmp<B>>::Output;
    assert_eq!(<U0CmpU1 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_0_BitAnd_2() {
    type A = UTerm;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0BitAndU2 = <<A as BitAnd<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0BitAndU2 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_BitOr_2() {
    type A = UTerm;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U2 = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U0BitOrU2 = <<A as BitOr<B>>::Output as Same<U2>>::Output;

    assert_eq!(<U0BitOrU2 as Unsigned>::to_u64(), <U2 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_BitXor_2() {
    type A = UTerm;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U2 = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U0BitXorU2 = <<A as BitXor<B>>::Output as Same<U2>>::Output;

    assert_eq!(<U0BitXorU2 as Unsigned>::to_u64(), <U2 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Shl_2() {
    type A = UTerm;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0ShlU2 = <<A as Shl<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0ShlU2 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Shr_2() {
    type A = UTerm;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0ShrU2 = <<A as Shr<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0ShrU2 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Add_2() {
    type A = UTerm;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U2 = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U0AddU2 = <<A as Add<B>>::Output as Same<U2>>::Output;

    assert_eq!(<U0AddU2 as Unsigned>::to_u64(), <U2 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Mul_2() {
    type A = UTerm;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0MulU2 = <<A as Mul<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0MulU2 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Pow_2() {
    type A = UTerm;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0PowU2 = <<A as Pow<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0PowU2 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Min_2() {
    type A = UTerm;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0MinU2 = <<A as Min<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0MinU2 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Max_2() {
    type A = UTerm;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U2 = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U0MaxU2 = <<A as Max<B>>::Output as Same<U2>>::Output;

    assert_eq!(<U0MaxU2 as Unsigned>::to_u64(), <U2 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Gcd_2() {
    type A = UTerm;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U2 = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U0GcdU2 = <<A as Gcd<B>>::Output as Same<U2>>::Output;

    assert_eq!(<U0GcdU2 as Unsigned>::to_u64(), <U2 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Div_2() {
    type A = UTerm;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0DivU2 = <<A as Div<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0DivU2 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Rem_2() {
    type A = UTerm;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0RemU2 = <<A as Rem<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0RemU2 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_PartialDiv_2() {
    type A = UTerm;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0PartialDivU2 = <<A as PartialDiv<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0PartialDivU2 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Cmp_2() {
    type A = UTerm;
    type B = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U0CmpU2 = <A as Cmp<B>>::Output;
    assert_eq!(<U0CmpU2 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_0_BitAnd_3() {
    type A = UTerm;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0BitAndU3 = <<A as BitAnd<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0BitAndU3 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_BitOr_3() {
    type A = UTerm;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U3 = UInt<UInt<UTerm, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U0BitOrU3 = <<A as BitOr<B>>::Output as Same<U3>>::Output;

    assert_eq!(<U0BitOrU3 as Unsigned>::to_u64(), <U3 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_BitXor_3() {
    type A = UTerm;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U3 = UInt<UInt<UTerm, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U0BitXorU3 = <<A as BitXor<B>>::Output as Same<U3>>::Output;

    assert_eq!(<U0BitXorU3 as Unsigned>::to_u64(), <U3 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Shl_3() {
    type A = UTerm;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0ShlU3 = <<A as Shl<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0ShlU3 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Shr_3() {
    type A = UTerm;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0ShrU3 = <<A as Shr<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0ShrU3 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Add_3() {
    type A = UTerm;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U3 = UInt<UInt<UTerm, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U0AddU3 = <<A as Add<B>>::Output as Same<U3>>::Output;

    assert_eq!(<U0AddU3 as Unsigned>::to_u64(), <U3 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Mul_3() {
    type A = UTerm;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0MulU3 = <<A as Mul<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0MulU3 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Pow_3() {
    type A = UTerm;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0PowU3 = <<A as Pow<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0PowU3 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Min_3() {
    type A = UTerm;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0MinU3 = <<A as Min<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0MinU3 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Max_3() {
    type A = UTerm;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U3 = UInt<UInt<UTerm, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U0MaxU3 = <<A as Max<B>>::Output as Same<U3>>::Output;

    assert_eq!(<U0MaxU3 as Unsigned>::to_u64(), <U3 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Gcd_3() {
    type A = UTerm;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U3 = UInt<UInt<UTerm, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U0GcdU3 = <<A as Gcd<B>>::Output as Same<U3>>::Output;

    assert_eq!(<U0GcdU3 as Unsigned>::to_u64(), <U3 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Div_3() {
    type A = UTerm;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0DivU3 = <<A as Div<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0DivU3 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Rem_3() {
    type A = UTerm;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0RemU3 = <<A as Rem<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0RemU3 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_PartialDiv_3() {
    type A = UTerm;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0PartialDivU3 = <<A as PartialDiv<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0PartialDivU3 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Cmp_3() {
    type A = UTerm;
    type B = UInt<UInt<UTerm, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U0CmpU3 = <A as Cmp<B>>::Output;
    assert_eq!(<U0CmpU3 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_0_BitAnd_4() {
    type A = UTerm;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0BitAndU4 = <<A as BitAnd<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0BitAndU4 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_BitOr_4() {
    type A = UTerm;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U4 = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U0BitOrU4 = <<A as BitOr<B>>::Output as Same<U4>>::Output;

    assert_eq!(<U0BitOrU4 as Unsigned>::to_u64(), <U4 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_BitXor_4() {
    type A = UTerm;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U4 = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U0BitXorU4 = <<A as BitXor<B>>::Output as Same<U4>>::Output;

    assert_eq!(<U0BitXorU4 as Unsigned>::to_u64(), <U4 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Shl_4() {
    type A = UTerm;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0ShlU4 = <<A as Shl<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0ShlU4 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Shr_4() {
    type A = UTerm;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0ShrU4 = <<A as Shr<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0ShrU4 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Add_4() {
    type A = UTerm;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U4 = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U0AddU4 = <<A as Add<B>>::Output as Same<U4>>::Output;

    assert_eq!(<U0AddU4 as Unsigned>::to_u64(), <U4 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Mul_4() {
    type A = UTerm;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0MulU4 = <<A as Mul<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0MulU4 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Pow_4() {
    type A = UTerm;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0PowU4 = <<A as Pow<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0PowU4 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Min_4() {
    type A = UTerm;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0MinU4 = <<A as Min<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0MinU4 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Max_4() {
    type A = UTerm;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U4 = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U0MaxU4 = <<A as Max<B>>::Output as Same<U4>>::Output;

    assert_eq!(<U0MaxU4 as Unsigned>::to_u64(), <U4 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Gcd_4() {
    type A = UTerm;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U4 = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U0GcdU4 = <<A as Gcd<B>>::Output as Same<U4>>::Output;

    assert_eq!(<U0GcdU4 as Unsigned>::to_u64(), <U4 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Div_4() {
    type A = UTerm;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0DivU4 = <<A as Div<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0DivU4 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Rem_4() {
    type A = UTerm;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0RemU4 = <<A as Rem<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0RemU4 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_PartialDiv_4() {
    type A = UTerm;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0PartialDivU4 = <<A as PartialDiv<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0PartialDivU4 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Cmp_4() {
    type A = UTerm;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U0CmpU4 = <A as Cmp<B>>::Output;
    assert_eq!(<U0CmpU4 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_0_BitAnd_5() {
    type A = UTerm;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0BitAndU5 = <<A as BitAnd<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0BitAndU5 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_BitOr_5() {
    type A = UTerm;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U5 = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U0BitOrU5 = <<A as BitOr<B>>::Output as Same<U5>>::Output;

    assert_eq!(<U0BitOrU5 as Unsigned>::to_u64(), <U5 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_BitXor_5() {
    type A = UTerm;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U5 = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U0BitXorU5 = <<A as BitXor<B>>::Output as Same<U5>>::Output;

    assert_eq!(<U0BitXorU5 as Unsigned>::to_u64(), <U5 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Shl_5() {
    type A = UTerm;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0ShlU5 = <<A as Shl<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0ShlU5 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Shr_5() {
    type A = UTerm;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0ShrU5 = <<A as Shr<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0ShrU5 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Add_5() {
    type A = UTerm;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U5 = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U0AddU5 = <<A as Add<B>>::Output as Same<U5>>::Output;

    assert_eq!(<U0AddU5 as Unsigned>::to_u64(), <U5 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Mul_5() {
    type A = UTerm;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0MulU5 = <<A as Mul<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0MulU5 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Pow_5() {
    type A = UTerm;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0PowU5 = <<A as Pow<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0PowU5 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Min_5() {
    type A = UTerm;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0MinU5 = <<A as Min<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0MinU5 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Max_5() {
    type A = UTerm;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U5 = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U0MaxU5 = <<A as Max<B>>::Output as Same<U5>>::Output;

    assert_eq!(<U0MaxU5 as Unsigned>::to_u64(), <U5 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Gcd_5() {
    type A = UTerm;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U5 = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U0GcdU5 = <<A as Gcd<B>>::Output as Same<U5>>::Output;

    assert_eq!(<U0GcdU5 as Unsigned>::to_u64(), <U5 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Div_5() {
    type A = UTerm;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0DivU5 = <<A as Div<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0DivU5 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Rem_5() {
    type A = UTerm;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0RemU5 = <<A as Rem<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0RemU5 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_PartialDiv_5() {
    type A = UTerm;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U0PartialDivU5 = <<A as PartialDiv<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U0PartialDivU5 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_0_Cmp_5() {
    type A = UTerm;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U0CmpU5 = <A as Cmp<B>>::Output;
    assert_eq!(<U0CmpU5 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_1_BitAnd_0() {
    type A = UInt<UTerm, B1>;
    type B = UTerm;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U1BitAndU0 = <<A as BitAnd<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U1BitAndU0 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_BitOr_0() {
    type A = UInt<UTerm, B1>;
    type B = UTerm;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U1BitOrU0 = <<A as BitOr<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U1BitOrU0 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_BitXor_0() {
    type A = UInt<UTerm, B1>;
    type B = UTerm;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U1BitXorU0 = <<A as BitXor<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U1BitXorU0 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Shl_0() {
    type A = UInt<UTerm, B1>;
    type B = UTerm;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U1ShlU0 = <<A as Shl<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U1ShlU0 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Shr_0() {
    type A = UInt<UTerm, B1>;
    type B = UTerm;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U1ShrU0 = <<A as Shr<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U1ShrU0 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Add_0() {
    type A = UInt<UTerm, B1>;
    type B = UTerm;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U1AddU0 = <<A as Add<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U1AddU0 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Mul_0() {
    type A = UInt<UTerm, B1>;
    type B = UTerm;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U1MulU0 = <<A as Mul<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U1MulU0 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Pow_0() {
    type A = UInt<UTerm, B1>;
    type B = UTerm;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U1PowU0 = <<A as Pow<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U1PowU0 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Min_0() {
    type A = UInt<UTerm, B1>;
    type B = UTerm;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U1MinU0 = <<A as Min<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U1MinU0 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Max_0() {
    type A = UInt<UTerm, B1>;
    type B = UTerm;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U1MaxU0 = <<A as Max<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U1MaxU0 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Gcd_0() {
    type A = UInt<UTerm, B1>;
    type B = UTerm;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U1GcdU0 = <<A as Gcd<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U1GcdU0 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Sub_0() {
    type A = UInt<UTerm, B1>;
    type B = UTerm;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U1SubU0 = <<A as Sub<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U1SubU0 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Cmp_0() {
    type A = UInt<UTerm, B1>;
    type B = UTerm;

    #[allow(non_camel_case_types)]
    type U1CmpU0 = <A as Cmp<B>>::Output;
    assert_eq!(<U1CmpU0 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_1_BitAnd_1() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UTerm, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U1BitAndU1 = <<A as BitAnd<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U1BitAndU1 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_BitOr_1() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UTerm, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U1BitOrU1 = <<A as BitOr<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U1BitOrU1 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_BitXor_1() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UTerm, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U1BitXorU1 = <<A as BitXor<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U1BitXorU1 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Shl_1() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UTerm, B1>;
    type U2 = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U1ShlU1 = <<A as Shl<B>>::Output as Same<U2>>::Output;

    assert_eq!(<U1ShlU1 as Unsigned>::to_u64(), <U2 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Shr_1() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UTerm, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U1ShrU1 = <<A as Shr<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U1ShrU1 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Add_1() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UTerm, B1>;
    type U2 = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U1AddU1 = <<A as Add<B>>::Output as Same<U2>>::Output;

    assert_eq!(<U1AddU1 as Unsigned>::to_u64(), <U2 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Mul_1() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UTerm, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U1MulU1 = <<A as Mul<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U1MulU1 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Pow_1() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UTerm, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U1PowU1 = <<A as Pow<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U1PowU1 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Min_1() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UTerm, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U1MinU1 = <<A as Min<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U1MinU1 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Max_1() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UTerm, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U1MaxU1 = <<A as Max<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U1MaxU1 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Gcd_1() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UTerm, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U1GcdU1 = <<A as Gcd<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U1GcdU1 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Sub_1() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UTerm, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U1SubU1 = <<A as Sub<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U1SubU1 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Div_1() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UTerm, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U1DivU1 = <<A as Div<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U1DivU1 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Rem_1() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UTerm, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U1RemU1 = <<A as Rem<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U1RemU1 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_PartialDiv_1() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UTerm, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U1PartialDivU1 = <<A as PartialDiv<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U1PartialDivU1 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Cmp_1() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U1CmpU1 = <A as Cmp<B>>::Output;
    assert_eq!(<U1CmpU1 as Ord>::to_ordering(), Ordering::Equal);
}
#[test]
#[allow(non_snake_case)]
fn test_1_BitAnd_2() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U1BitAndU2 = <<A as BitAnd<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U1BitAndU2 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_BitOr_2() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U3 = UInt<UInt<UTerm, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U1BitOrU2 = <<A as BitOr<B>>::Output as Same<U3>>::Output;

    assert_eq!(<U1BitOrU2 as Unsigned>::to_u64(), <U3 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_BitXor_2() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U3 = UInt<UInt<UTerm, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U1BitXorU2 = <<A as BitXor<B>>::Output as Same<U3>>::Output;

    assert_eq!(<U1BitXorU2 as Unsigned>::to_u64(), <U3 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Shl_2() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U4 = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U1ShlU2 = <<A as Shl<B>>::Output as Same<U4>>::Output;

    assert_eq!(<U1ShlU2 as Unsigned>::to_u64(), <U4 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Shr_2() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U1ShrU2 = <<A as Shr<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U1ShrU2 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Add_2() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U3 = UInt<UInt<UTerm, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U1AddU2 = <<A as Add<B>>::Output as Same<U3>>::Output;

    assert_eq!(<U1AddU2 as Unsigned>::to_u64(), <U3 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Mul_2() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U2 = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U1MulU2 = <<A as Mul<B>>::Output as Same<U2>>::Output;

    assert_eq!(<U1MulU2 as Unsigned>::to_u64(), <U2 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Pow_2() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U1PowU2 = <<A as Pow<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U1PowU2 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Min_2() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U1MinU2 = <<A as Min<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U1MinU2 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Max_2() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U2 = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U1MaxU2 = <<A as Max<B>>::Output as Same<U2>>::Output;

    assert_eq!(<U1MaxU2 as Unsigned>::to_u64(), <U2 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Gcd_2() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U1GcdU2 = <<A as Gcd<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U1GcdU2 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Div_2() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U1DivU2 = <<A as Div<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U1DivU2 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Rem_2() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U1RemU2 = <<A as Rem<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U1RemU2 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Cmp_2() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U1CmpU2 = <A as Cmp<B>>::Output;
    assert_eq!(<U1CmpU2 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_1_BitAnd_3() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U1BitAndU3 = <<A as BitAnd<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U1BitAndU3 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_BitOr_3() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U3 = UInt<UInt<UTerm, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U1BitOrU3 = <<A as BitOr<B>>::Output as Same<U3>>::Output;

    assert_eq!(<U1BitOrU3 as Unsigned>::to_u64(), <U3 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_BitXor_3() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U2 = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U1BitXorU3 = <<A as BitXor<B>>::Output as Same<U2>>::Output;

    assert_eq!(<U1BitXorU3 as Unsigned>::to_u64(), <U2 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Shl_3() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U8 = UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U1ShlU3 = <<A as Shl<B>>::Output as Same<U8>>::Output;

    assert_eq!(<U1ShlU3 as Unsigned>::to_u64(), <U8 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Shr_3() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U1ShrU3 = <<A as Shr<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U1ShrU3 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Add_3() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U4 = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U1AddU3 = <<A as Add<B>>::Output as Same<U4>>::Output;

    assert_eq!(<U1AddU3 as Unsigned>::to_u64(), <U4 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Mul_3() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U3 = UInt<UInt<UTerm, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U1MulU3 = <<A as Mul<B>>::Output as Same<U3>>::Output;

    assert_eq!(<U1MulU3 as Unsigned>::to_u64(), <U3 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Pow_3() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U1PowU3 = <<A as Pow<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U1PowU3 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Min_3() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U1MinU3 = <<A as Min<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U1MinU3 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Max_3() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U3 = UInt<UInt<UTerm, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U1MaxU3 = <<A as Max<B>>::Output as Same<U3>>::Output;

    assert_eq!(<U1MaxU3 as Unsigned>::to_u64(), <U3 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Gcd_3() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U1GcdU3 = <<A as Gcd<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U1GcdU3 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Div_3() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U1DivU3 = <<A as Div<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U1DivU3 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Rem_3() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U1RemU3 = <<A as Rem<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U1RemU3 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Cmp_3() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UTerm, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U1CmpU3 = <A as Cmp<B>>::Output;
    assert_eq!(<U1CmpU3 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_1_BitAnd_4() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U1BitAndU4 = <<A as BitAnd<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U1BitAndU4 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_BitOr_4() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U5 = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U1BitOrU4 = <<A as BitOr<B>>::Output as Same<U5>>::Output;

    assert_eq!(<U1BitOrU4 as Unsigned>::to_u64(), <U5 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_BitXor_4() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U5 = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U1BitXorU4 = <<A as BitXor<B>>::Output as Same<U5>>::Output;

    assert_eq!(<U1BitXorU4 as Unsigned>::to_u64(), <U5 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Shl_4() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U16 = UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U1ShlU4 = <<A as Shl<B>>::Output as Same<U16>>::Output;

    assert_eq!(<U1ShlU4 as Unsigned>::to_u64(), <U16 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Shr_4() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U1ShrU4 = <<A as Shr<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U1ShrU4 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Add_4() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U5 = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U1AddU4 = <<A as Add<B>>::Output as Same<U5>>::Output;

    assert_eq!(<U1AddU4 as Unsigned>::to_u64(), <U5 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Mul_4() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U4 = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U1MulU4 = <<A as Mul<B>>::Output as Same<U4>>::Output;

    assert_eq!(<U1MulU4 as Unsigned>::to_u64(), <U4 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Pow_4() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U1PowU4 = <<A as Pow<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U1PowU4 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Min_4() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U1MinU4 = <<A as Min<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U1MinU4 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Max_4() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U4 = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U1MaxU4 = <<A as Max<B>>::Output as Same<U4>>::Output;

    assert_eq!(<U1MaxU4 as Unsigned>::to_u64(), <U4 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Gcd_4() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U1GcdU4 = <<A as Gcd<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U1GcdU4 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Div_4() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U1DivU4 = <<A as Div<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U1DivU4 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Rem_4() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U1RemU4 = <<A as Rem<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U1RemU4 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Cmp_4() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U1CmpU4 = <A as Cmp<B>>::Output;
    assert_eq!(<U1CmpU4 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_1_BitAnd_5() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U1BitAndU5 = <<A as BitAnd<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U1BitAndU5 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_BitOr_5() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U5 = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U1BitOrU5 = <<A as BitOr<B>>::Output as Same<U5>>::Output;

    assert_eq!(<U1BitOrU5 as Unsigned>::to_u64(), <U5 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_BitXor_5() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U4 = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U1BitXorU5 = <<A as BitXor<B>>::Output as Same<U4>>::Output;

    assert_eq!(<U1BitXorU5 as Unsigned>::to_u64(), <U4 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Shl_5() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U32 = UInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U1ShlU5 = <<A as Shl<B>>::Output as Same<U32>>::Output;

    assert_eq!(<U1ShlU5 as Unsigned>::to_u64(), <U32 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Shr_5() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U1ShrU5 = <<A as Shr<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U1ShrU5 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Add_5() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U6 = UInt<UInt<UInt<UTerm, B1>, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U1AddU5 = <<A as Add<B>>::Output as Same<U6>>::Output;

    assert_eq!(<U1AddU5 as Unsigned>::to_u64(), <U6 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Mul_5() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U5 = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U1MulU5 = <<A as Mul<B>>::Output as Same<U5>>::Output;

    assert_eq!(<U1MulU5 as Unsigned>::to_u64(), <U5 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Pow_5() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U1PowU5 = <<A as Pow<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U1PowU5 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Min_5() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U1MinU5 = <<A as Min<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U1MinU5 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Max_5() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U5 = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U1MaxU5 = <<A as Max<B>>::Output as Same<U5>>::Output;

    assert_eq!(<U1MaxU5 as Unsigned>::to_u64(), <U5 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Gcd_5() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U1GcdU5 = <<A as Gcd<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U1GcdU5 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Div_5() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U1DivU5 = <<A as Div<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U1DivU5 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Rem_5() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U1RemU5 = <<A as Rem<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U1RemU5 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_1_Cmp_5() {
    type A = UInt<UTerm, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U1CmpU5 = <A as Cmp<B>>::Output;
    assert_eq!(<U1CmpU5 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_2_BitAnd_0() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UTerm;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U2BitAndU0 = <<A as BitAnd<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U2BitAndU0 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_BitOr_0() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UTerm;
    type U2 = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U2BitOrU0 = <<A as BitOr<B>>::Output as Same<U2>>::Output;

    assert_eq!(<U2BitOrU0 as Unsigned>::to_u64(), <U2 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_BitXor_0() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UTerm;
    type U2 = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U2BitXorU0 = <<A as BitXor<B>>::Output as Same<U2>>::Output;

    assert_eq!(<U2BitXorU0 as Unsigned>::to_u64(), <U2 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Shl_0() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UTerm;
    type U2 = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U2ShlU0 = <<A as Shl<B>>::Output as Same<U2>>::Output;

    assert_eq!(<U2ShlU0 as Unsigned>::to_u64(), <U2 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Shr_0() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UTerm;
    type U2 = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U2ShrU0 = <<A as Shr<B>>::Output as Same<U2>>::Output;

    assert_eq!(<U2ShrU0 as Unsigned>::to_u64(), <U2 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Add_0() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UTerm;
    type U2 = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U2AddU0 = <<A as Add<B>>::Output as Same<U2>>::Output;

    assert_eq!(<U2AddU0 as Unsigned>::to_u64(), <U2 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Mul_0() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UTerm;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U2MulU0 = <<A as Mul<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U2MulU0 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Pow_0() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UTerm;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U2PowU0 = <<A as Pow<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U2PowU0 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Min_0() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UTerm;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U2MinU0 = <<A as Min<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U2MinU0 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Max_0() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UTerm;
    type U2 = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U2MaxU0 = <<A as Max<B>>::Output as Same<U2>>::Output;

    assert_eq!(<U2MaxU0 as Unsigned>::to_u64(), <U2 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Gcd_0() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UTerm;
    type U2 = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U2GcdU0 = <<A as Gcd<B>>::Output as Same<U2>>::Output;

    assert_eq!(<U2GcdU0 as Unsigned>::to_u64(), <U2 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Sub_0() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UTerm;
    type U2 = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U2SubU0 = <<A as Sub<B>>::Output as Same<U2>>::Output;

    assert_eq!(<U2SubU0 as Unsigned>::to_u64(), <U2 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Cmp_0() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UTerm;

    #[allow(non_camel_case_types)]
    type U2CmpU0 = <A as Cmp<B>>::Output;
    assert_eq!(<U2CmpU0 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_2_BitAnd_1() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UTerm, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U2BitAndU1 = <<A as BitAnd<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U2BitAndU1 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_BitOr_1() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UTerm, B1>;
    type U3 = UInt<UInt<UTerm, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U2BitOrU1 = <<A as BitOr<B>>::Output as Same<U3>>::Output;

    assert_eq!(<U2BitOrU1 as Unsigned>::to_u64(), <U3 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_BitXor_1() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UTerm, B1>;
    type U3 = UInt<UInt<UTerm, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U2BitXorU1 = <<A as BitXor<B>>::Output as Same<U3>>::Output;

    assert_eq!(<U2BitXorU1 as Unsigned>::to_u64(), <U3 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Shl_1() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UTerm, B1>;
    type U4 = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U2ShlU1 = <<A as Shl<B>>::Output as Same<U4>>::Output;

    assert_eq!(<U2ShlU1 as Unsigned>::to_u64(), <U4 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Shr_1() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UTerm, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U2ShrU1 = <<A as Shr<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U2ShrU1 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Add_1() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UTerm, B1>;
    type U3 = UInt<UInt<UTerm, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U2AddU1 = <<A as Add<B>>::Output as Same<U3>>::Output;

    assert_eq!(<U2AddU1 as Unsigned>::to_u64(), <U3 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Mul_1() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UTerm, B1>;
    type U2 = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U2MulU1 = <<A as Mul<B>>::Output as Same<U2>>::Output;

    assert_eq!(<U2MulU1 as Unsigned>::to_u64(), <U2 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Pow_1() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UTerm, B1>;
    type U2 = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U2PowU1 = <<A as Pow<B>>::Output as Same<U2>>::Output;

    assert_eq!(<U2PowU1 as Unsigned>::to_u64(), <U2 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Min_1() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UTerm, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U2MinU1 = <<A as Min<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U2MinU1 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Max_1() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UTerm, B1>;
    type U2 = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U2MaxU1 = <<A as Max<B>>::Output as Same<U2>>::Output;

    assert_eq!(<U2MaxU1 as Unsigned>::to_u64(), <U2 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Gcd_1() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UTerm, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U2GcdU1 = <<A as Gcd<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U2GcdU1 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Sub_1() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UTerm, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U2SubU1 = <<A as Sub<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U2SubU1 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Div_1() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UTerm, B1>;
    type U2 = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U2DivU1 = <<A as Div<B>>::Output as Same<U2>>::Output;

    assert_eq!(<U2DivU1 as Unsigned>::to_u64(), <U2 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Rem_1() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UTerm, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U2RemU1 = <<A as Rem<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U2RemU1 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_PartialDiv_1() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UTerm, B1>;
    type U2 = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U2PartialDivU1 = <<A as PartialDiv<B>>::Output as Same<U2>>::Output;

    assert_eq!(<U2PartialDivU1 as Unsigned>::to_u64(), <U2 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Cmp_1() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U2CmpU1 = <A as Cmp<B>>::Output;
    assert_eq!(<U2CmpU1 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_2_BitAnd_2() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U2 = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U2BitAndU2 = <<A as BitAnd<B>>::Output as Same<U2>>::Output;

    assert_eq!(<U2BitAndU2 as Unsigned>::to_u64(), <U2 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_BitOr_2() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U2 = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U2BitOrU2 = <<A as BitOr<B>>::Output as Same<U2>>::Output;

    assert_eq!(<U2BitOrU2 as Unsigned>::to_u64(), <U2 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_BitXor_2() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U2BitXorU2 = <<A as BitXor<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U2BitXorU2 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Shl_2() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U8 = UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U2ShlU2 = <<A as Shl<B>>::Output as Same<U8>>::Output;

    assert_eq!(<U2ShlU2 as Unsigned>::to_u64(), <U8 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Shr_2() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U2ShrU2 = <<A as Shr<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U2ShrU2 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Add_2() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U4 = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U2AddU2 = <<A as Add<B>>::Output as Same<U4>>::Output;

    assert_eq!(<U2AddU2 as Unsigned>::to_u64(), <U4 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Mul_2() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U4 = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U2MulU2 = <<A as Mul<B>>::Output as Same<U4>>::Output;

    assert_eq!(<U2MulU2 as Unsigned>::to_u64(), <U4 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Pow_2() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U4 = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U2PowU2 = <<A as Pow<B>>::Output as Same<U4>>::Output;

    assert_eq!(<U2PowU2 as Unsigned>::to_u64(), <U4 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Min_2() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U2 = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U2MinU2 = <<A as Min<B>>::Output as Same<U2>>::Output;

    assert_eq!(<U2MinU2 as Unsigned>::to_u64(), <U2 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Max_2() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U2 = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U2MaxU2 = <<A as Max<B>>::Output as Same<U2>>::Output;

    assert_eq!(<U2MaxU2 as Unsigned>::to_u64(), <U2 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Gcd_2() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U2 = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U2GcdU2 = <<A as Gcd<B>>::Output as Same<U2>>::Output;

    assert_eq!(<U2GcdU2 as Unsigned>::to_u64(), <U2 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Sub_2() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U2SubU2 = <<A as Sub<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U2SubU2 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Div_2() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U2DivU2 = <<A as Div<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U2DivU2 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Rem_2() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U2RemU2 = <<A as Rem<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U2RemU2 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_PartialDiv_2() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U2PartialDivU2 = <<A as PartialDiv<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U2PartialDivU2 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Cmp_2() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U2CmpU2 = <A as Cmp<B>>::Output;
    assert_eq!(<U2CmpU2 as Ord>::to_ordering(), Ordering::Equal);
}
#[test]
#[allow(non_snake_case)]
fn test_2_BitAnd_3() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U2 = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U2BitAndU3 = <<A as BitAnd<B>>::Output as Same<U2>>::Output;

    assert_eq!(<U2BitAndU3 as Unsigned>::to_u64(), <U2 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_BitOr_3() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U3 = UInt<UInt<UTerm, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U2BitOrU3 = <<A as BitOr<B>>::Output as Same<U3>>::Output;

    assert_eq!(<U2BitOrU3 as Unsigned>::to_u64(), <U3 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_BitXor_3() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U2BitXorU3 = <<A as BitXor<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U2BitXorU3 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Shl_3() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U16 = UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U2ShlU3 = <<A as Shl<B>>::Output as Same<U16>>::Output;

    assert_eq!(<U2ShlU3 as Unsigned>::to_u64(), <U16 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Shr_3() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U2ShrU3 = <<A as Shr<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U2ShrU3 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Add_3() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U5 = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U2AddU3 = <<A as Add<B>>::Output as Same<U5>>::Output;

    assert_eq!(<U2AddU3 as Unsigned>::to_u64(), <U5 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Mul_3() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U6 = UInt<UInt<UInt<UTerm, B1>, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U2MulU3 = <<A as Mul<B>>::Output as Same<U6>>::Output;

    assert_eq!(<U2MulU3 as Unsigned>::to_u64(), <U6 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Pow_3() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U8 = UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U2PowU3 = <<A as Pow<B>>::Output as Same<U8>>::Output;

    assert_eq!(<U2PowU3 as Unsigned>::to_u64(), <U8 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Min_3() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U2 = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U2MinU3 = <<A as Min<B>>::Output as Same<U2>>::Output;

    assert_eq!(<U2MinU3 as Unsigned>::to_u64(), <U2 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Max_3() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U3 = UInt<UInt<UTerm, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U2MaxU3 = <<A as Max<B>>::Output as Same<U3>>::Output;

    assert_eq!(<U2MaxU3 as Unsigned>::to_u64(), <U3 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Gcd_3() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U2GcdU3 = <<A as Gcd<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U2GcdU3 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Div_3() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U2DivU3 = <<A as Div<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U2DivU3 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Rem_3() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U2 = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U2RemU3 = <<A as Rem<B>>::Output as Same<U2>>::Output;

    assert_eq!(<U2RemU3 as Unsigned>::to_u64(), <U2 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Cmp_3() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UTerm, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U2CmpU3 = <A as Cmp<B>>::Output;
    assert_eq!(<U2CmpU3 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_2_BitAnd_4() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U2BitAndU4 = <<A as BitAnd<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U2BitAndU4 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_BitOr_4() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U6 = UInt<UInt<UInt<UTerm, B1>, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U2BitOrU4 = <<A as BitOr<B>>::Output as Same<U6>>::Output;

    assert_eq!(<U2BitOrU4 as Unsigned>::to_u64(), <U6 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_BitXor_4() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U6 = UInt<UInt<UInt<UTerm, B1>, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U2BitXorU4 = <<A as BitXor<B>>::Output as Same<U6>>::Output;

    assert_eq!(<U2BitXorU4 as Unsigned>::to_u64(), <U6 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Shl_4() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U32 = UInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U2ShlU4 = <<A as Shl<B>>::Output as Same<U32>>::Output;

    assert_eq!(<U2ShlU4 as Unsigned>::to_u64(), <U32 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Shr_4() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U2ShrU4 = <<A as Shr<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U2ShrU4 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Add_4() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U6 = UInt<UInt<UInt<UTerm, B1>, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U2AddU4 = <<A as Add<B>>::Output as Same<U6>>::Output;

    assert_eq!(<U2AddU4 as Unsigned>::to_u64(), <U6 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Mul_4() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U8 = UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U2MulU4 = <<A as Mul<B>>::Output as Same<U8>>::Output;

    assert_eq!(<U2MulU4 as Unsigned>::to_u64(), <U8 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Pow_4() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U16 = UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U2PowU4 = <<A as Pow<B>>::Output as Same<U16>>::Output;

    assert_eq!(<U2PowU4 as Unsigned>::to_u64(), <U16 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Min_4() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U2 = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U2MinU4 = <<A as Min<B>>::Output as Same<U2>>::Output;

    assert_eq!(<U2MinU4 as Unsigned>::to_u64(), <U2 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Max_4() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U4 = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U2MaxU4 = <<A as Max<B>>::Output as Same<U4>>::Output;

    assert_eq!(<U2MaxU4 as Unsigned>::to_u64(), <U4 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Gcd_4() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U2 = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U2GcdU4 = <<A as Gcd<B>>::Output as Same<U2>>::Output;

    assert_eq!(<U2GcdU4 as Unsigned>::to_u64(), <U2 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Div_4() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U2DivU4 = <<A as Div<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U2DivU4 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Rem_4() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U2 = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U2RemU4 = <<A as Rem<B>>::Output as Same<U2>>::Output;

    assert_eq!(<U2RemU4 as Unsigned>::to_u64(), <U2 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Cmp_4() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U2CmpU4 = <A as Cmp<B>>::Output;
    assert_eq!(<U2CmpU4 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_2_BitAnd_5() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U2BitAndU5 = <<A as BitAnd<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U2BitAndU5 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_BitOr_5() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U7 = UInt<UInt<UInt<UTerm, B1>, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U2BitOrU5 = <<A as BitOr<B>>::Output as Same<U7>>::Output;

    assert_eq!(<U2BitOrU5 as Unsigned>::to_u64(), <U7 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_BitXor_5() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U7 = UInt<UInt<UInt<UTerm, B1>, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U2BitXorU5 = <<A as BitXor<B>>::Output as Same<U7>>::Output;

    assert_eq!(<U2BitXorU5 as Unsigned>::to_u64(), <U7 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Shl_5() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U64 = UInt<UInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>, B0>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U2ShlU5 = <<A as Shl<B>>::Output as Same<U64>>::Output;

    assert_eq!(<U2ShlU5 as Unsigned>::to_u64(), <U64 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Shr_5() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U2ShrU5 = <<A as Shr<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U2ShrU5 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Add_5() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U7 = UInt<UInt<UInt<UTerm, B1>, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U2AddU5 = <<A as Add<B>>::Output as Same<U7>>::Output;

    assert_eq!(<U2AddU5 as Unsigned>::to_u64(), <U7 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Mul_5() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U10 = UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U2MulU5 = <<A as Mul<B>>::Output as Same<U10>>::Output;

    assert_eq!(<U2MulU5 as Unsigned>::to_u64(), <U10 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Pow_5() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U32 = UInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U2PowU5 = <<A as Pow<B>>::Output as Same<U32>>::Output;

    assert_eq!(<U2PowU5 as Unsigned>::to_u64(), <U32 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Min_5() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U2 = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U2MinU5 = <<A as Min<B>>::Output as Same<U2>>::Output;

    assert_eq!(<U2MinU5 as Unsigned>::to_u64(), <U2 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Max_5() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U5 = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U2MaxU5 = <<A as Max<B>>::Output as Same<U5>>::Output;

    assert_eq!(<U2MaxU5 as Unsigned>::to_u64(), <U5 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Gcd_5() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U2GcdU5 = <<A as Gcd<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U2GcdU5 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Div_5() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U2DivU5 = <<A as Div<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U2DivU5 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Rem_5() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U2 = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U2RemU5 = <<A as Rem<B>>::Output as Same<U2>>::Output;

    assert_eq!(<U2RemU5 as Unsigned>::to_u64(), <U2 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_2_Cmp_5() {
    type A = UInt<UInt<UTerm, B1>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U2CmpU5 = <A as Cmp<B>>::Output;
    assert_eq!(<U2CmpU5 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_3_BitAnd_0() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UTerm;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U3BitAndU0 = <<A as BitAnd<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U3BitAndU0 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_BitOr_0() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UTerm;
    type U3 = UInt<UInt<UTerm, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U3BitOrU0 = <<A as BitOr<B>>::Output as Same<U3>>::Output;

    assert_eq!(<U3BitOrU0 as Unsigned>::to_u64(), <U3 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_BitXor_0() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UTerm;
    type U3 = UInt<UInt<UTerm, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U3BitXorU0 = <<A as BitXor<B>>::Output as Same<U3>>::Output;

    assert_eq!(<U3BitXorU0 as Unsigned>::to_u64(), <U3 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Shl_0() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UTerm;
    type U3 = UInt<UInt<UTerm, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U3ShlU0 = <<A as Shl<B>>::Output as Same<U3>>::Output;

    assert_eq!(<U3ShlU0 as Unsigned>::to_u64(), <U3 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Shr_0() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UTerm;
    type U3 = UInt<UInt<UTerm, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U3ShrU0 = <<A as Shr<B>>::Output as Same<U3>>::Output;

    assert_eq!(<U3ShrU0 as Unsigned>::to_u64(), <U3 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Add_0() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UTerm;
    type U3 = UInt<UInt<UTerm, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U3AddU0 = <<A as Add<B>>::Output as Same<U3>>::Output;

    assert_eq!(<U3AddU0 as Unsigned>::to_u64(), <U3 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Mul_0() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UTerm;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U3MulU0 = <<A as Mul<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U3MulU0 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Pow_0() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UTerm;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U3PowU0 = <<A as Pow<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U3PowU0 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Min_0() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UTerm;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U3MinU0 = <<A as Min<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U3MinU0 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Max_0() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UTerm;
    type U3 = UInt<UInt<UTerm, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U3MaxU0 = <<A as Max<B>>::Output as Same<U3>>::Output;

    assert_eq!(<U3MaxU0 as Unsigned>::to_u64(), <U3 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Gcd_0() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UTerm;
    type U3 = UInt<UInt<UTerm, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U3GcdU0 = <<A as Gcd<B>>::Output as Same<U3>>::Output;

    assert_eq!(<U3GcdU0 as Unsigned>::to_u64(), <U3 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Sub_0() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UTerm;
    type U3 = UInt<UInt<UTerm, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U3SubU0 = <<A as Sub<B>>::Output as Same<U3>>::Output;

    assert_eq!(<U3SubU0 as Unsigned>::to_u64(), <U3 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Cmp_0() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UTerm;

    #[allow(non_camel_case_types)]
    type U3CmpU0 = <A as Cmp<B>>::Output;
    assert_eq!(<U3CmpU0 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_3_BitAnd_1() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UTerm, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U3BitAndU1 = <<A as BitAnd<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U3BitAndU1 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_BitOr_1() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UTerm, B1>;
    type U3 = UInt<UInt<UTerm, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U3BitOrU1 = <<A as BitOr<B>>::Output as Same<U3>>::Output;

    assert_eq!(<U3BitOrU1 as Unsigned>::to_u64(), <U3 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_BitXor_1() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UTerm, B1>;
    type U2 = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U3BitXorU1 = <<A as BitXor<B>>::Output as Same<U2>>::Output;

    assert_eq!(<U3BitXorU1 as Unsigned>::to_u64(), <U2 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Shl_1() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UTerm, B1>;
    type U6 = UInt<UInt<UInt<UTerm, B1>, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U3ShlU1 = <<A as Shl<B>>::Output as Same<U6>>::Output;

    assert_eq!(<U3ShlU1 as Unsigned>::to_u64(), <U6 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Shr_1() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UTerm, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U3ShrU1 = <<A as Shr<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U3ShrU1 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Add_1() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UTerm, B1>;
    type U4 = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U3AddU1 = <<A as Add<B>>::Output as Same<U4>>::Output;

    assert_eq!(<U3AddU1 as Unsigned>::to_u64(), <U4 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Mul_1() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UTerm, B1>;
    type U3 = UInt<UInt<UTerm, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U3MulU1 = <<A as Mul<B>>::Output as Same<U3>>::Output;

    assert_eq!(<U3MulU1 as Unsigned>::to_u64(), <U3 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Pow_1() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UTerm, B1>;
    type U3 = UInt<UInt<UTerm, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U3PowU1 = <<A as Pow<B>>::Output as Same<U3>>::Output;

    assert_eq!(<U3PowU1 as Unsigned>::to_u64(), <U3 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Min_1() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UTerm, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U3MinU1 = <<A as Min<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U3MinU1 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Max_1() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UTerm, B1>;
    type U3 = UInt<UInt<UTerm, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U3MaxU1 = <<A as Max<B>>::Output as Same<U3>>::Output;

    assert_eq!(<U3MaxU1 as Unsigned>::to_u64(), <U3 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Gcd_1() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UTerm, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U3GcdU1 = <<A as Gcd<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U3GcdU1 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Sub_1() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UTerm, B1>;
    type U2 = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U3SubU1 = <<A as Sub<B>>::Output as Same<U2>>::Output;

    assert_eq!(<U3SubU1 as Unsigned>::to_u64(), <U2 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Div_1() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UTerm, B1>;
    type U3 = UInt<UInt<UTerm, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U3DivU1 = <<A as Div<B>>::Output as Same<U3>>::Output;

    assert_eq!(<U3DivU1 as Unsigned>::to_u64(), <U3 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Rem_1() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UTerm, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U3RemU1 = <<A as Rem<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U3RemU1 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_PartialDiv_1() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UTerm, B1>;
    type U3 = UInt<UInt<UTerm, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U3PartialDivU1 = <<A as PartialDiv<B>>::Output as Same<U3>>::Output;

    assert_eq!(<U3PartialDivU1 as Unsigned>::to_u64(), <U3 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Cmp_1() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U3CmpU1 = <A as Cmp<B>>::Output;
    assert_eq!(<U3CmpU1 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_3_BitAnd_2() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U2 = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U3BitAndU2 = <<A as BitAnd<B>>::Output as Same<U2>>::Output;

    assert_eq!(<U3BitAndU2 as Unsigned>::to_u64(), <U2 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_BitOr_2() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U3 = UInt<UInt<UTerm, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U3BitOrU2 = <<A as BitOr<B>>::Output as Same<U3>>::Output;

    assert_eq!(<U3BitOrU2 as Unsigned>::to_u64(), <U3 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_BitXor_2() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U3BitXorU2 = <<A as BitXor<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U3BitXorU2 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Shl_2() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U12 = UInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U3ShlU2 = <<A as Shl<B>>::Output as Same<U12>>::Output;

    assert_eq!(<U3ShlU2 as Unsigned>::to_u64(), <U12 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Shr_2() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U3ShrU2 = <<A as Shr<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U3ShrU2 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Add_2() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U5 = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U3AddU2 = <<A as Add<B>>::Output as Same<U5>>::Output;

    assert_eq!(<U3AddU2 as Unsigned>::to_u64(), <U5 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Mul_2() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U6 = UInt<UInt<UInt<UTerm, B1>, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U3MulU2 = <<A as Mul<B>>::Output as Same<U6>>::Output;

    assert_eq!(<U3MulU2 as Unsigned>::to_u64(), <U6 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Pow_2() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U9 = UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U3PowU2 = <<A as Pow<B>>::Output as Same<U9>>::Output;

    assert_eq!(<U3PowU2 as Unsigned>::to_u64(), <U9 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Min_2() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U2 = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U3MinU2 = <<A as Min<B>>::Output as Same<U2>>::Output;

    assert_eq!(<U3MinU2 as Unsigned>::to_u64(), <U2 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Max_2() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U3 = UInt<UInt<UTerm, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U3MaxU2 = <<A as Max<B>>::Output as Same<U3>>::Output;

    assert_eq!(<U3MaxU2 as Unsigned>::to_u64(), <U3 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Gcd_2() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U3GcdU2 = <<A as Gcd<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U3GcdU2 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Sub_2() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U3SubU2 = <<A as Sub<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U3SubU2 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Div_2() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U3DivU2 = <<A as Div<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U3DivU2 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Rem_2() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U3RemU2 = <<A as Rem<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U3RemU2 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Cmp_2() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U3CmpU2 = <A as Cmp<B>>::Output;
    assert_eq!(<U3CmpU2 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_3_BitAnd_3() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U3 = UInt<UInt<UTerm, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U3BitAndU3 = <<A as BitAnd<B>>::Output as Same<U3>>::Output;

    assert_eq!(<U3BitAndU3 as Unsigned>::to_u64(), <U3 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_BitOr_3() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U3 = UInt<UInt<UTerm, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U3BitOrU3 = <<A as BitOr<B>>::Output as Same<U3>>::Output;

    assert_eq!(<U3BitOrU3 as Unsigned>::to_u64(), <U3 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_BitXor_3() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U3BitXorU3 = <<A as BitXor<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U3BitXorU3 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Shl_3() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U24 = UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U3ShlU3 = <<A as Shl<B>>::Output as Same<U24>>::Output;

    assert_eq!(<U3ShlU3 as Unsigned>::to_u64(), <U24 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Shr_3() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U3ShrU3 = <<A as Shr<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U3ShrU3 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Add_3() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U6 = UInt<UInt<UInt<UTerm, B1>, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U3AddU3 = <<A as Add<B>>::Output as Same<U6>>::Output;

    assert_eq!(<U3AddU3 as Unsigned>::to_u64(), <U6 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Mul_3() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U9 = UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U3MulU3 = <<A as Mul<B>>::Output as Same<U9>>::Output;

    assert_eq!(<U3MulU3 as Unsigned>::to_u64(), <U9 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Pow_3() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U27 = UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U3PowU3 = <<A as Pow<B>>::Output as Same<U27>>::Output;

    assert_eq!(<U3PowU3 as Unsigned>::to_u64(), <U27 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Min_3() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U3 = UInt<UInt<UTerm, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U3MinU3 = <<A as Min<B>>::Output as Same<U3>>::Output;

    assert_eq!(<U3MinU3 as Unsigned>::to_u64(), <U3 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Max_3() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U3 = UInt<UInt<UTerm, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U3MaxU3 = <<A as Max<B>>::Output as Same<U3>>::Output;

    assert_eq!(<U3MaxU3 as Unsigned>::to_u64(), <U3 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Gcd_3() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U3 = UInt<UInt<UTerm, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U3GcdU3 = <<A as Gcd<B>>::Output as Same<U3>>::Output;

    assert_eq!(<U3GcdU3 as Unsigned>::to_u64(), <U3 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Sub_3() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U3SubU3 = <<A as Sub<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U3SubU3 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Div_3() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U3DivU3 = <<A as Div<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U3DivU3 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Rem_3() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U3RemU3 = <<A as Rem<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U3RemU3 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_PartialDiv_3() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U3PartialDivU3 = <<A as PartialDiv<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U3PartialDivU3 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Cmp_3() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UTerm, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U3CmpU3 = <A as Cmp<B>>::Output;
    assert_eq!(<U3CmpU3 as Ord>::to_ordering(), Ordering::Equal);
}
#[test]
#[allow(non_snake_case)]
fn test_3_BitAnd_4() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U3BitAndU4 = <<A as BitAnd<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U3BitAndU4 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_BitOr_4() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U7 = UInt<UInt<UInt<UTerm, B1>, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U3BitOrU4 = <<A as BitOr<B>>::Output as Same<U7>>::Output;

    assert_eq!(<U3BitOrU4 as Unsigned>::to_u64(), <U7 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_BitXor_4() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U7 = UInt<UInt<UInt<UTerm, B1>, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U3BitXorU4 = <<A as BitXor<B>>::Output as Same<U7>>::Output;

    assert_eq!(<U3BitXorU4 as Unsigned>::to_u64(), <U7 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Shl_4() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U48 = UInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>, B0>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U3ShlU4 = <<A as Shl<B>>::Output as Same<U48>>::Output;

    assert_eq!(<U3ShlU4 as Unsigned>::to_u64(), <U48 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Shr_4() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U3ShrU4 = <<A as Shr<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U3ShrU4 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Add_4() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U7 = UInt<UInt<UInt<UTerm, B1>, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U3AddU4 = <<A as Add<B>>::Output as Same<U7>>::Output;

    assert_eq!(<U3AddU4 as Unsigned>::to_u64(), <U7 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Mul_4() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U12 = UInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U3MulU4 = <<A as Mul<B>>::Output as Same<U12>>::Output;

    assert_eq!(<U3MulU4 as Unsigned>::to_u64(), <U12 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Pow_4() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U81 = UInt<UInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>, B0>, B0>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U3PowU4 = <<A as Pow<B>>::Output as Same<U81>>::Output;

    assert_eq!(<U3PowU4 as Unsigned>::to_u64(), <U81 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Min_4() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U3 = UInt<UInt<UTerm, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U3MinU4 = <<A as Min<B>>::Output as Same<U3>>::Output;

    assert_eq!(<U3MinU4 as Unsigned>::to_u64(), <U3 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Max_4() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U4 = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U3MaxU4 = <<A as Max<B>>::Output as Same<U4>>::Output;

    assert_eq!(<U3MaxU4 as Unsigned>::to_u64(), <U4 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Gcd_4() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U3GcdU4 = <<A as Gcd<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U3GcdU4 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Div_4() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U3DivU4 = <<A as Div<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U3DivU4 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Rem_4() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U3 = UInt<UInt<UTerm, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U3RemU4 = <<A as Rem<B>>::Output as Same<U3>>::Output;

    assert_eq!(<U3RemU4 as Unsigned>::to_u64(), <U3 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Cmp_4() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U3CmpU4 = <A as Cmp<B>>::Output;
    assert_eq!(<U3CmpU4 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_3_BitAnd_5() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U3BitAndU5 = <<A as BitAnd<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U3BitAndU5 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_BitOr_5() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U7 = UInt<UInt<UInt<UTerm, B1>, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U3BitOrU5 = <<A as BitOr<B>>::Output as Same<U7>>::Output;

    assert_eq!(<U3BitOrU5 as Unsigned>::to_u64(), <U7 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_BitXor_5() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U6 = UInt<UInt<UInt<UTerm, B1>, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U3BitXorU5 = <<A as BitXor<B>>::Output as Same<U6>>::Output;

    assert_eq!(<U3BitXorU5 as Unsigned>::to_u64(), <U6 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Shl_5() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U96 = UInt<UInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>, B0>, B0>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U3ShlU5 = <<A as Shl<B>>::Output as Same<U96>>::Output;

    assert_eq!(<U3ShlU5 as Unsigned>::to_u64(), <U96 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Shr_5() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U3ShrU5 = <<A as Shr<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U3ShrU5 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Add_5() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U8 = UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U3AddU5 = <<A as Add<B>>::Output as Same<U8>>::Output;

    assert_eq!(<U3AddU5 as Unsigned>::to_u64(), <U8 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Mul_5() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U15 = UInt<UInt<UInt<UInt<UTerm, B1>, B1>, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U3MulU5 = <<A as Mul<B>>::Output as Same<U15>>::Output;

    assert_eq!(<U3MulU5 as Unsigned>::to_u64(), <U15 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Pow_5() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U243 = UInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B1>, B1>, B1>, B0>, B0>, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U3PowU5 = <<A as Pow<B>>::Output as Same<U243>>::Output;

    assert_eq!(<U3PowU5 as Unsigned>::to_u64(), <U243 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Min_5() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U3 = UInt<UInt<UTerm, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U3MinU5 = <<A as Min<B>>::Output as Same<U3>>::Output;

    assert_eq!(<U3MinU5 as Unsigned>::to_u64(), <U3 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Max_5() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U5 = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U3MaxU5 = <<A as Max<B>>::Output as Same<U5>>::Output;

    assert_eq!(<U3MaxU5 as Unsigned>::to_u64(), <U5 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Gcd_5() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U3GcdU5 = <<A as Gcd<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U3GcdU5 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Div_5() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U3DivU5 = <<A as Div<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U3DivU5 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Rem_5() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U3 = UInt<UInt<UTerm, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U3RemU5 = <<A as Rem<B>>::Output as Same<U3>>::Output;

    assert_eq!(<U3RemU5 as Unsigned>::to_u64(), <U3 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_3_Cmp_5() {
    type A = UInt<UInt<UTerm, B1>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U3CmpU5 = <A as Cmp<B>>::Output;
    assert_eq!(<U3CmpU5 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_4_BitAnd_0() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UTerm;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U4BitAndU0 = <<A as BitAnd<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U4BitAndU0 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_BitOr_0() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UTerm;
    type U4 = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U4BitOrU0 = <<A as BitOr<B>>::Output as Same<U4>>::Output;

    assert_eq!(<U4BitOrU0 as Unsigned>::to_u64(), <U4 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_BitXor_0() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UTerm;
    type U4 = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U4BitXorU0 = <<A as BitXor<B>>::Output as Same<U4>>::Output;

    assert_eq!(<U4BitXorU0 as Unsigned>::to_u64(), <U4 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Shl_0() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UTerm;
    type U4 = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U4ShlU0 = <<A as Shl<B>>::Output as Same<U4>>::Output;

    assert_eq!(<U4ShlU0 as Unsigned>::to_u64(), <U4 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Shr_0() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UTerm;
    type U4 = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U4ShrU0 = <<A as Shr<B>>::Output as Same<U4>>::Output;

    assert_eq!(<U4ShrU0 as Unsigned>::to_u64(), <U4 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Add_0() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UTerm;
    type U4 = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U4AddU0 = <<A as Add<B>>::Output as Same<U4>>::Output;

    assert_eq!(<U4AddU0 as Unsigned>::to_u64(), <U4 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Mul_0() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UTerm;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U4MulU0 = <<A as Mul<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U4MulU0 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Pow_0() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UTerm;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U4PowU0 = <<A as Pow<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U4PowU0 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Min_0() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UTerm;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U4MinU0 = <<A as Min<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U4MinU0 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Max_0() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UTerm;
    type U4 = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U4MaxU0 = <<A as Max<B>>::Output as Same<U4>>::Output;

    assert_eq!(<U4MaxU0 as Unsigned>::to_u64(), <U4 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Gcd_0() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UTerm;
    type U4 = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U4GcdU0 = <<A as Gcd<B>>::Output as Same<U4>>::Output;

    assert_eq!(<U4GcdU0 as Unsigned>::to_u64(), <U4 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Sub_0() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UTerm;
    type U4 = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U4SubU0 = <<A as Sub<B>>::Output as Same<U4>>::Output;

    assert_eq!(<U4SubU0 as Unsigned>::to_u64(), <U4 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Cmp_0() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UTerm;

    #[allow(non_camel_case_types)]
    type U4CmpU0 = <A as Cmp<B>>::Output;
    assert_eq!(<U4CmpU0 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_4_BitAnd_1() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UTerm, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U4BitAndU1 = <<A as BitAnd<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U4BitAndU1 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_BitOr_1() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UTerm, B1>;
    type U5 = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U4BitOrU1 = <<A as BitOr<B>>::Output as Same<U5>>::Output;

    assert_eq!(<U4BitOrU1 as Unsigned>::to_u64(), <U5 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_BitXor_1() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UTerm, B1>;
    type U5 = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U4BitXorU1 = <<A as BitXor<B>>::Output as Same<U5>>::Output;

    assert_eq!(<U4BitXorU1 as Unsigned>::to_u64(), <U5 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Shl_1() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UTerm, B1>;
    type U8 = UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U4ShlU1 = <<A as Shl<B>>::Output as Same<U8>>::Output;

    assert_eq!(<U4ShlU1 as Unsigned>::to_u64(), <U8 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Shr_1() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UTerm, B1>;
    type U2 = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U4ShrU1 = <<A as Shr<B>>::Output as Same<U2>>::Output;

    assert_eq!(<U4ShrU1 as Unsigned>::to_u64(), <U2 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Add_1() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UTerm, B1>;
    type U5 = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U4AddU1 = <<A as Add<B>>::Output as Same<U5>>::Output;

    assert_eq!(<U4AddU1 as Unsigned>::to_u64(), <U5 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Mul_1() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UTerm, B1>;
    type U4 = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U4MulU1 = <<A as Mul<B>>::Output as Same<U4>>::Output;

    assert_eq!(<U4MulU1 as Unsigned>::to_u64(), <U4 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Pow_1() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UTerm, B1>;
    type U4 = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U4PowU1 = <<A as Pow<B>>::Output as Same<U4>>::Output;

    assert_eq!(<U4PowU1 as Unsigned>::to_u64(), <U4 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Min_1() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UTerm, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U4MinU1 = <<A as Min<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U4MinU1 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Max_1() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UTerm, B1>;
    type U4 = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U4MaxU1 = <<A as Max<B>>::Output as Same<U4>>::Output;

    assert_eq!(<U4MaxU1 as Unsigned>::to_u64(), <U4 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Gcd_1() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UTerm, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U4GcdU1 = <<A as Gcd<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U4GcdU1 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Sub_1() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UTerm, B1>;
    type U3 = UInt<UInt<UTerm, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U4SubU1 = <<A as Sub<B>>::Output as Same<U3>>::Output;

    assert_eq!(<U4SubU1 as Unsigned>::to_u64(), <U3 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Div_1() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UTerm, B1>;
    type U4 = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U4DivU1 = <<A as Div<B>>::Output as Same<U4>>::Output;

    assert_eq!(<U4DivU1 as Unsigned>::to_u64(), <U4 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Rem_1() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UTerm, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U4RemU1 = <<A as Rem<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U4RemU1 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_PartialDiv_1() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UTerm, B1>;
    type U4 = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U4PartialDivU1 = <<A as PartialDiv<B>>::Output as Same<U4>>::Output;

    assert_eq!(<U4PartialDivU1 as Unsigned>::to_u64(), <U4 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Cmp_1() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U4CmpU1 = <A as Cmp<B>>::Output;
    assert_eq!(<U4CmpU1 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_4_BitAnd_2() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U4BitAndU2 = <<A as BitAnd<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U4BitAndU2 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_BitOr_2() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U6 = UInt<UInt<UInt<UTerm, B1>, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U4BitOrU2 = <<A as BitOr<B>>::Output as Same<U6>>::Output;

    assert_eq!(<U4BitOrU2 as Unsigned>::to_u64(), <U6 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_BitXor_2() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U6 = UInt<UInt<UInt<UTerm, B1>, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U4BitXorU2 = <<A as BitXor<B>>::Output as Same<U6>>::Output;

    assert_eq!(<U4BitXorU2 as Unsigned>::to_u64(), <U6 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Shl_2() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U16 = UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U4ShlU2 = <<A as Shl<B>>::Output as Same<U16>>::Output;

    assert_eq!(<U4ShlU2 as Unsigned>::to_u64(), <U16 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Shr_2() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U4ShrU2 = <<A as Shr<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U4ShrU2 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Add_2() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U6 = UInt<UInt<UInt<UTerm, B1>, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U4AddU2 = <<A as Add<B>>::Output as Same<U6>>::Output;

    assert_eq!(<U4AddU2 as Unsigned>::to_u64(), <U6 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Mul_2() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U8 = UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U4MulU2 = <<A as Mul<B>>::Output as Same<U8>>::Output;

    assert_eq!(<U4MulU2 as Unsigned>::to_u64(), <U8 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Pow_2() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U16 = UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U4PowU2 = <<A as Pow<B>>::Output as Same<U16>>::Output;

    assert_eq!(<U4PowU2 as Unsigned>::to_u64(), <U16 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Min_2() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U2 = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U4MinU2 = <<A as Min<B>>::Output as Same<U2>>::Output;

    assert_eq!(<U4MinU2 as Unsigned>::to_u64(), <U2 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Max_2() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U4 = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U4MaxU2 = <<A as Max<B>>::Output as Same<U4>>::Output;

    assert_eq!(<U4MaxU2 as Unsigned>::to_u64(), <U4 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Gcd_2() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U2 = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U4GcdU2 = <<A as Gcd<B>>::Output as Same<U2>>::Output;

    assert_eq!(<U4GcdU2 as Unsigned>::to_u64(), <U2 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Sub_2() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U2 = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U4SubU2 = <<A as Sub<B>>::Output as Same<U2>>::Output;

    assert_eq!(<U4SubU2 as Unsigned>::to_u64(), <U2 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Div_2() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U2 = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U4DivU2 = <<A as Div<B>>::Output as Same<U2>>::Output;

    assert_eq!(<U4DivU2 as Unsigned>::to_u64(), <U2 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Rem_2() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U4RemU2 = <<A as Rem<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U4RemU2 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_PartialDiv_2() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U2 = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U4PartialDivU2 = <<A as PartialDiv<B>>::Output as Same<U2>>::Output;

    assert_eq!(<U4PartialDivU2 as Unsigned>::to_u64(), <U2 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Cmp_2() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U4CmpU2 = <A as Cmp<B>>::Output;
    assert_eq!(<U4CmpU2 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_4_BitAnd_3() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U4BitAndU3 = <<A as BitAnd<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U4BitAndU3 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_BitOr_3() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U7 = UInt<UInt<UInt<UTerm, B1>, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U4BitOrU3 = <<A as BitOr<B>>::Output as Same<U7>>::Output;

    assert_eq!(<U4BitOrU3 as Unsigned>::to_u64(), <U7 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_BitXor_3() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U7 = UInt<UInt<UInt<UTerm, B1>, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U4BitXorU3 = <<A as BitXor<B>>::Output as Same<U7>>::Output;

    assert_eq!(<U4BitXorU3 as Unsigned>::to_u64(), <U7 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Shl_3() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U32 = UInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U4ShlU3 = <<A as Shl<B>>::Output as Same<U32>>::Output;

    assert_eq!(<U4ShlU3 as Unsigned>::to_u64(), <U32 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Shr_3() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U4ShrU3 = <<A as Shr<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U4ShrU3 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Add_3() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U7 = UInt<UInt<UInt<UTerm, B1>, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U4AddU3 = <<A as Add<B>>::Output as Same<U7>>::Output;

    assert_eq!(<U4AddU3 as Unsigned>::to_u64(), <U7 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Mul_3() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U12 = UInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U4MulU3 = <<A as Mul<B>>::Output as Same<U12>>::Output;

    assert_eq!(<U4MulU3 as Unsigned>::to_u64(), <U12 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Pow_3() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U64 = UInt<UInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>, B0>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U4PowU3 = <<A as Pow<B>>::Output as Same<U64>>::Output;

    assert_eq!(<U4PowU3 as Unsigned>::to_u64(), <U64 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Min_3() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U3 = UInt<UInt<UTerm, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U4MinU3 = <<A as Min<B>>::Output as Same<U3>>::Output;

    assert_eq!(<U4MinU3 as Unsigned>::to_u64(), <U3 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Max_3() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U4 = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U4MaxU3 = <<A as Max<B>>::Output as Same<U4>>::Output;

    assert_eq!(<U4MaxU3 as Unsigned>::to_u64(), <U4 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Gcd_3() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U4GcdU3 = <<A as Gcd<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U4GcdU3 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Sub_3() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U4SubU3 = <<A as Sub<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U4SubU3 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Div_3() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U4DivU3 = <<A as Div<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U4DivU3 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Rem_3() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U4RemU3 = <<A as Rem<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U4RemU3 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Cmp_3() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UTerm, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U4CmpU3 = <A as Cmp<B>>::Output;
    assert_eq!(<U4CmpU3 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_4_BitAnd_4() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U4 = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U4BitAndU4 = <<A as BitAnd<B>>::Output as Same<U4>>::Output;

    assert_eq!(<U4BitAndU4 as Unsigned>::to_u64(), <U4 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_BitOr_4() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U4 = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U4BitOrU4 = <<A as BitOr<B>>::Output as Same<U4>>::Output;

    assert_eq!(<U4BitOrU4 as Unsigned>::to_u64(), <U4 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_BitXor_4() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U4BitXorU4 = <<A as BitXor<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U4BitXorU4 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Shl_4() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U64 = UInt<UInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>, B0>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U4ShlU4 = <<A as Shl<B>>::Output as Same<U64>>::Output;

    assert_eq!(<U4ShlU4 as Unsigned>::to_u64(), <U64 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Shr_4() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U4ShrU4 = <<A as Shr<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U4ShrU4 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Add_4() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U8 = UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U4AddU4 = <<A as Add<B>>::Output as Same<U8>>::Output;

    assert_eq!(<U4AddU4 as Unsigned>::to_u64(), <U8 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Mul_4() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U16 = UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U4MulU4 = <<A as Mul<B>>::Output as Same<U16>>::Output;

    assert_eq!(<U4MulU4 as Unsigned>::to_u64(), <U16 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Pow_4() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U256 = UInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>, B0>, B0>, B0>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U4PowU4 = <<A as Pow<B>>::Output as Same<U256>>::Output;

    assert_eq!(<U4PowU4 as Unsigned>::to_u64(), <U256 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Min_4() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U4 = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U4MinU4 = <<A as Min<B>>::Output as Same<U4>>::Output;

    assert_eq!(<U4MinU4 as Unsigned>::to_u64(), <U4 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Max_4() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U4 = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U4MaxU4 = <<A as Max<B>>::Output as Same<U4>>::Output;

    assert_eq!(<U4MaxU4 as Unsigned>::to_u64(), <U4 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Gcd_4() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U4 = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U4GcdU4 = <<A as Gcd<B>>::Output as Same<U4>>::Output;

    assert_eq!(<U4GcdU4 as Unsigned>::to_u64(), <U4 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Sub_4() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U4SubU4 = <<A as Sub<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U4SubU4 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Div_4() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U4DivU4 = <<A as Div<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U4DivU4 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Rem_4() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U4RemU4 = <<A as Rem<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U4RemU4 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_PartialDiv_4() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U4PartialDivU4 = <<A as PartialDiv<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U4PartialDivU4 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Cmp_4() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U4CmpU4 = <A as Cmp<B>>::Output;
    assert_eq!(<U4CmpU4 as Ord>::to_ordering(), Ordering::Equal);
}
#[test]
#[allow(non_snake_case)]
fn test_4_BitAnd_5() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U4 = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U4BitAndU5 = <<A as BitAnd<B>>::Output as Same<U4>>::Output;

    assert_eq!(<U4BitAndU5 as Unsigned>::to_u64(), <U4 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_BitOr_5() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U5 = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U4BitOrU5 = <<A as BitOr<B>>::Output as Same<U5>>::Output;

    assert_eq!(<U4BitOrU5 as Unsigned>::to_u64(), <U5 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_BitXor_5() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U4BitXorU5 = <<A as BitXor<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U4BitXorU5 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Shl_5() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U128 = UInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>, B0>, B0>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U4ShlU5 = <<A as Shl<B>>::Output as Same<U128>>::Output;

    assert_eq!(<U4ShlU5 as Unsigned>::to_u64(), <U128 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Shr_5() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U4ShrU5 = <<A as Shr<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U4ShrU5 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Add_5() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U9 = UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U4AddU5 = <<A as Add<B>>::Output as Same<U9>>::Output;

    assert_eq!(<U4AddU5 as Unsigned>::to_u64(), <U9 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Mul_5() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U20 = UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U4MulU5 = <<A as Mul<B>>::Output as Same<U20>>::Output;

    assert_eq!(<U4MulU5 as Unsigned>::to_u64(), <U20 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Pow_5() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U1024 = UInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>, B0>, B0>, B0>, B0>, B0>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U4PowU5 = <<A as Pow<B>>::Output as Same<U1024>>::Output;

    assert_eq!(<U4PowU5 as Unsigned>::to_u64(), <U1024 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Min_5() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U4 = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U4MinU5 = <<A as Min<B>>::Output as Same<U4>>::Output;

    assert_eq!(<U4MinU5 as Unsigned>::to_u64(), <U4 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Max_5() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U5 = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U4MaxU5 = <<A as Max<B>>::Output as Same<U5>>::Output;

    assert_eq!(<U4MaxU5 as Unsigned>::to_u64(), <U5 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Gcd_5() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U4GcdU5 = <<A as Gcd<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U4GcdU5 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Div_5() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U4DivU5 = <<A as Div<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U4DivU5 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Rem_5() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U4 = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U4RemU5 = <<A as Rem<B>>::Output as Same<U4>>::Output;

    assert_eq!(<U4RemU5 as Unsigned>::to_u64(), <U4 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_4_Cmp_5() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U4CmpU5 = <A as Cmp<B>>::Output;
    assert_eq!(<U4CmpU5 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_5_BitAnd_0() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UTerm;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U5BitAndU0 = <<A as BitAnd<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U5BitAndU0 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_BitOr_0() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UTerm;
    type U5 = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U5BitOrU0 = <<A as BitOr<B>>::Output as Same<U5>>::Output;

    assert_eq!(<U5BitOrU0 as Unsigned>::to_u64(), <U5 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_BitXor_0() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UTerm;
    type U5 = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U5BitXorU0 = <<A as BitXor<B>>::Output as Same<U5>>::Output;

    assert_eq!(<U5BitXorU0 as Unsigned>::to_u64(), <U5 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Shl_0() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UTerm;
    type U5 = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U5ShlU0 = <<A as Shl<B>>::Output as Same<U5>>::Output;

    assert_eq!(<U5ShlU0 as Unsigned>::to_u64(), <U5 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Shr_0() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UTerm;
    type U5 = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U5ShrU0 = <<A as Shr<B>>::Output as Same<U5>>::Output;

    assert_eq!(<U5ShrU0 as Unsigned>::to_u64(), <U5 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Add_0() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UTerm;
    type U5 = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U5AddU0 = <<A as Add<B>>::Output as Same<U5>>::Output;

    assert_eq!(<U5AddU0 as Unsigned>::to_u64(), <U5 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Mul_0() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UTerm;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U5MulU0 = <<A as Mul<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U5MulU0 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Pow_0() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UTerm;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U5PowU0 = <<A as Pow<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U5PowU0 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Min_0() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UTerm;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U5MinU0 = <<A as Min<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U5MinU0 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Max_0() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UTerm;
    type U5 = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U5MaxU0 = <<A as Max<B>>::Output as Same<U5>>::Output;

    assert_eq!(<U5MaxU0 as Unsigned>::to_u64(), <U5 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Gcd_0() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UTerm;
    type U5 = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U5GcdU0 = <<A as Gcd<B>>::Output as Same<U5>>::Output;

    assert_eq!(<U5GcdU0 as Unsigned>::to_u64(), <U5 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Sub_0() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UTerm;
    type U5 = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U5SubU0 = <<A as Sub<B>>::Output as Same<U5>>::Output;

    assert_eq!(<U5SubU0 as Unsigned>::to_u64(), <U5 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Cmp_0() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UTerm;

    #[allow(non_camel_case_types)]
    type U5CmpU0 = <A as Cmp<B>>::Output;
    assert_eq!(<U5CmpU0 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_5_BitAnd_1() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UTerm, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U5BitAndU1 = <<A as BitAnd<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U5BitAndU1 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_BitOr_1() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UTerm, B1>;
    type U5 = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U5BitOrU1 = <<A as BitOr<B>>::Output as Same<U5>>::Output;

    assert_eq!(<U5BitOrU1 as Unsigned>::to_u64(), <U5 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_BitXor_1() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UTerm, B1>;
    type U4 = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U5BitXorU1 = <<A as BitXor<B>>::Output as Same<U4>>::Output;

    assert_eq!(<U5BitXorU1 as Unsigned>::to_u64(), <U4 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Shl_1() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UTerm, B1>;
    type U10 = UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U5ShlU1 = <<A as Shl<B>>::Output as Same<U10>>::Output;

    assert_eq!(<U5ShlU1 as Unsigned>::to_u64(), <U10 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Shr_1() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UTerm, B1>;
    type U2 = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U5ShrU1 = <<A as Shr<B>>::Output as Same<U2>>::Output;

    assert_eq!(<U5ShrU1 as Unsigned>::to_u64(), <U2 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Add_1() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UTerm, B1>;
    type U6 = UInt<UInt<UInt<UTerm, B1>, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U5AddU1 = <<A as Add<B>>::Output as Same<U6>>::Output;

    assert_eq!(<U5AddU1 as Unsigned>::to_u64(), <U6 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Mul_1() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UTerm, B1>;
    type U5 = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U5MulU1 = <<A as Mul<B>>::Output as Same<U5>>::Output;

    assert_eq!(<U5MulU1 as Unsigned>::to_u64(), <U5 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Pow_1() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UTerm, B1>;
    type U5 = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U5PowU1 = <<A as Pow<B>>::Output as Same<U5>>::Output;

    assert_eq!(<U5PowU1 as Unsigned>::to_u64(), <U5 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Min_1() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UTerm, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U5MinU1 = <<A as Min<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U5MinU1 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Max_1() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UTerm, B1>;
    type U5 = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U5MaxU1 = <<A as Max<B>>::Output as Same<U5>>::Output;

    assert_eq!(<U5MaxU1 as Unsigned>::to_u64(), <U5 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Gcd_1() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UTerm, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U5GcdU1 = <<A as Gcd<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U5GcdU1 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Sub_1() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UTerm, B1>;
    type U4 = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U5SubU1 = <<A as Sub<B>>::Output as Same<U4>>::Output;

    assert_eq!(<U5SubU1 as Unsigned>::to_u64(), <U4 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Div_1() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UTerm, B1>;
    type U5 = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U5DivU1 = <<A as Div<B>>::Output as Same<U5>>::Output;

    assert_eq!(<U5DivU1 as Unsigned>::to_u64(), <U5 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Rem_1() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UTerm, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U5RemU1 = <<A as Rem<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U5RemU1 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_PartialDiv_1() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UTerm, B1>;
    type U5 = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U5PartialDivU1 = <<A as PartialDiv<B>>::Output as Same<U5>>::Output;

    assert_eq!(<U5PartialDivU1 as Unsigned>::to_u64(), <U5 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Cmp_1() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U5CmpU1 = <A as Cmp<B>>::Output;
    assert_eq!(<U5CmpU1 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_5_BitAnd_2() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U5BitAndU2 = <<A as BitAnd<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U5BitAndU2 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_BitOr_2() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U7 = UInt<UInt<UInt<UTerm, B1>, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U5BitOrU2 = <<A as BitOr<B>>::Output as Same<U7>>::Output;

    assert_eq!(<U5BitOrU2 as Unsigned>::to_u64(), <U7 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_BitXor_2() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U7 = UInt<UInt<UInt<UTerm, B1>, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U5BitXorU2 = <<A as BitXor<B>>::Output as Same<U7>>::Output;

    assert_eq!(<U5BitXorU2 as Unsigned>::to_u64(), <U7 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Shl_2() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U20 = UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U5ShlU2 = <<A as Shl<B>>::Output as Same<U20>>::Output;

    assert_eq!(<U5ShlU2 as Unsigned>::to_u64(), <U20 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Shr_2() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U5ShrU2 = <<A as Shr<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U5ShrU2 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Add_2() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U7 = UInt<UInt<UInt<UTerm, B1>, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U5AddU2 = <<A as Add<B>>::Output as Same<U7>>::Output;

    assert_eq!(<U5AddU2 as Unsigned>::to_u64(), <U7 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Mul_2() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U10 = UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U5MulU2 = <<A as Mul<B>>::Output as Same<U10>>::Output;

    assert_eq!(<U5MulU2 as Unsigned>::to_u64(), <U10 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Pow_2() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U25 = UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U5PowU2 = <<A as Pow<B>>::Output as Same<U25>>::Output;

    assert_eq!(<U5PowU2 as Unsigned>::to_u64(), <U25 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Min_2() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U2 = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U5MinU2 = <<A as Min<B>>::Output as Same<U2>>::Output;

    assert_eq!(<U5MinU2 as Unsigned>::to_u64(), <U2 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Max_2() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U5 = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U5MaxU2 = <<A as Max<B>>::Output as Same<U5>>::Output;

    assert_eq!(<U5MaxU2 as Unsigned>::to_u64(), <U5 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Gcd_2() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U5GcdU2 = <<A as Gcd<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U5GcdU2 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Sub_2() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U3 = UInt<UInt<UTerm, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U5SubU2 = <<A as Sub<B>>::Output as Same<U3>>::Output;

    assert_eq!(<U5SubU2 as Unsigned>::to_u64(), <U3 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Div_2() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U2 = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U5DivU2 = <<A as Div<B>>::Output as Same<U2>>::Output;

    assert_eq!(<U5DivU2 as Unsigned>::to_u64(), <U2 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Rem_2() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UTerm, B1>, B0>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U5RemU2 = <<A as Rem<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U5RemU2 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Cmp_2() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U5CmpU2 = <A as Cmp<B>>::Output;
    assert_eq!(<U5CmpU2 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_5_BitAnd_3() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U5BitAndU3 = <<A as BitAnd<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U5BitAndU3 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_BitOr_3() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U7 = UInt<UInt<UInt<UTerm, B1>, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U5BitOrU3 = <<A as BitOr<B>>::Output as Same<U7>>::Output;

    assert_eq!(<U5BitOrU3 as Unsigned>::to_u64(), <U7 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_BitXor_3() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U6 = UInt<UInt<UInt<UTerm, B1>, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U5BitXorU3 = <<A as BitXor<B>>::Output as Same<U6>>::Output;

    assert_eq!(<U5BitXorU3 as Unsigned>::to_u64(), <U6 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Shl_3() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U40 = UInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>, B0>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U5ShlU3 = <<A as Shl<B>>::Output as Same<U40>>::Output;

    assert_eq!(<U5ShlU3 as Unsigned>::to_u64(), <U40 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Shr_3() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U5ShrU3 = <<A as Shr<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U5ShrU3 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Add_3() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U8 = UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U5AddU3 = <<A as Add<B>>::Output as Same<U8>>::Output;

    assert_eq!(<U5AddU3 as Unsigned>::to_u64(), <U8 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Mul_3() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U15 = UInt<UInt<UInt<UInt<UTerm, B1>, B1>, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U5MulU3 = <<A as Mul<B>>::Output as Same<U15>>::Output;

    assert_eq!(<U5MulU3 as Unsigned>::to_u64(), <U15 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Pow_3() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U125 = UInt<UInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B1>, B1>, B1>, B1>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U5PowU3 = <<A as Pow<B>>::Output as Same<U125>>::Output;

    assert_eq!(<U5PowU3 as Unsigned>::to_u64(), <U125 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Min_3() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U3 = UInt<UInt<UTerm, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U5MinU3 = <<A as Min<B>>::Output as Same<U3>>::Output;

    assert_eq!(<U5MinU3 as Unsigned>::to_u64(), <U3 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Max_3() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U5 = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U5MaxU3 = <<A as Max<B>>::Output as Same<U5>>::Output;

    assert_eq!(<U5MaxU3 as Unsigned>::to_u64(), <U5 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Gcd_3() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U5GcdU3 = <<A as Gcd<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U5GcdU3 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Sub_3() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U2 = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U5SubU3 = <<A as Sub<B>>::Output as Same<U2>>::Output;

    assert_eq!(<U5SubU3 as Unsigned>::to_u64(), <U2 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Div_3() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U5DivU3 = <<A as Div<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U5DivU3 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Rem_3() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UTerm, B1>, B1>;
    type U2 = UInt<UInt<UTerm, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U5RemU3 = <<A as Rem<B>>::Output as Same<U2>>::Output;

    assert_eq!(<U5RemU3 as Unsigned>::to_u64(), <U2 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Cmp_3() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UTerm, B1>, B1>;

    #[allow(non_camel_case_types)]
    type U5CmpU3 = <A as Cmp<B>>::Output;
    assert_eq!(<U5CmpU3 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_5_BitAnd_4() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U4 = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U5BitAndU4 = <<A as BitAnd<B>>::Output as Same<U4>>::Output;

    assert_eq!(<U5BitAndU4 as Unsigned>::to_u64(), <U4 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_BitOr_4() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U5 = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U5BitOrU4 = <<A as BitOr<B>>::Output as Same<U5>>::Output;

    assert_eq!(<U5BitOrU4 as Unsigned>::to_u64(), <U5 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_BitXor_4() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U5BitXorU4 = <<A as BitXor<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U5BitXorU4 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Shl_4() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U80 = UInt<UInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>, B0>, B0>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U5ShlU4 = <<A as Shl<B>>::Output as Same<U80>>::Output;

    assert_eq!(<U5ShlU4 as Unsigned>::to_u64(), <U80 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Shr_4() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U5ShrU4 = <<A as Shr<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U5ShrU4 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Add_4() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U9 = UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U5AddU4 = <<A as Add<B>>::Output as Same<U9>>::Output;

    assert_eq!(<U5AddU4 as Unsigned>::to_u64(), <U9 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Mul_4() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U20 = UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U5MulU4 = <<A as Mul<B>>::Output as Same<U20>>::Output;

    assert_eq!(<U5MulU4 as Unsigned>::to_u64(), <U20 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Pow_4() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U625 = UInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B1>, B1>, B1>, B0>, B0>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U5PowU4 = <<A as Pow<B>>::Output as Same<U625>>::Output;

    assert_eq!(<U5PowU4 as Unsigned>::to_u64(), <U625 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Min_4() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U4 = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U5MinU4 = <<A as Min<B>>::Output as Same<U4>>::Output;

    assert_eq!(<U5MinU4 as Unsigned>::to_u64(), <U4 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Max_4() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U5 = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U5MaxU4 = <<A as Max<B>>::Output as Same<U5>>::Output;

    assert_eq!(<U5MaxU4 as Unsigned>::to_u64(), <U5 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Gcd_4() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U5GcdU4 = <<A as Gcd<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U5GcdU4 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Sub_4() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U5SubU4 = <<A as Sub<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U5SubU4 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Div_4() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U5DivU4 = <<A as Div<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U5DivU4 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Rem_4() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U5RemU4 = <<A as Rem<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U5RemU4 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Cmp_4() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U5CmpU4 = <A as Cmp<B>>::Output;
    assert_eq!(<U5CmpU4 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_5_BitAnd_5() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U5 = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U5BitAndU5 = <<A as BitAnd<B>>::Output as Same<U5>>::Output;

    assert_eq!(<U5BitAndU5 as Unsigned>::to_u64(), <U5 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_BitOr_5() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U5 = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U5BitOrU5 = <<A as BitOr<B>>::Output as Same<U5>>::Output;

    assert_eq!(<U5BitOrU5 as Unsigned>::to_u64(), <U5 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_BitXor_5() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U5BitXorU5 = <<A as BitXor<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U5BitXorU5 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Shl_5() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U160 = UInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>, B0>, B0>, B0>, B0>, B0>;

    #[allow(non_camel_case_types)]
    type U5ShlU5 = <<A as Shl<B>>::Output as Same<U160>>::Output;

    assert_eq!(<U5ShlU5 as Unsigned>::to_u64(), <U160 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Shr_5() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U5ShrU5 = <<A as Shr<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U5ShrU5 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Add_5() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U10 = UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>, B0>;

    #[allow(non_camel_case_types)]
    type U5AddU5 = <<A as Add<B>>::Output as Same<U10>>::Output;

    assert_eq!(<U5AddU5 as Unsigned>::to_u64(), <U10 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Mul_5() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U25 = UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U5MulU5 = <<A as Mul<B>>::Output as Same<U25>>::Output;

    assert_eq!(<U5MulU5 as Unsigned>::to_u64(), <U25 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Pow_5() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U3125 = UInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>, B0>, B0>, B0>, B1>, B1>, B0>, B1>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U5PowU5 = <<A as Pow<B>>::Output as Same<U3125>>::Output;

    assert_eq!(<U5PowU5 as Unsigned>::to_u64(), <U3125 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Min_5() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U5 = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U5MinU5 = <<A as Min<B>>::Output as Same<U5>>::Output;

    assert_eq!(<U5MinU5 as Unsigned>::to_u64(), <U5 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Max_5() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U5 = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U5MaxU5 = <<A as Max<B>>::Output as Same<U5>>::Output;

    assert_eq!(<U5MaxU5 as Unsigned>::to_u64(), <U5 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Gcd_5() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U5 = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U5GcdU5 = <<A as Gcd<B>>::Output as Same<U5>>::Output;

    assert_eq!(<U5GcdU5 as Unsigned>::to_u64(), <U5 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Sub_5() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U5SubU5 = <<A as Sub<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U5SubU5 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Div_5() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U5DivU5 = <<A as Div<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U5DivU5 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Rem_5() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U0 = UTerm;

    #[allow(non_camel_case_types)]
    type U5RemU5 = <<A as Rem<B>>::Output as Same<U0>>::Output;

    assert_eq!(<U5RemU5 as Unsigned>::to_u64(), <U0 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_PartialDiv_5() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type U1 = UInt<UTerm, B1>;

    #[allow(non_camel_case_types)]
    type U5PartialDivU5 = <<A as PartialDiv<B>>::Output as Same<U1>>::Output;

    assert_eq!(<U5PartialDivU5 as Unsigned>::to_u64(), <U1 as Unsigned>::to_u64());
}
#[test]
#[allow(non_snake_case)]
fn test_5_Cmp_5() {
    type A = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;
    type B = UInt<UInt<UInt<UTerm, B1>, B0>, B1>;

    #[allow(non_camel_case_types)]
    type U5CmpU5 = <A as Cmp<B>>::Output;
    assert_eq!(<U5CmpU5 as Ord>::to_ordering(), Ordering::Equal);
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Add_N5() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N10 = NInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N5AddN5 = <<A as Add<B>>::Output as Same<N10>>::Output;

    assert_eq!(<N5AddN5 as Integer>::to_i64(), <N10 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Sub_N5() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N5SubN5 = <<A as Sub<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N5SubN5 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Mul_N5() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P25 = PInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N5MulN5 = <<A as Mul<B>>::Output as Same<P25>>::Output;

    assert_eq!(<N5MulN5 as Integer>::to_i64(), <P25 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Min_N5() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N5 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N5MinN5 = <<A as Min<B>>::Output as Same<N5>>::Output;

    assert_eq!(<N5MinN5 as Integer>::to_i64(), <N5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Max_N5() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N5 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N5MaxN5 = <<A as Max<B>>::Output as Same<N5>>::Output;

    assert_eq!(<N5MaxN5 as Integer>::to_i64(), <N5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Gcd_N5() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N5GcdN5 = <<A as Gcd<B>>::Output as Same<P5>>::Output;

    assert_eq!(<N5GcdN5 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Div_N5() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N5DivN5 = <<A as Div<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N5DivN5 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Rem_N5() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N5RemN5 = <<A as Rem<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N5RemN5 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_PartialDiv_N5() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N5PartialDivN5 = <<A as PartialDiv<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N5PartialDivN5 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Cmp_N5() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N5CmpN5 = <A as Cmp<B>>::Output;
    assert_eq!(<N5CmpN5 as Ord>::to_ordering(), Ordering::Equal);
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Add_N4() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N9 = NInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N5AddN4 = <<A as Add<B>>::Output as Same<N9>>::Output;

    assert_eq!(<N5AddN4 as Integer>::to_i64(), <N9 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Sub_N4() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N5SubN4 = <<A as Sub<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N5SubN4 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Mul_N4() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P20 = PInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N5MulN4 = <<A as Mul<B>>::Output as Same<P20>>::Output;

    assert_eq!(<N5MulN4 as Integer>::to_i64(), <P20 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Min_N4() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N5 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N5MinN4 = <<A as Min<B>>::Output as Same<N5>>::Output;

    assert_eq!(<N5MinN4 as Integer>::to_i64(), <N5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Max_N4() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N4 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N5MaxN4 = <<A as Max<B>>::Output as Same<N4>>::Output;

    assert_eq!(<N5MaxN4 as Integer>::to_i64(), <N4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Gcd_N4() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N5GcdN4 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N5GcdN4 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Div_N4() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N5DivN4 = <<A as Div<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N5DivN4 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Rem_N4() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N5RemN4 = <<A as Rem<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N5RemN4 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Cmp_N4() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N5CmpN4 = <A as Cmp<B>>::Output;
    assert_eq!(<N5CmpN4 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Add_N3() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type N8 = NInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N5AddN3 = <<A as Add<B>>::Output as Same<N8>>::Output;

    assert_eq!(<N5AddN3 as Integer>::to_i64(), <N8 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Sub_N3() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N5SubN3 = <<A as Sub<B>>::Output as Same<N2>>::Output;

    assert_eq!(<N5SubN3 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Mul_N3() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type P15 = PInt<UInt<UInt<UInt<UInt<UTerm, B1>, B1>, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N5MulN3 = <<A as Mul<B>>::Output as Same<P15>>::Output;

    assert_eq!(<N5MulN3 as Integer>::to_i64(), <P15 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Min_N3() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type N5 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N5MinN3 = <<A as Min<B>>::Output as Same<N5>>::Output;

    assert_eq!(<N5MinN3 as Integer>::to_i64(), <N5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Max_N3() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type N3 = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N5MaxN3 = <<A as Max<B>>::Output as Same<N3>>::Output;

    assert_eq!(<N5MaxN3 as Integer>::to_i64(), <N3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Gcd_N3() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N5GcdN3 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N5GcdN3 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Div_N3() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N5DivN3 = <<A as Div<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N5DivN3 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Rem_N3() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N5RemN3 = <<A as Rem<B>>::Output as Same<N2>>::Output;

    assert_eq!(<N5RemN3 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Cmp_N3() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N5CmpN3 = <A as Cmp<B>>::Output;
    assert_eq!(<N5CmpN3 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Add_N2() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type N7 = NInt<UInt<UInt<UInt<UTerm, B1>, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N5AddN2 = <<A as Add<B>>::Output as Same<N7>>::Output;

    assert_eq!(<N5AddN2 as Integer>::to_i64(), <N7 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Sub_N2() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type N3 = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N5SubN2 = <<A as Sub<B>>::Output as Same<N3>>::Output;

    assert_eq!(<N5SubN2 as Integer>::to_i64(), <N3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Mul_N2() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type P10 = PInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N5MulN2 = <<A as Mul<B>>::Output as Same<P10>>::Output;

    assert_eq!(<N5MulN2 as Integer>::to_i64(), <P10 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Min_N2() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type N5 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N5MinN2 = <<A as Min<B>>::Output as Same<N5>>::Output;

    assert_eq!(<N5MinN2 as Integer>::to_i64(), <N5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Max_N2() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N5MaxN2 = <<A as Max<B>>::Output as Same<N2>>::Output;

    assert_eq!(<N5MaxN2 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Gcd_N2() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N5GcdN2 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N5GcdN2 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Div_N2() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N5DivN2 = <<A as Div<B>>::Output as Same<P2>>::Output;

    assert_eq!(<N5DivN2 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Rem_N2() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N5RemN2 = <<A as Rem<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N5RemN2 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Cmp_N2() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N5CmpN2 = <A as Cmp<B>>::Output;
    assert_eq!(<N5CmpN2 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Add_N1() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type N6 = NInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N5AddN1 = <<A as Add<B>>::Output as Same<N6>>::Output;

    assert_eq!(<N5AddN1 as Integer>::to_i64(), <N6 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Sub_N1() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type N4 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N5SubN1 = <<A as Sub<B>>::Output as Same<N4>>::Output;

    assert_eq!(<N5SubN1 as Integer>::to_i64(), <N4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Mul_N1() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N5MulN1 = <<A as Mul<B>>::Output as Same<P5>>::Output;

    assert_eq!(<N5MulN1 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Min_N1() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type N5 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N5MinN1 = <<A as Min<B>>::Output as Same<N5>>::Output;

    assert_eq!(<N5MinN1 as Integer>::to_i64(), <N5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Max_N1() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N5MaxN1 = <<A as Max<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N5MaxN1 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Gcd_N1() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N5GcdN1 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N5GcdN1 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Div_N1() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N5DivN1 = <<A as Div<B>>::Output as Same<P5>>::Output;

    assert_eq!(<N5DivN1 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Rem_N1() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N5RemN1 = <<A as Rem<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N5RemN1 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_PartialDiv_N1() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N5PartialDivN1 = <<A as PartialDiv<B>>::Output as Same<P5>>::Output;

    assert_eq!(<N5PartialDivN1 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Cmp_N1() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N5CmpN1 = <A as Cmp<B>>::Output;
    assert_eq!(<N5CmpN1 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Add__0() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = Z0;
    type N5 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N5Add_0 = <<A as Add<B>>::Output as Same<N5>>::Output;

    assert_eq!(<N5Add_0 as Integer>::to_i64(), <N5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Sub__0() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = Z0;
    type N5 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N5Sub_0 = <<A as Sub<B>>::Output as Same<N5>>::Output;

    assert_eq!(<N5Sub_0 as Integer>::to_i64(), <N5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Mul__0() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = Z0;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N5Mul_0 = <<A as Mul<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N5Mul_0 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Min__0() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = Z0;
    type N5 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N5Min_0 = <<A as Min<B>>::Output as Same<N5>>::Output;

    assert_eq!(<N5Min_0 as Integer>::to_i64(), <N5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Max__0() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = Z0;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N5Max_0 = <<A as Max<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N5Max_0 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Gcd__0() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = Z0;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N5Gcd_0 = <<A as Gcd<B>>::Output as Same<P5>>::Output;

    assert_eq!(<N5Gcd_0 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Pow__0() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = Z0;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N5Pow_0 = <<A as Pow<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N5Pow_0 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Cmp__0() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = Z0;

    #[allow(non_camel_case_types)]
    type N5Cmp_0 = <A as Cmp<B>>::Output;
    assert_eq!(<N5Cmp_0 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Add_P1() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type N4 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N5AddP1 = <<A as Add<B>>::Output as Same<N4>>::Output;

    assert_eq!(<N5AddP1 as Integer>::to_i64(), <N4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Sub_P1() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type N6 = NInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N5SubP1 = <<A as Sub<B>>::Output as Same<N6>>::Output;

    assert_eq!(<N5SubP1 as Integer>::to_i64(), <N6 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Mul_P1() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type N5 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N5MulP1 = <<A as Mul<B>>::Output as Same<N5>>::Output;

    assert_eq!(<N5MulP1 as Integer>::to_i64(), <N5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Min_P1() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type N5 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N5MinP1 = <<A as Min<B>>::Output as Same<N5>>::Output;

    assert_eq!(<N5MinP1 as Integer>::to_i64(), <N5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Max_P1() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N5MaxP1 = <<A as Max<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N5MaxP1 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Gcd_P1() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N5GcdP1 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N5GcdP1 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Div_P1() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type N5 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N5DivP1 = <<A as Div<B>>::Output as Same<N5>>::Output;

    assert_eq!(<N5DivP1 as Integer>::to_i64(), <N5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Rem_P1() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N5RemP1 = <<A as Rem<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N5RemP1 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_PartialDiv_P1() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type N5 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N5PartialDivP1 = <<A as PartialDiv<B>>::Output as Same<N5>>::Output;

    assert_eq!(<N5PartialDivP1 as Integer>::to_i64(), <N5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Pow_P1() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type N5 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N5PowP1 = <<A as Pow<B>>::Output as Same<N5>>::Output;

    assert_eq!(<N5PowP1 as Integer>::to_i64(), <N5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Cmp_P1() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N5CmpP1 = <A as Cmp<B>>::Output;
    assert_eq!(<N5CmpP1 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Add_P2() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type N3 = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N5AddP2 = <<A as Add<B>>::Output as Same<N3>>::Output;

    assert_eq!(<N5AddP2 as Integer>::to_i64(), <N3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Sub_P2() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type N7 = NInt<UInt<UInt<UInt<UTerm, B1>, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N5SubP2 = <<A as Sub<B>>::Output as Same<N7>>::Output;

    assert_eq!(<N5SubP2 as Integer>::to_i64(), <N7 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Mul_P2() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type N10 = NInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N5MulP2 = <<A as Mul<B>>::Output as Same<N10>>::Output;

    assert_eq!(<N5MulP2 as Integer>::to_i64(), <N10 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Min_P2() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type N5 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N5MinP2 = <<A as Min<B>>::Output as Same<N5>>::Output;

    assert_eq!(<N5MinP2 as Integer>::to_i64(), <N5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Max_P2() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N5MaxP2 = <<A as Max<B>>::Output as Same<P2>>::Output;

    assert_eq!(<N5MaxP2 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Gcd_P2() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N5GcdP2 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N5GcdP2 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Div_P2() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N5DivP2 = <<A as Div<B>>::Output as Same<N2>>::Output;

    assert_eq!(<N5DivP2 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Rem_P2() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N5RemP2 = <<A as Rem<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N5RemP2 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Pow_P2() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P25 = PInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N5PowP2 = <<A as Pow<B>>::Output as Same<P25>>::Output;

    assert_eq!(<N5PowP2 as Integer>::to_i64(), <P25 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Cmp_P2() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N5CmpP2 = <A as Cmp<B>>::Output;
    assert_eq!(<N5CmpP2 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Add_P3() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N5AddP3 = <<A as Add<B>>::Output as Same<N2>>::Output;

    assert_eq!(<N5AddP3 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Sub_P3() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type N8 = NInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N5SubP3 = <<A as Sub<B>>::Output as Same<N8>>::Output;

    assert_eq!(<N5SubP3 as Integer>::to_i64(), <N8 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Mul_P3() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type N15 = NInt<UInt<UInt<UInt<UInt<UTerm, B1>, B1>, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N5MulP3 = <<A as Mul<B>>::Output as Same<N15>>::Output;

    assert_eq!(<N5MulP3 as Integer>::to_i64(), <N15 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Min_P3() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type N5 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N5MinP3 = <<A as Min<B>>::Output as Same<N5>>::Output;

    assert_eq!(<N5MinP3 as Integer>::to_i64(), <N5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Max_P3() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N5MaxP3 = <<A as Max<B>>::Output as Same<P3>>::Output;

    assert_eq!(<N5MaxP3 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Gcd_P3() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N5GcdP3 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N5GcdP3 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Div_P3() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N5DivP3 = <<A as Div<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N5DivP3 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Rem_P3() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N5RemP3 = <<A as Rem<B>>::Output as Same<N2>>::Output;

    assert_eq!(<N5RemP3 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Pow_P3() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type N125 = NInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B1>, B1>, B1>, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N5PowP3 = <<A as Pow<B>>::Output as Same<N125>>::Output;

    assert_eq!(<N5PowP3 as Integer>::to_i64(), <N125 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Cmp_P3() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N5CmpP3 = <A as Cmp<B>>::Output;
    assert_eq!(<N5CmpP3 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Add_P4() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N5AddP4 = <<A as Add<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N5AddP4 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Sub_P4() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N9 = NInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N5SubP4 = <<A as Sub<B>>::Output as Same<N9>>::Output;

    assert_eq!(<N5SubP4 as Integer>::to_i64(), <N9 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Mul_P4() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N20 = NInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N5MulP4 = <<A as Mul<B>>::Output as Same<N20>>::Output;

    assert_eq!(<N5MulP4 as Integer>::to_i64(), <N20 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Min_P4() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N5 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N5MinP4 = <<A as Min<B>>::Output as Same<N5>>::Output;

    assert_eq!(<N5MinP4 as Integer>::to_i64(), <N5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Max_P4() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N5MaxP4 = <<A as Max<B>>::Output as Same<P4>>::Output;

    assert_eq!(<N5MaxP4 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Gcd_P4() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N5GcdP4 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N5GcdP4 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Div_P4() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N5DivP4 = <<A as Div<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N5DivP4 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Rem_P4() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N5RemP4 = <<A as Rem<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N5RemP4 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Pow_P4() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P625 = PInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B1>, B1>, B1>, B0>, B0>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N5PowP4 = <<A as Pow<B>>::Output as Same<P625>>::Output;

    assert_eq!(<N5PowP4 as Integer>::to_i64(), <P625 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Cmp_P4() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N5CmpP4 = <A as Cmp<B>>::Output;
    assert_eq!(<N5CmpP4 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Add_P5() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N5AddP5 = <<A as Add<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N5AddP5 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Sub_P5() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N10 = NInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N5SubP5 = <<A as Sub<B>>::Output as Same<N10>>::Output;

    assert_eq!(<N5SubP5 as Integer>::to_i64(), <N10 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Mul_P5() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N25 = NInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N5MulP5 = <<A as Mul<B>>::Output as Same<N25>>::Output;

    assert_eq!(<N5MulP5 as Integer>::to_i64(), <N25 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Min_P5() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N5 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N5MinP5 = <<A as Min<B>>::Output as Same<N5>>::Output;

    assert_eq!(<N5MinP5 as Integer>::to_i64(), <N5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Max_P5() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N5MaxP5 = <<A as Max<B>>::Output as Same<P5>>::Output;

    assert_eq!(<N5MaxP5 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Gcd_P5() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N5GcdP5 = <<A as Gcd<B>>::Output as Same<P5>>::Output;

    assert_eq!(<N5GcdP5 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Div_P5() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N5DivP5 = <<A as Div<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N5DivP5 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Rem_P5() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N5RemP5 = <<A as Rem<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N5RemP5 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_PartialDiv_P5() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N5PartialDivP5 = <<A as PartialDiv<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N5PartialDivP5 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Pow_P5() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N3125 = NInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>, B0>, B0>, B0>, B1>, B1>, B0>, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N5PowP5 = <<A as Pow<B>>::Output as Same<N3125>>::Output;

    assert_eq!(<N5PowP5 as Integer>::to_i64(), <N3125 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Cmp_P5() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N5CmpP5 = <A as Cmp<B>>::Output;
    assert_eq!(<N5CmpP5 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Add_N5() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N9 = NInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N4AddN5 = <<A as Add<B>>::Output as Same<N9>>::Output;

    assert_eq!(<N4AddN5 as Integer>::to_i64(), <N9 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Sub_N5() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N4SubN5 = <<A as Sub<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N4SubN5 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Mul_N5() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P20 = PInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N4MulN5 = <<A as Mul<B>>::Output as Same<P20>>::Output;

    assert_eq!(<N4MulN5 as Integer>::to_i64(), <P20 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Min_N5() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N5 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N4MinN5 = <<A as Min<B>>::Output as Same<N5>>::Output;

    assert_eq!(<N4MinN5 as Integer>::to_i64(), <N5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Max_N5() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N4 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N4MaxN5 = <<A as Max<B>>::Output as Same<N4>>::Output;

    assert_eq!(<N4MaxN5 as Integer>::to_i64(), <N4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Gcd_N5() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N4GcdN5 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N4GcdN5 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Div_N5() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N4DivN5 = <<A as Div<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N4DivN5 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Rem_N5() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N4 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N4RemN5 = <<A as Rem<B>>::Output as Same<N4>>::Output;

    assert_eq!(<N4RemN5 as Integer>::to_i64(), <N4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Cmp_N5() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N4CmpN5 = <A as Cmp<B>>::Output;
    assert_eq!(<N4CmpN5 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Add_N4() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N8 = NInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N4AddN4 = <<A as Add<B>>::Output as Same<N8>>::Output;

    assert_eq!(<N4AddN4 as Integer>::to_i64(), <N8 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Sub_N4() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N4SubN4 = <<A as Sub<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N4SubN4 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Mul_N4() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P16 = PInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N4MulN4 = <<A as Mul<B>>::Output as Same<P16>>::Output;

    assert_eq!(<N4MulN4 as Integer>::to_i64(), <P16 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Min_N4() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N4 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N4MinN4 = <<A as Min<B>>::Output as Same<N4>>::Output;

    assert_eq!(<N4MinN4 as Integer>::to_i64(), <N4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Max_N4() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N4 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N4MaxN4 = <<A as Max<B>>::Output as Same<N4>>::Output;

    assert_eq!(<N4MaxN4 as Integer>::to_i64(), <N4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Gcd_N4() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N4GcdN4 = <<A as Gcd<B>>::Output as Same<P4>>::Output;

    assert_eq!(<N4GcdN4 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Div_N4() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N4DivN4 = <<A as Div<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N4DivN4 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Rem_N4() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N4RemN4 = <<A as Rem<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N4RemN4 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_PartialDiv_N4() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N4PartialDivN4 = <<A as PartialDiv<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N4PartialDivN4 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Cmp_N4() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N4CmpN4 = <A as Cmp<B>>::Output;
    assert_eq!(<N4CmpN4 as Ord>::to_ordering(), Ordering::Equal);
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Add_N3() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type N7 = NInt<UInt<UInt<UInt<UTerm, B1>, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N4AddN3 = <<A as Add<B>>::Output as Same<N7>>::Output;

    assert_eq!(<N4AddN3 as Integer>::to_i64(), <N7 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Sub_N3() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N4SubN3 = <<A as Sub<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N4SubN3 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Mul_N3() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type P12 = PInt<UInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N4MulN3 = <<A as Mul<B>>::Output as Same<P12>>::Output;

    assert_eq!(<N4MulN3 as Integer>::to_i64(), <P12 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Min_N3() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type N4 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N4MinN3 = <<A as Min<B>>::Output as Same<N4>>::Output;

    assert_eq!(<N4MinN3 as Integer>::to_i64(), <N4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Max_N3() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type N3 = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N4MaxN3 = <<A as Max<B>>::Output as Same<N3>>::Output;

    assert_eq!(<N4MaxN3 as Integer>::to_i64(), <N3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Gcd_N3() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N4GcdN3 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N4GcdN3 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Div_N3() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N4DivN3 = <<A as Div<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N4DivN3 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Rem_N3() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N4RemN3 = <<A as Rem<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N4RemN3 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Cmp_N3() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N4CmpN3 = <A as Cmp<B>>::Output;
    assert_eq!(<N4CmpN3 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Add_N2() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type N6 = NInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N4AddN2 = <<A as Add<B>>::Output as Same<N6>>::Output;

    assert_eq!(<N4AddN2 as Integer>::to_i64(), <N6 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Sub_N2() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N4SubN2 = <<A as Sub<B>>::Output as Same<N2>>::Output;

    assert_eq!(<N4SubN2 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Mul_N2() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type P8 = PInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N4MulN2 = <<A as Mul<B>>::Output as Same<P8>>::Output;

    assert_eq!(<N4MulN2 as Integer>::to_i64(), <P8 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Min_N2() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type N4 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N4MinN2 = <<A as Min<B>>::Output as Same<N4>>::Output;

    assert_eq!(<N4MinN2 as Integer>::to_i64(), <N4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Max_N2() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N4MaxN2 = <<A as Max<B>>::Output as Same<N2>>::Output;

    assert_eq!(<N4MaxN2 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Gcd_N2() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N4GcdN2 = <<A as Gcd<B>>::Output as Same<P2>>::Output;

    assert_eq!(<N4GcdN2 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Div_N2() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N4DivN2 = <<A as Div<B>>::Output as Same<P2>>::Output;

    assert_eq!(<N4DivN2 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Rem_N2() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N4RemN2 = <<A as Rem<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N4RemN2 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_PartialDiv_N2() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N4PartialDivN2 = <<A as PartialDiv<B>>::Output as Same<P2>>::Output;

    assert_eq!(<N4PartialDivN2 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Cmp_N2() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N4CmpN2 = <A as Cmp<B>>::Output;
    assert_eq!(<N4CmpN2 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Add_N1() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UTerm, B1>>;
    type N5 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N4AddN1 = <<A as Add<B>>::Output as Same<N5>>::Output;

    assert_eq!(<N4AddN1 as Integer>::to_i64(), <N5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Sub_N1() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UTerm, B1>>;
    type N3 = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N4SubN1 = <<A as Sub<B>>::Output as Same<N3>>::Output;

    assert_eq!(<N4SubN1 as Integer>::to_i64(), <N3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Mul_N1() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UTerm, B1>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N4MulN1 = <<A as Mul<B>>::Output as Same<P4>>::Output;

    assert_eq!(<N4MulN1 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Min_N1() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UTerm, B1>>;
    type N4 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N4MinN1 = <<A as Min<B>>::Output as Same<N4>>::Output;

    assert_eq!(<N4MinN1 as Integer>::to_i64(), <N4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Max_N1() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UTerm, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N4MaxN1 = <<A as Max<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N4MaxN1 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Gcd_N1() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UTerm, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N4GcdN1 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N4GcdN1 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Div_N1() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UTerm, B1>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N4DivN1 = <<A as Div<B>>::Output as Same<P4>>::Output;

    assert_eq!(<N4DivN1 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Rem_N1() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UTerm, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N4RemN1 = <<A as Rem<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N4RemN1 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_PartialDiv_N1() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UTerm, B1>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N4PartialDivN1 = <<A as PartialDiv<B>>::Output as Same<P4>>::Output;

    assert_eq!(<N4PartialDivN1 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Cmp_N1() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N4CmpN1 = <A as Cmp<B>>::Output;
    assert_eq!(<N4CmpN1 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Add__0() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = Z0;
    type N4 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N4Add_0 = <<A as Add<B>>::Output as Same<N4>>::Output;

    assert_eq!(<N4Add_0 as Integer>::to_i64(), <N4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Sub__0() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = Z0;
    type N4 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N4Sub_0 = <<A as Sub<B>>::Output as Same<N4>>::Output;

    assert_eq!(<N4Sub_0 as Integer>::to_i64(), <N4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Mul__0() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = Z0;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N4Mul_0 = <<A as Mul<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N4Mul_0 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Min__0() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = Z0;
    type N4 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N4Min_0 = <<A as Min<B>>::Output as Same<N4>>::Output;

    assert_eq!(<N4Min_0 as Integer>::to_i64(), <N4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Max__0() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = Z0;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N4Max_0 = <<A as Max<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N4Max_0 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Gcd__0() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = Z0;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N4Gcd_0 = <<A as Gcd<B>>::Output as Same<P4>>::Output;

    assert_eq!(<N4Gcd_0 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Pow__0() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = Z0;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N4Pow_0 = <<A as Pow<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N4Pow_0 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Cmp__0() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = Z0;

    #[allow(non_camel_case_types)]
    type N4Cmp_0 = <A as Cmp<B>>::Output;
    assert_eq!(<N4Cmp_0 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Add_P1() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UTerm, B1>>;
    type N3 = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N4AddP1 = <<A as Add<B>>::Output as Same<N3>>::Output;

    assert_eq!(<N4AddP1 as Integer>::to_i64(), <N3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Sub_P1() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UTerm, B1>>;
    type N5 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N4SubP1 = <<A as Sub<B>>::Output as Same<N5>>::Output;

    assert_eq!(<N4SubP1 as Integer>::to_i64(), <N5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Mul_P1() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UTerm, B1>>;
    type N4 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N4MulP1 = <<A as Mul<B>>::Output as Same<N4>>::Output;

    assert_eq!(<N4MulP1 as Integer>::to_i64(), <N4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Min_P1() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UTerm, B1>>;
    type N4 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N4MinP1 = <<A as Min<B>>::Output as Same<N4>>::Output;

    assert_eq!(<N4MinP1 as Integer>::to_i64(), <N4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Max_P1() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N4MaxP1 = <<A as Max<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N4MaxP1 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Gcd_P1() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N4GcdP1 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N4GcdP1 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Div_P1() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UTerm, B1>>;
    type N4 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N4DivP1 = <<A as Div<B>>::Output as Same<N4>>::Output;

    assert_eq!(<N4DivP1 as Integer>::to_i64(), <N4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Rem_P1() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UTerm, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N4RemP1 = <<A as Rem<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N4RemP1 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_PartialDiv_P1() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UTerm, B1>>;
    type N4 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N4PartialDivP1 = <<A as PartialDiv<B>>::Output as Same<N4>>::Output;

    assert_eq!(<N4PartialDivP1 as Integer>::to_i64(), <N4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Pow_P1() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UTerm, B1>>;
    type N4 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N4PowP1 = <<A as Pow<B>>::Output as Same<N4>>::Output;

    assert_eq!(<N4PowP1 as Integer>::to_i64(), <N4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Cmp_P1() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N4CmpP1 = <A as Cmp<B>>::Output;
    assert_eq!(<N4CmpP1 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Add_P2() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N4AddP2 = <<A as Add<B>>::Output as Same<N2>>::Output;

    assert_eq!(<N4AddP2 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Sub_P2() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type N6 = NInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N4SubP2 = <<A as Sub<B>>::Output as Same<N6>>::Output;

    assert_eq!(<N4SubP2 as Integer>::to_i64(), <N6 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Mul_P2() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type N8 = NInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N4MulP2 = <<A as Mul<B>>::Output as Same<N8>>::Output;

    assert_eq!(<N4MulP2 as Integer>::to_i64(), <N8 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Min_P2() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type N4 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N4MinP2 = <<A as Min<B>>::Output as Same<N4>>::Output;

    assert_eq!(<N4MinP2 as Integer>::to_i64(), <N4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Max_P2() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N4MaxP2 = <<A as Max<B>>::Output as Same<P2>>::Output;

    assert_eq!(<N4MaxP2 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Gcd_P2() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N4GcdP2 = <<A as Gcd<B>>::Output as Same<P2>>::Output;

    assert_eq!(<N4GcdP2 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Div_P2() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N4DivP2 = <<A as Div<B>>::Output as Same<N2>>::Output;

    assert_eq!(<N4DivP2 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Rem_P2() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N4RemP2 = <<A as Rem<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N4RemP2 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_PartialDiv_P2() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N4PartialDivP2 = <<A as PartialDiv<B>>::Output as Same<N2>>::Output;

    assert_eq!(<N4PartialDivP2 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Pow_P2() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P16 = PInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N4PowP2 = <<A as Pow<B>>::Output as Same<P16>>::Output;

    assert_eq!(<N4PowP2 as Integer>::to_i64(), <P16 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Cmp_P2() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N4CmpP2 = <A as Cmp<B>>::Output;
    assert_eq!(<N4CmpP2 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Add_P3() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N4AddP3 = <<A as Add<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N4AddP3 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Sub_P3() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type N7 = NInt<UInt<UInt<UInt<UTerm, B1>, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N4SubP3 = <<A as Sub<B>>::Output as Same<N7>>::Output;

    assert_eq!(<N4SubP3 as Integer>::to_i64(), <N7 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Mul_P3() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type N12 = NInt<UInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N4MulP3 = <<A as Mul<B>>::Output as Same<N12>>::Output;

    assert_eq!(<N4MulP3 as Integer>::to_i64(), <N12 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Min_P3() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type N4 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N4MinP3 = <<A as Min<B>>::Output as Same<N4>>::Output;

    assert_eq!(<N4MinP3 as Integer>::to_i64(), <N4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Max_P3() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N4MaxP3 = <<A as Max<B>>::Output as Same<P3>>::Output;

    assert_eq!(<N4MaxP3 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Gcd_P3() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N4GcdP3 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N4GcdP3 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Div_P3() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N4DivP3 = <<A as Div<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N4DivP3 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Rem_P3() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N4RemP3 = <<A as Rem<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N4RemP3 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Pow_P3() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type N64 = NInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>, B0>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N4PowP3 = <<A as Pow<B>>::Output as Same<N64>>::Output;

    assert_eq!(<N4PowP3 as Integer>::to_i64(), <N64 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Cmp_P3() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N4CmpP3 = <A as Cmp<B>>::Output;
    assert_eq!(<N4CmpP3 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Add_P4() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N4AddP4 = <<A as Add<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N4AddP4 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Sub_P4() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N8 = NInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N4SubP4 = <<A as Sub<B>>::Output as Same<N8>>::Output;

    assert_eq!(<N4SubP4 as Integer>::to_i64(), <N8 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Mul_P4() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N16 = NInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N4MulP4 = <<A as Mul<B>>::Output as Same<N16>>::Output;

    assert_eq!(<N4MulP4 as Integer>::to_i64(), <N16 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Min_P4() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N4 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N4MinP4 = <<A as Min<B>>::Output as Same<N4>>::Output;

    assert_eq!(<N4MinP4 as Integer>::to_i64(), <N4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Max_P4() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N4MaxP4 = <<A as Max<B>>::Output as Same<P4>>::Output;

    assert_eq!(<N4MaxP4 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Gcd_P4() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N4GcdP4 = <<A as Gcd<B>>::Output as Same<P4>>::Output;

    assert_eq!(<N4GcdP4 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Div_P4() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N4DivP4 = <<A as Div<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N4DivP4 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Rem_P4() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N4RemP4 = <<A as Rem<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N4RemP4 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_PartialDiv_P4() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N4PartialDivP4 = <<A as PartialDiv<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N4PartialDivP4 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Pow_P4() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P256 = PInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>, B0>, B0>, B0>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N4PowP4 = <<A as Pow<B>>::Output as Same<P256>>::Output;

    assert_eq!(<N4PowP4 as Integer>::to_i64(), <P256 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Cmp_P4() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N4CmpP4 = <A as Cmp<B>>::Output;
    assert_eq!(<N4CmpP4 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Add_P5() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N4AddP5 = <<A as Add<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N4AddP5 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Sub_P5() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N9 = NInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N4SubP5 = <<A as Sub<B>>::Output as Same<N9>>::Output;

    assert_eq!(<N4SubP5 as Integer>::to_i64(), <N9 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Mul_P5() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N20 = NInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N4MulP5 = <<A as Mul<B>>::Output as Same<N20>>::Output;

    assert_eq!(<N4MulP5 as Integer>::to_i64(), <N20 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Min_P5() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N4 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N4MinP5 = <<A as Min<B>>::Output as Same<N4>>::Output;

    assert_eq!(<N4MinP5 as Integer>::to_i64(), <N4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Max_P5() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N4MaxP5 = <<A as Max<B>>::Output as Same<P5>>::Output;

    assert_eq!(<N4MaxP5 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Gcd_P5() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N4GcdP5 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N4GcdP5 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Div_P5() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N4DivP5 = <<A as Div<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N4DivP5 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Rem_P5() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N4 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N4RemP5 = <<A as Rem<B>>::Output as Same<N4>>::Output;

    assert_eq!(<N4RemP5 as Integer>::to_i64(), <N4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Pow_P5() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N1024 = NInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>, B0>, B0>, B0>, B0>, B0>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N4PowP5 = <<A as Pow<B>>::Output as Same<N1024>>::Output;

    assert_eq!(<N4PowP5 as Integer>::to_i64(), <N1024 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Cmp_P5() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N4CmpP5 = <A as Cmp<B>>::Output;
    assert_eq!(<N4CmpP5 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Add_N5() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N8 = NInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N3AddN5 = <<A as Add<B>>::Output as Same<N8>>::Output;

    assert_eq!(<N3AddN5 as Integer>::to_i64(), <N8 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Sub_N5() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N3SubN5 = <<A as Sub<B>>::Output as Same<P2>>::Output;

    assert_eq!(<N3SubN5 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Mul_N5() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P15 = PInt<UInt<UInt<UInt<UInt<UTerm, B1>, B1>, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N3MulN5 = <<A as Mul<B>>::Output as Same<P15>>::Output;

    assert_eq!(<N3MulN5 as Integer>::to_i64(), <P15 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Min_N5() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N5 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N3MinN5 = <<A as Min<B>>::Output as Same<N5>>::Output;

    assert_eq!(<N3MinN5 as Integer>::to_i64(), <N5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Max_N5() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N3 = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N3MaxN5 = <<A as Max<B>>::Output as Same<N3>>::Output;

    assert_eq!(<N3MaxN5 as Integer>::to_i64(), <N3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Gcd_N5() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N3GcdN5 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N3GcdN5 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Div_N5() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N3DivN5 = <<A as Div<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N3DivN5 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Rem_N5() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N3 = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N3RemN5 = <<A as Rem<B>>::Output as Same<N3>>::Output;

    assert_eq!(<N3RemN5 as Integer>::to_i64(), <N3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Cmp_N5() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N3CmpN5 = <A as Cmp<B>>::Output;
    assert_eq!(<N3CmpN5 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Add_N4() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N7 = NInt<UInt<UInt<UInt<UTerm, B1>, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N3AddN4 = <<A as Add<B>>::Output as Same<N7>>::Output;

    assert_eq!(<N3AddN4 as Integer>::to_i64(), <N7 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Sub_N4() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N3SubN4 = <<A as Sub<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N3SubN4 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Mul_N4() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P12 = PInt<UInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N3MulN4 = <<A as Mul<B>>::Output as Same<P12>>::Output;

    assert_eq!(<N3MulN4 as Integer>::to_i64(), <P12 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Min_N4() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N4 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N3MinN4 = <<A as Min<B>>::Output as Same<N4>>::Output;

    assert_eq!(<N3MinN4 as Integer>::to_i64(), <N4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Max_N4() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N3 = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N3MaxN4 = <<A as Max<B>>::Output as Same<N3>>::Output;

    assert_eq!(<N3MaxN4 as Integer>::to_i64(), <N3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Gcd_N4() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N3GcdN4 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N3GcdN4 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Div_N4() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N3DivN4 = <<A as Div<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N3DivN4 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Rem_N4() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N3 = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N3RemN4 = <<A as Rem<B>>::Output as Same<N3>>::Output;

    assert_eq!(<N3RemN4 as Integer>::to_i64(), <N3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Cmp_N4() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N3CmpN4 = <A as Cmp<B>>::Output;
    assert_eq!(<N3CmpN4 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Add_N3() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type N6 = NInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N3AddN3 = <<A as Add<B>>::Output as Same<N6>>::Output;

    assert_eq!(<N3AddN3 as Integer>::to_i64(), <N6 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Sub_N3() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N3SubN3 = <<A as Sub<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N3SubN3 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Mul_N3() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type P9 = PInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N3MulN3 = <<A as Mul<B>>::Output as Same<P9>>::Output;

    assert_eq!(<N3MulN3 as Integer>::to_i64(), <P9 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Min_N3() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type N3 = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N3MinN3 = <<A as Min<B>>::Output as Same<N3>>::Output;

    assert_eq!(<N3MinN3 as Integer>::to_i64(), <N3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Max_N3() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type N3 = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N3MaxN3 = <<A as Max<B>>::Output as Same<N3>>::Output;

    assert_eq!(<N3MaxN3 as Integer>::to_i64(), <N3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Gcd_N3() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N3GcdN3 = <<A as Gcd<B>>::Output as Same<P3>>::Output;

    assert_eq!(<N3GcdN3 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Div_N3() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N3DivN3 = <<A as Div<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N3DivN3 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Rem_N3() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N3RemN3 = <<A as Rem<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N3RemN3 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_PartialDiv_N3() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N3PartialDivN3 = <<A as PartialDiv<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N3PartialDivN3 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Cmp_N3() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N3CmpN3 = <A as Cmp<B>>::Output;
    assert_eq!(<N3CmpN3 as Ord>::to_ordering(), Ordering::Equal);
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Add_N2() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type N5 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N3AddN2 = <<A as Add<B>>::Output as Same<N5>>::Output;

    assert_eq!(<N3AddN2 as Integer>::to_i64(), <N5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Sub_N2() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N3SubN2 = <<A as Sub<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N3SubN2 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Mul_N2() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type P6 = PInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N3MulN2 = <<A as Mul<B>>::Output as Same<P6>>::Output;

    assert_eq!(<N3MulN2 as Integer>::to_i64(), <P6 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Min_N2() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type N3 = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N3MinN2 = <<A as Min<B>>::Output as Same<N3>>::Output;

    assert_eq!(<N3MinN2 as Integer>::to_i64(), <N3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Max_N2() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N3MaxN2 = <<A as Max<B>>::Output as Same<N2>>::Output;

    assert_eq!(<N3MaxN2 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Gcd_N2() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N3GcdN2 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N3GcdN2 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Div_N2() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N3DivN2 = <<A as Div<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N3DivN2 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Rem_N2() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N3RemN2 = <<A as Rem<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N3RemN2 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Cmp_N2() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N3CmpN2 = <A as Cmp<B>>::Output;
    assert_eq!(<N3CmpN2 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Add_N1() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type N4 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N3AddN1 = <<A as Add<B>>::Output as Same<N4>>::Output;

    assert_eq!(<N3AddN1 as Integer>::to_i64(), <N4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Sub_N1() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N3SubN1 = <<A as Sub<B>>::Output as Same<N2>>::Output;

    assert_eq!(<N3SubN1 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Mul_N1() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N3MulN1 = <<A as Mul<B>>::Output as Same<P3>>::Output;

    assert_eq!(<N3MulN1 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Min_N1() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type N3 = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N3MinN1 = <<A as Min<B>>::Output as Same<N3>>::Output;

    assert_eq!(<N3MinN1 as Integer>::to_i64(), <N3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Max_N1() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N3MaxN1 = <<A as Max<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N3MaxN1 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Gcd_N1() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N3GcdN1 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N3GcdN1 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Div_N1() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N3DivN1 = <<A as Div<B>>::Output as Same<P3>>::Output;

    assert_eq!(<N3DivN1 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Rem_N1() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N3RemN1 = <<A as Rem<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N3RemN1 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_PartialDiv_N1() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N3PartialDivN1 = <<A as PartialDiv<B>>::Output as Same<P3>>::Output;

    assert_eq!(<N3PartialDivN1 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Cmp_N1() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N3CmpN1 = <A as Cmp<B>>::Output;
    assert_eq!(<N3CmpN1 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Add__0() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = Z0;
    type N3 = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N3Add_0 = <<A as Add<B>>::Output as Same<N3>>::Output;

    assert_eq!(<N3Add_0 as Integer>::to_i64(), <N3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Sub__0() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = Z0;
    type N3 = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N3Sub_0 = <<A as Sub<B>>::Output as Same<N3>>::Output;

    assert_eq!(<N3Sub_0 as Integer>::to_i64(), <N3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Mul__0() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = Z0;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N3Mul_0 = <<A as Mul<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N3Mul_0 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Min__0() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = Z0;
    type N3 = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N3Min_0 = <<A as Min<B>>::Output as Same<N3>>::Output;

    assert_eq!(<N3Min_0 as Integer>::to_i64(), <N3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Max__0() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = Z0;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N3Max_0 = <<A as Max<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N3Max_0 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Gcd__0() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = Z0;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N3Gcd_0 = <<A as Gcd<B>>::Output as Same<P3>>::Output;

    assert_eq!(<N3Gcd_0 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Pow__0() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = Z0;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N3Pow_0 = <<A as Pow<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N3Pow_0 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Cmp__0() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = Z0;

    #[allow(non_camel_case_types)]
    type N3Cmp_0 = <A as Cmp<B>>::Output;
    assert_eq!(<N3Cmp_0 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Add_P1() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N3AddP1 = <<A as Add<B>>::Output as Same<N2>>::Output;

    assert_eq!(<N3AddP1 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Sub_P1() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type N4 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N3SubP1 = <<A as Sub<B>>::Output as Same<N4>>::Output;

    assert_eq!(<N3SubP1 as Integer>::to_i64(), <N4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Mul_P1() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type N3 = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N3MulP1 = <<A as Mul<B>>::Output as Same<N3>>::Output;

    assert_eq!(<N3MulP1 as Integer>::to_i64(), <N3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Min_P1() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type N3 = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N3MinP1 = <<A as Min<B>>::Output as Same<N3>>::Output;

    assert_eq!(<N3MinP1 as Integer>::to_i64(), <N3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Max_P1() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N3MaxP1 = <<A as Max<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N3MaxP1 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Gcd_P1() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N3GcdP1 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N3GcdP1 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Div_P1() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type N3 = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N3DivP1 = <<A as Div<B>>::Output as Same<N3>>::Output;

    assert_eq!(<N3DivP1 as Integer>::to_i64(), <N3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Rem_P1() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N3RemP1 = <<A as Rem<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N3RemP1 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_PartialDiv_P1() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type N3 = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N3PartialDivP1 = <<A as PartialDiv<B>>::Output as Same<N3>>::Output;

    assert_eq!(<N3PartialDivP1 as Integer>::to_i64(), <N3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Pow_P1() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type N3 = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N3PowP1 = <<A as Pow<B>>::Output as Same<N3>>::Output;

    assert_eq!(<N3PowP1 as Integer>::to_i64(), <N3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Cmp_P1() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N3CmpP1 = <A as Cmp<B>>::Output;
    assert_eq!(<N3CmpP1 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Add_P2() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N3AddP2 = <<A as Add<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N3AddP2 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Sub_P2() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type N5 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N3SubP2 = <<A as Sub<B>>::Output as Same<N5>>::Output;

    assert_eq!(<N3SubP2 as Integer>::to_i64(), <N5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Mul_P2() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type N6 = NInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N3MulP2 = <<A as Mul<B>>::Output as Same<N6>>::Output;

    assert_eq!(<N3MulP2 as Integer>::to_i64(), <N6 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Min_P2() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type N3 = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N3MinP2 = <<A as Min<B>>::Output as Same<N3>>::Output;

    assert_eq!(<N3MinP2 as Integer>::to_i64(), <N3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Max_P2() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N3MaxP2 = <<A as Max<B>>::Output as Same<P2>>::Output;

    assert_eq!(<N3MaxP2 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Gcd_P2() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N3GcdP2 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N3GcdP2 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Div_P2() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N3DivP2 = <<A as Div<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N3DivP2 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Rem_P2() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N3RemP2 = <<A as Rem<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N3RemP2 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Pow_P2() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P9 = PInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N3PowP2 = <<A as Pow<B>>::Output as Same<P9>>::Output;

    assert_eq!(<N3PowP2 as Integer>::to_i64(), <P9 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Cmp_P2() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N3CmpP2 = <A as Cmp<B>>::Output;
    assert_eq!(<N3CmpP2 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Add_P3() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N3AddP3 = <<A as Add<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N3AddP3 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Sub_P3() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type N6 = NInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N3SubP3 = <<A as Sub<B>>::Output as Same<N6>>::Output;

    assert_eq!(<N3SubP3 as Integer>::to_i64(), <N6 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Mul_P3() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type N9 = NInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N3MulP3 = <<A as Mul<B>>::Output as Same<N9>>::Output;

    assert_eq!(<N3MulP3 as Integer>::to_i64(), <N9 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Min_P3() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type N3 = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N3MinP3 = <<A as Min<B>>::Output as Same<N3>>::Output;

    assert_eq!(<N3MinP3 as Integer>::to_i64(), <N3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Max_P3() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N3MaxP3 = <<A as Max<B>>::Output as Same<P3>>::Output;

    assert_eq!(<N3MaxP3 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Gcd_P3() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N3GcdP3 = <<A as Gcd<B>>::Output as Same<P3>>::Output;

    assert_eq!(<N3GcdP3 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Div_P3() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N3DivP3 = <<A as Div<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N3DivP3 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Rem_P3() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N3RemP3 = <<A as Rem<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N3RemP3 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_PartialDiv_P3() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N3PartialDivP3 = <<A as PartialDiv<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N3PartialDivP3 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Pow_P3() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type N27 = NInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N3PowP3 = <<A as Pow<B>>::Output as Same<N27>>::Output;

    assert_eq!(<N3PowP3 as Integer>::to_i64(), <N27 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Cmp_P3() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N3CmpP3 = <A as Cmp<B>>::Output;
    assert_eq!(<N3CmpP3 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Add_P4() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N3AddP4 = <<A as Add<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N3AddP4 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Sub_P4() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N7 = NInt<UInt<UInt<UInt<UTerm, B1>, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N3SubP4 = <<A as Sub<B>>::Output as Same<N7>>::Output;

    assert_eq!(<N3SubP4 as Integer>::to_i64(), <N7 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Mul_P4() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N12 = NInt<UInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N3MulP4 = <<A as Mul<B>>::Output as Same<N12>>::Output;

    assert_eq!(<N3MulP4 as Integer>::to_i64(), <N12 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Min_P4() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N3 = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N3MinP4 = <<A as Min<B>>::Output as Same<N3>>::Output;

    assert_eq!(<N3MinP4 as Integer>::to_i64(), <N3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Max_P4() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N3MaxP4 = <<A as Max<B>>::Output as Same<P4>>::Output;

    assert_eq!(<N3MaxP4 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Gcd_P4() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N3GcdP4 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N3GcdP4 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Div_P4() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N3DivP4 = <<A as Div<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N3DivP4 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Rem_P4() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N3 = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N3RemP4 = <<A as Rem<B>>::Output as Same<N3>>::Output;

    assert_eq!(<N3RemP4 as Integer>::to_i64(), <N3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Pow_P4() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P81 = PInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>, B0>, B0>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N3PowP4 = <<A as Pow<B>>::Output as Same<P81>>::Output;

    assert_eq!(<N3PowP4 as Integer>::to_i64(), <P81 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Cmp_P4() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N3CmpP4 = <A as Cmp<B>>::Output;
    assert_eq!(<N3CmpP4 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Add_P5() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N3AddP5 = <<A as Add<B>>::Output as Same<P2>>::Output;

    assert_eq!(<N3AddP5 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Sub_P5() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N8 = NInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N3SubP5 = <<A as Sub<B>>::Output as Same<N8>>::Output;

    assert_eq!(<N3SubP5 as Integer>::to_i64(), <N8 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Mul_P5() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N15 = NInt<UInt<UInt<UInt<UInt<UTerm, B1>, B1>, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N3MulP5 = <<A as Mul<B>>::Output as Same<N15>>::Output;

    assert_eq!(<N3MulP5 as Integer>::to_i64(), <N15 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Min_P5() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N3 = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N3MinP5 = <<A as Min<B>>::Output as Same<N3>>::Output;

    assert_eq!(<N3MinP5 as Integer>::to_i64(), <N3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Max_P5() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N3MaxP5 = <<A as Max<B>>::Output as Same<P5>>::Output;

    assert_eq!(<N3MaxP5 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Gcd_P5() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N3GcdP5 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N3GcdP5 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Div_P5() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N3DivP5 = <<A as Div<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N3DivP5 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Rem_P5() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N3 = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N3RemP5 = <<A as Rem<B>>::Output as Same<N3>>::Output;

    assert_eq!(<N3RemP5 as Integer>::to_i64(), <N3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Pow_P5() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N243 = NInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B1>, B1>, B1>, B0>, B0>, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N3PowP5 = <<A as Pow<B>>::Output as Same<N243>>::Output;

    assert_eq!(<N3PowP5 as Integer>::to_i64(), <N243 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Cmp_P5() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N3CmpP5 = <A as Cmp<B>>::Output;
    assert_eq!(<N3CmpP5 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Add_N5() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N7 = NInt<UInt<UInt<UInt<UTerm, B1>, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N2AddN5 = <<A as Add<B>>::Output as Same<N7>>::Output;

    assert_eq!(<N2AddN5 as Integer>::to_i64(), <N7 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Sub_N5() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N2SubN5 = <<A as Sub<B>>::Output as Same<P3>>::Output;

    assert_eq!(<N2SubN5 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Mul_N5() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P10 = PInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N2MulN5 = <<A as Mul<B>>::Output as Same<P10>>::Output;

    assert_eq!(<N2MulN5 as Integer>::to_i64(), <P10 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Min_N5() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N5 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N2MinN5 = <<A as Min<B>>::Output as Same<N5>>::Output;

    assert_eq!(<N2MinN5 as Integer>::to_i64(), <N5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Max_N5() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N2MaxN5 = <<A as Max<B>>::Output as Same<N2>>::Output;

    assert_eq!(<N2MaxN5 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Gcd_N5() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N2GcdN5 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N2GcdN5 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Div_N5() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N2DivN5 = <<A as Div<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N2DivN5 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Rem_N5() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N2RemN5 = <<A as Rem<B>>::Output as Same<N2>>::Output;

    assert_eq!(<N2RemN5 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Cmp_N5() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N2CmpN5 = <A as Cmp<B>>::Output;
    assert_eq!(<N2CmpN5 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Add_N4() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N6 = NInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N2AddN4 = <<A as Add<B>>::Output as Same<N6>>::Output;

    assert_eq!(<N2AddN4 as Integer>::to_i64(), <N6 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Sub_N4() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N2SubN4 = <<A as Sub<B>>::Output as Same<P2>>::Output;

    assert_eq!(<N2SubN4 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Mul_N4() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P8 = PInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N2MulN4 = <<A as Mul<B>>::Output as Same<P8>>::Output;

    assert_eq!(<N2MulN4 as Integer>::to_i64(), <P8 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Min_N4() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N4 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N2MinN4 = <<A as Min<B>>::Output as Same<N4>>::Output;

    assert_eq!(<N2MinN4 as Integer>::to_i64(), <N4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Max_N4() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N2MaxN4 = <<A as Max<B>>::Output as Same<N2>>::Output;

    assert_eq!(<N2MaxN4 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Gcd_N4() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N2GcdN4 = <<A as Gcd<B>>::Output as Same<P2>>::Output;

    assert_eq!(<N2GcdN4 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Div_N4() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N2DivN4 = <<A as Div<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N2DivN4 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Rem_N4() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N2RemN4 = <<A as Rem<B>>::Output as Same<N2>>::Output;

    assert_eq!(<N2RemN4 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Cmp_N4() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N2CmpN4 = <A as Cmp<B>>::Output;
    assert_eq!(<N2CmpN4 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Add_N3() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type N5 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N2AddN3 = <<A as Add<B>>::Output as Same<N5>>::Output;

    assert_eq!(<N2AddN3 as Integer>::to_i64(), <N5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Sub_N3() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N2SubN3 = <<A as Sub<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N2SubN3 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Mul_N3() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type P6 = PInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N2MulN3 = <<A as Mul<B>>::Output as Same<P6>>::Output;

    assert_eq!(<N2MulN3 as Integer>::to_i64(), <P6 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Min_N3() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type N3 = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N2MinN3 = <<A as Min<B>>::Output as Same<N3>>::Output;

    assert_eq!(<N2MinN3 as Integer>::to_i64(), <N3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Max_N3() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N2MaxN3 = <<A as Max<B>>::Output as Same<N2>>::Output;

    assert_eq!(<N2MaxN3 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Gcd_N3() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N2GcdN3 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N2GcdN3 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Div_N3() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N2DivN3 = <<A as Div<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N2DivN3 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Rem_N3() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N2RemN3 = <<A as Rem<B>>::Output as Same<N2>>::Output;

    assert_eq!(<N2RemN3 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Cmp_N3() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N2CmpN3 = <A as Cmp<B>>::Output;
    assert_eq!(<N2CmpN3 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Add_N2() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type N4 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N2AddN2 = <<A as Add<B>>::Output as Same<N4>>::Output;

    assert_eq!(<N2AddN2 as Integer>::to_i64(), <N4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Sub_N2() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N2SubN2 = <<A as Sub<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N2SubN2 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Mul_N2() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N2MulN2 = <<A as Mul<B>>::Output as Same<P4>>::Output;

    assert_eq!(<N2MulN2 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Min_N2() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N2MinN2 = <<A as Min<B>>::Output as Same<N2>>::Output;

    assert_eq!(<N2MinN2 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Max_N2() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N2MaxN2 = <<A as Max<B>>::Output as Same<N2>>::Output;

    assert_eq!(<N2MaxN2 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Gcd_N2() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N2GcdN2 = <<A as Gcd<B>>::Output as Same<P2>>::Output;

    assert_eq!(<N2GcdN2 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Div_N2() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N2DivN2 = <<A as Div<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N2DivN2 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Rem_N2() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N2RemN2 = <<A as Rem<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N2RemN2 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_PartialDiv_N2() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N2PartialDivN2 = <<A as PartialDiv<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N2PartialDivN2 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Cmp_N2() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N2CmpN2 = <A as Cmp<B>>::Output;
    assert_eq!(<N2CmpN2 as Ord>::to_ordering(), Ordering::Equal);
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Add_N1() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UTerm, B1>>;
    type N3 = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N2AddN1 = <<A as Add<B>>::Output as Same<N3>>::Output;

    assert_eq!(<N2AddN1 as Integer>::to_i64(), <N3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Sub_N1() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UTerm, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N2SubN1 = <<A as Sub<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N2SubN1 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Mul_N1() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UTerm, B1>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N2MulN1 = <<A as Mul<B>>::Output as Same<P2>>::Output;

    assert_eq!(<N2MulN1 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Min_N1() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UTerm, B1>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N2MinN1 = <<A as Min<B>>::Output as Same<N2>>::Output;

    assert_eq!(<N2MinN1 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Max_N1() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UTerm, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N2MaxN1 = <<A as Max<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N2MaxN1 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Gcd_N1() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UTerm, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N2GcdN1 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N2GcdN1 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Div_N1() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UTerm, B1>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N2DivN1 = <<A as Div<B>>::Output as Same<P2>>::Output;

    assert_eq!(<N2DivN1 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Rem_N1() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UTerm, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N2RemN1 = <<A as Rem<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N2RemN1 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_PartialDiv_N1() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UTerm, B1>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N2PartialDivN1 = <<A as PartialDiv<B>>::Output as Same<P2>>::Output;

    assert_eq!(<N2PartialDivN1 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Cmp_N1() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N2CmpN1 = <A as Cmp<B>>::Output;
    assert_eq!(<N2CmpN1 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Add__0() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = Z0;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N2Add_0 = <<A as Add<B>>::Output as Same<N2>>::Output;

    assert_eq!(<N2Add_0 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Sub__0() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = Z0;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N2Sub_0 = <<A as Sub<B>>::Output as Same<N2>>::Output;

    assert_eq!(<N2Sub_0 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Mul__0() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = Z0;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N2Mul_0 = <<A as Mul<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N2Mul_0 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Min__0() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = Z0;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N2Min_0 = <<A as Min<B>>::Output as Same<N2>>::Output;

    assert_eq!(<N2Min_0 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Max__0() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = Z0;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N2Max_0 = <<A as Max<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N2Max_0 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Gcd__0() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = Z0;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N2Gcd_0 = <<A as Gcd<B>>::Output as Same<P2>>::Output;

    assert_eq!(<N2Gcd_0 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Pow__0() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = Z0;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N2Pow_0 = <<A as Pow<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N2Pow_0 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Cmp__0() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = Z0;

    #[allow(non_camel_case_types)]
    type N2Cmp_0 = <A as Cmp<B>>::Output;
    assert_eq!(<N2Cmp_0 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Add_P1() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UTerm, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N2AddP1 = <<A as Add<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N2AddP1 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Sub_P1() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UTerm, B1>>;
    type N3 = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N2SubP1 = <<A as Sub<B>>::Output as Same<N3>>::Output;

    assert_eq!(<N2SubP1 as Integer>::to_i64(), <N3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Mul_P1() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UTerm, B1>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N2MulP1 = <<A as Mul<B>>::Output as Same<N2>>::Output;

    assert_eq!(<N2MulP1 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Min_P1() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UTerm, B1>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N2MinP1 = <<A as Min<B>>::Output as Same<N2>>::Output;

    assert_eq!(<N2MinP1 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Max_P1() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N2MaxP1 = <<A as Max<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N2MaxP1 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Gcd_P1() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N2GcdP1 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N2GcdP1 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Div_P1() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UTerm, B1>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N2DivP1 = <<A as Div<B>>::Output as Same<N2>>::Output;

    assert_eq!(<N2DivP1 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Rem_P1() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UTerm, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N2RemP1 = <<A as Rem<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N2RemP1 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_PartialDiv_P1() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UTerm, B1>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N2PartialDivP1 = <<A as PartialDiv<B>>::Output as Same<N2>>::Output;

    assert_eq!(<N2PartialDivP1 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Pow_P1() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UTerm, B1>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N2PowP1 = <<A as Pow<B>>::Output as Same<N2>>::Output;

    assert_eq!(<N2PowP1 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Cmp_P1() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N2CmpP1 = <A as Cmp<B>>::Output;
    assert_eq!(<N2CmpP1 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Add_P2() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N2AddP2 = <<A as Add<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N2AddP2 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Sub_P2() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type N4 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N2SubP2 = <<A as Sub<B>>::Output as Same<N4>>::Output;

    assert_eq!(<N2SubP2 as Integer>::to_i64(), <N4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Mul_P2() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type N4 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N2MulP2 = <<A as Mul<B>>::Output as Same<N4>>::Output;

    assert_eq!(<N2MulP2 as Integer>::to_i64(), <N4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Min_P2() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N2MinP2 = <<A as Min<B>>::Output as Same<N2>>::Output;

    assert_eq!(<N2MinP2 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Max_P2() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N2MaxP2 = <<A as Max<B>>::Output as Same<P2>>::Output;

    assert_eq!(<N2MaxP2 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Gcd_P2() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N2GcdP2 = <<A as Gcd<B>>::Output as Same<P2>>::Output;

    assert_eq!(<N2GcdP2 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Div_P2() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N2DivP2 = <<A as Div<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N2DivP2 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Rem_P2() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N2RemP2 = <<A as Rem<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N2RemP2 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_PartialDiv_P2() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N2PartialDivP2 = <<A as PartialDiv<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N2PartialDivP2 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Pow_P2() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N2PowP2 = <<A as Pow<B>>::Output as Same<P4>>::Output;

    assert_eq!(<N2PowP2 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Cmp_P2() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N2CmpP2 = <A as Cmp<B>>::Output;
    assert_eq!(<N2CmpP2 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Add_P3() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N2AddP3 = <<A as Add<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N2AddP3 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Sub_P3() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type N5 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N2SubP3 = <<A as Sub<B>>::Output as Same<N5>>::Output;

    assert_eq!(<N2SubP3 as Integer>::to_i64(), <N5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Mul_P3() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type N6 = NInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N2MulP3 = <<A as Mul<B>>::Output as Same<N6>>::Output;

    assert_eq!(<N2MulP3 as Integer>::to_i64(), <N6 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Min_P3() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N2MinP3 = <<A as Min<B>>::Output as Same<N2>>::Output;

    assert_eq!(<N2MinP3 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Max_P3() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N2MaxP3 = <<A as Max<B>>::Output as Same<P3>>::Output;

    assert_eq!(<N2MaxP3 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Gcd_P3() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N2GcdP3 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N2GcdP3 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Div_P3() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N2DivP3 = <<A as Div<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N2DivP3 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Rem_P3() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N2RemP3 = <<A as Rem<B>>::Output as Same<N2>>::Output;

    assert_eq!(<N2RemP3 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Pow_P3() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type N8 = NInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N2PowP3 = <<A as Pow<B>>::Output as Same<N8>>::Output;

    assert_eq!(<N2PowP3 as Integer>::to_i64(), <N8 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Cmp_P3() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N2CmpP3 = <A as Cmp<B>>::Output;
    assert_eq!(<N2CmpP3 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Add_P4() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N2AddP4 = <<A as Add<B>>::Output as Same<P2>>::Output;

    assert_eq!(<N2AddP4 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Sub_P4() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N6 = NInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N2SubP4 = <<A as Sub<B>>::Output as Same<N6>>::Output;

    assert_eq!(<N2SubP4 as Integer>::to_i64(), <N6 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Mul_P4() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N8 = NInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N2MulP4 = <<A as Mul<B>>::Output as Same<N8>>::Output;

    assert_eq!(<N2MulP4 as Integer>::to_i64(), <N8 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Min_P4() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N2MinP4 = <<A as Min<B>>::Output as Same<N2>>::Output;

    assert_eq!(<N2MinP4 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Max_P4() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N2MaxP4 = <<A as Max<B>>::Output as Same<P4>>::Output;

    assert_eq!(<N2MaxP4 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Gcd_P4() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N2GcdP4 = <<A as Gcd<B>>::Output as Same<P2>>::Output;

    assert_eq!(<N2GcdP4 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Div_P4() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N2DivP4 = <<A as Div<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N2DivP4 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Rem_P4() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N2RemP4 = <<A as Rem<B>>::Output as Same<N2>>::Output;

    assert_eq!(<N2RemP4 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Pow_P4() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P16 = PInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N2PowP4 = <<A as Pow<B>>::Output as Same<P16>>::Output;

    assert_eq!(<N2PowP4 as Integer>::to_i64(), <P16 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Cmp_P4() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N2CmpP4 = <A as Cmp<B>>::Output;
    assert_eq!(<N2CmpP4 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Add_P5() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N2AddP5 = <<A as Add<B>>::Output as Same<P3>>::Output;

    assert_eq!(<N2AddP5 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Sub_P5() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N7 = NInt<UInt<UInt<UInt<UTerm, B1>, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N2SubP5 = <<A as Sub<B>>::Output as Same<N7>>::Output;

    assert_eq!(<N2SubP5 as Integer>::to_i64(), <N7 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Mul_P5() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N10 = NInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N2MulP5 = <<A as Mul<B>>::Output as Same<N10>>::Output;

    assert_eq!(<N2MulP5 as Integer>::to_i64(), <N10 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Min_P5() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N2MinP5 = <<A as Min<B>>::Output as Same<N2>>::Output;

    assert_eq!(<N2MinP5 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Max_P5() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N2MaxP5 = <<A as Max<B>>::Output as Same<P5>>::Output;

    assert_eq!(<N2MaxP5 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Gcd_P5() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N2GcdP5 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N2GcdP5 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Div_P5() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N2DivP5 = <<A as Div<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N2DivP5 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Rem_P5() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N2RemP5 = <<A as Rem<B>>::Output as Same<N2>>::Output;

    assert_eq!(<N2RemP5 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Pow_P5() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N32 = NInt<UInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N2PowP5 = <<A as Pow<B>>::Output as Same<N32>>::Output;

    assert_eq!(<N2PowP5 as Integer>::to_i64(), <N32 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Cmp_P5() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N2CmpP5 = <A as Cmp<B>>::Output;
    assert_eq!(<N2CmpP5 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Add_N5() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N6 = NInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N1AddN5 = <<A as Add<B>>::Output as Same<N6>>::Output;

    assert_eq!(<N1AddN5 as Integer>::to_i64(), <N6 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Sub_N5() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N1SubN5 = <<A as Sub<B>>::Output as Same<P4>>::Output;

    assert_eq!(<N1SubN5 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Mul_N5() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N1MulN5 = <<A as Mul<B>>::Output as Same<P5>>::Output;

    assert_eq!(<N1MulN5 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Min_N5() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N5 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N1MinN5 = <<A as Min<B>>::Output as Same<N5>>::Output;

    assert_eq!(<N1MinN5 as Integer>::to_i64(), <N5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Max_N5() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1MaxN5 = <<A as Max<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N1MaxN5 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Gcd_N5() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1GcdN5 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N1GcdN5 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Div_N5() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N1DivN5 = <<A as Div<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N1DivN5 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Rem_N5() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1RemN5 = <<A as Rem<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N1RemN5 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Pow_N5() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1PowN5 = <<A as Pow<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N1PowN5 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Cmp_N5() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N1CmpN5 = <A as Cmp<B>>::Output;
    assert_eq!(<N1CmpN5 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Add_N4() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N5 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N1AddN4 = <<A as Add<B>>::Output as Same<N5>>::Output;

    assert_eq!(<N1AddN4 as Integer>::to_i64(), <N5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Sub_N4() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N1SubN4 = <<A as Sub<B>>::Output as Same<P3>>::Output;

    assert_eq!(<N1SubN4 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Mul_N4() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N1MulN4 = <<A as Mul<B>>::Output as Same<P4>>::Output;

    assert_eq!(<N1MulN4 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Min_N4() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N4 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N1MinN4 = <<A as Min<B>>::Output as Same<N4>>::Output;

    assert_eq!(<N1MinN4 as Integer>::to_i64(), <N4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Max_N4() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1MaxN4 = <<A as Max<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N1MaxN4 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Gcd_N4() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1GcdN4 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N1GcdN4 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Div_N4() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N1DivN4 = <<A as Div<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N1DivN4 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Rem_N4() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1RemN4 = <<A as Rem<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N1RemN4 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Pow_N4() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1PowN4 = <<A as Pow<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N1PowN4 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Cmp_N4() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N1CmpN4 = <A as Cmp<B>>::Output;
    assert_eq!(<N1CmpN4 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Add_N3() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type N4 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N1AddN3 = <<A as Add<B>>::Output as Same<N4>>::Output;

    assert_eq!(<N1AddN3 as Integer>::to_i64(), <N4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Sub_N3() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N1SubN3 = <<A as Sub<B>>::Output as Same<P2>>::Output;

    assert_eq!(<N1SubN3 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Mul_N3() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N1MulN3 = <<A as Mul<B>>::Output as Same<P3>>::Output;

    assert_eq!(<N1MulN3 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Min_N3() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type N3 = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N1MinN3 = <<A as Min<B>>::Output as Same<N3>>::Output;

    assert_eq!(<N1MinN3 as Integer>::to_i64(), <N3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Max_N3() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1MaxN3 = <<A as Max<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N1MaxN3 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Gcd_N3() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1GcdN3 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N1GcdN3 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Div_N3() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N1DivN3 = <<A as Div<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N1DivN3 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Rem_N3() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1RemN3 = <<A as Rem<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N1RemN3 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Pow_N3() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1PowN3 = <<A as Pow<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N1PowN3 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Cmp_N3() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N1CmpN3 = <A as Cmp<B>>::Output;
    assert_eq!(<N1CmpN3 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Add_N2() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type N3 = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N1AddN2 = <<A as Add<B>>::Output as Same<N3>>::Output;

    assert_eq!(<N1AddN2 as Integer>::to_i64(), <N3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Sub_N2() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1SubN2 = <<A as Sub<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N1SubN2 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Mul_N2() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N1MulN2 = <<A as Mul<B>>::Output as Same<P2>>::Output;

    assert_eq!(<N1MulN2 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Min_N2() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N1MinN2 = <<A as Min<B>>::Output as Same<N2>>::Output;

    assert_eq!(<N1MinN2 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Max_N2() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1MaxN2 = <<A as Max<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N1MaxN2 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Gcd_N2() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1GcdN2 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N1GcdN2 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Div_N2() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N1DivN2 = <<A as Div<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N1DivN2 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Rem_N2() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1RemN2 = <<A as Rem<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N1RemN2 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Pow_N2() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1PowN2 = <<A as Pow<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N1PowN2 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Cmp_N2() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N1CmpN2 = <A as Cmp<B>>::Output;
    assert_eq!(<N1CmpN2 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Add_N1() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N1AddN1 = <<A as Add<B>>::Output as Same<N2>>::Output;

    assert_eq!(<N1AddN1 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Sub_N1() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N1SubN1 = <<A as Sub<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N1SubN1 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Mul_N1() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1MulN1 = <<A as Mul<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N1MulN1 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Min_N1() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1MinN1 = <<A as Min<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N1MinN1 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Max_N1() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1MaxN1 = <<A as Max<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N1MaxN1 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Gcd_N1() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1GcdN1 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N1GcdN1 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Div_N1() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1DivN1 = <<A as Div<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N1DivN1 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Rem_N1() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N1RemN1 = <<A as Rem<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N1RemN1 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_PartialDiv_N1() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1PartialDivN1 = <<A as PartialDiv<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N1PartialDivN1 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Pow_N1() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1PowN1 = <<A as Pow<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N1PowN1 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Cmp_N1() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1CmpN1 = <A as Cmp<B>>::Output;
    assert_eq!(<N1CmpN1 as Ord>::to_ordering(), Ordering::Equal);
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Add__0() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = Z0;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1Add_0 = <<A as Add<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N1Add_0 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Sub__0() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = Z0;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1Sub_0 = <<A as Sub<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N1Sub_0 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Mul__0() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = Z0;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N1Mul_0 = <<A as Mul<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N1Mul_0 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Min__0() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = Z0;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1Min_0 = <<A as Min<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N1Min_0 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Max__0() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = Z0;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N1Max_0 = <<A as Max<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N1Max_0 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Gcd__0() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = Z0;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1Gcd_0 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N1Gcd_0 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Pow__0() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = Z0;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1Pow_0 = <<A as Pow<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N1Pow_0 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Cmp__0() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = Z0;

    #[allow(non_camel_case_types)]
    type N1Cmp_0 = <A as Cmp<B>>::Output;
    assert_eq!(<N1Cmp_0 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Add_P1() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N1AddP1 = <<A as Add<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N1AddP1 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Sub_P1() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N1SubP1 = <<A as Sub<B>>::Output as Same<N2>>::Output;

    assert_eq!(<N1SubP1 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Mul_P1() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1MulP1 = <<A as Mul<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N1MulP1 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Min_P1() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1MinP1 = <<A as Min<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N1MinP1 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Max_P1() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1MaxP1 = <<A as Max<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N1MaxP1 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Gcd_P1() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1GcdP1 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N1GcdP1 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Div_P1() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1DivP1 = <<A as Div<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N1DivP1 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Rem_P1() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N1RemP1 = <<A as Rem<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N1RemP1 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_PartialDiv_P1() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1PartialDivP1 = <<A as PartialDiv<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N1PartialDivP1 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Pow_P1() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1PowP1 = <<A as Pow<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N1PowP1 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Cmp_P1() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1CmpP1 = <A as Cmp<B>>::Output;
    assert_eq!(<N1CmpP1 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Add_P2() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1AddP2 = <<A as Add<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N1AddP2 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Sub_P2() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type N3 = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N1SubP2 = <<A as Sub<B>>::Output as Same<N3>>::Output;

    assert_eq!(<N1SubP2 as Integer>::to_i64(), <N3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Mul_P2() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N1MulP2 = <<A as Mul<B>>::Output as Same<N2>>::Output;

    assert_eq!(<N1MulP2 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Min_P2() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1MinP2 = <<A as Min<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N1MinP2 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Max_P2() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N1MaxP2 = <<A as Max<B>>::Output as Same<P2>>::Output;

    assert_eq!(<N1MaxP2 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Gcd_P2() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1GcdP2 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N1GcdP2 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Div_P2() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N1DivP2 = <<A as Div<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N1DivP2 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Rem_P2() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1RemP2 = <<A as Rem<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N1RemP2 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Pow_P2() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1PowP2 = <<A as Pow<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N1PowP2 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Cmp_P2() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N1CmpP2 = <A as Cmp<B>>::Output;
    assert_eq!(<N1CmpP2 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Add_P3() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N1AddP3 = <<A as Add<B>>::Output as Same<P2>>::Output;

    assert_eq!(<N1AddP3 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Sub_P3() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type N4 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N1SubP3 = <<A as Sub<B>>::Output as Same<N4>>::Output;

    assert_eq!(<N1SubP3 as Integer>::to_i64(), <N4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Mul_P3() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type N3 = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N1MulP3 = <<A as Mul<B>>::Output as Same<N3>>::Output;

    assert_eq!(<N1MulP3 as Integer>::to_i64(), <N3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Min_P3() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1MinP3 = <<A as Min<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N1MinP3 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Max_P3() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N1MaxP3 = <<A as Max<B>>::Output as Same<P3>>::Output;

    assert_eq!(<N1MaxP3 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Gcd_P3() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1GcdP3 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N1GcdP3 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Div_P3() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N1DivP3 = <<A as Div<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N1DivP3 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Rem_P3() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1RemP3 = <<A as Rem<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N1RemP3 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Pow_P3() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1PowP3 = <<A as Pow<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N1PowP3 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Cmp_P3() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N1CmpP3 = <A as Cmp<B>>::Output;
    assert_eq!(<N1CmpP3 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Add_P4() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type N1AddP4 = <<A as Add<B>>::Output as Same<P3>>::Output;

    assert_eq!(<N1AddP4 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Sub_P4() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N5 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N1SubP4 = <<A as Sub<B>>::Output as Same<N5>>::Output;

    assert_eq!(<N1SubP4 as Integer>::to_i64(), <N5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Mul_P4() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N4 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N1MulP4 = <<A as Mul<B>>::Output as Same<N4>>::Output;

    assert_eq!(<N1MulP4 as Integer>::to_i64(), <N4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Min_P4() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1MinP4 = <<A as Min<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N1MinP4 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Max_P4() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N1MaxP4 = <<A as Max<B>>::Output as Same<P4>>::Output;

    assert_eq!(<N1MaxP4 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Gcd_P4() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1GcdP4 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N1GcdP4 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Div_P4() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N1DivP4 = <<A as Div<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N1DivP4 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Rem_P4() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1RemP4 = <<A as Rem<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N1RemP4 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Pow_P4() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1PowP4 = <<A as Pow<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N1PowP4 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Cmp_P4() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N1CmpP4 = <A as Cmp<B>>::Output;
    assert_eq!(<N1CmpP4 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Add_P5() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type N1AddP5 = <<A as Add<B>>::Output as Same<P4>>::Output;

    assert_eq!(<N1AddP5 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Sub_P5() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N6 = NInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type N1SubP5 = <<A as Sub<B>>::Output as Same<N6>>::Output;

    assert_eq!(<N1SubP5 as Integer>::to_i64(), <N6 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Mul_P5() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N5 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N1MulP5 = <<A as Mul<B>>::Output as Same<N5>>::Output;

    assert_eq!(<N1MulP5 as Integer>::to_i64(), <N5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Min_P5() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1MinP5 = <<A as Min<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N1MinP5 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Max_P5() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N1MaxP5 = <<A as Max<B>>::Output as Same<P5>>::Output;

    assert_eq!(<N1MaxP5 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Gcd_P5() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1GcdP5 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<N1GcdP5 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Div_P5() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type N1DivP5 = <<A as Div<B>>::Output as Same<_0>>::Output;

    assert_eq!(<N1DivP5 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Rem_P5() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1RemP5 = <<A as Rem<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N1RemP5 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Pow_P5() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type N1PowP5 = <<A as Pow<B>>::Output as Same<N1>>::Output;

    assert_eq!(<N1PowP5 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Cmp_P5() {
    type A = NInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type N1CmpP5 = <A as Cmp<B>>::Output;
    assert_eq!(<N1CmpP5 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test__0_Add_N5() {
    type A = Z0;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N5 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type _0AddN5 = <<A as Add<B>>::Output as Same<N5>>::Output;

    assert_eq!(<_0AddN5 as Integer>::to_i64(), <N5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Sub_N5() {
    type A = Z0;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type _0SubN5 = <<A as Sub<B>>::Output as Same<P5>>::Output;

    assert_eq!(<_0SubN5 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Mul_N5() {
    type A = Z0;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0MulN5 = <<A as Mul<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0MulN5 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Min_N5() {
    type A = Z0;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N5 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type _0MinN5 = <<A as Min<B>>::Output as Same<N5>>::Output;

    assert_eq!(<_0MinN5 as Integer>::to_i64(), <N5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Max_N5() {
    type A = Z0;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0MaxN5 = <<A as Max<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0MaxN5 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Gcd_N5() {
    type A = Z0;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type _0GcdN5 = <<A as Gcd<B>>::Output as Same<P5>>::Output;

    assert_eq!(<_0GcdN5 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Div_N5() {
    type A = Z0;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0DivN5 = <<A as Div<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0DivN5 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Rem_N5() {
    type A = Z0;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0RemN5 = <<A as Rem<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0RemN5 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_PartialDiv_N5() {
    type A = Z0;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0PartialDivN5 = <<A as PartialDiv<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0PartialDivN5 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Cmp_N5() {
    type A = Z0;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type _0CmpN5 = <A as Cmp<B>>::Output;
    assert_eq!(<_0CmpN5 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test__0_Add_N4() {
    type A = Z0;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N4 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type _0AddN4 = <<A as Add<B>>::Output as Same<N4>>::Output;

    assert_eq!(<_0AddN4 as Integer>::to_i64(), <N4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Sub_N4() {
    type A = Z0;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type _0SubN4 = <<A as Sub<B>>::Output as Same<P4>>::Output;

    assert_eq!(<_0SubN4 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Mul_N4() {
    type A = Z0;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0MulN4 = <<A as Mul<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0MulN4 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Min_N4() {
    type A = Z0;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N4 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type _0MinN4 = <<A as Min<B>>::Output as Same<N4>>::Output;

    assert_eq!(<_0MinN4 as Integer>::to_i64(), <N4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Max_N4() {
    type A = Z0;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0MaxN4 = <<A as Max<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0MaxN4 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Gcd_N4() {
    type A = Z0;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type _0GcdN4 = <<A as Gcd<B>>::Output as Same<P4>>::Output;

    assert_eq!(<_0GcdN4 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Div_N4() {
    type A = Z0;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0DivN4 = <<A as Div<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0DivN4 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Rem_N4() {
    type A = Z0;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0RemN4 = <<A as Rem<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0RemN4 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_PartialDiv_N4() {
    type A = Z0;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0PartialDivN4 = <<A as PartialDiv<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0PartialDivN4 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Cmp_N4() {
    type A = Z0;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type _0CmpN4 = <A as Cmp<B>>::Output;
    assert_eq!(<_0CmpN4 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test__0_Add_N3() {
    type A = Z0;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type N3 = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type _0AddN3 = <<A as Add<B>>::Output as Same<N3>>::Output;

    assert_eq!(<_0AddN3 as Integer>::to_i64(), <N3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Sub_N3() {
    type A = Z0;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type _0SubN3 = <<A as Sub<B>>::Output as Same<P3>>::Output;

    assert_eq!(<_0SubN3 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Mul_N3() {
    type A = Z0;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0MulN3 = <<A as Mul<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0MulN3 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Min_N3() {
    type A = Z0;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type N3 = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type _0MinN3 = <<A as Min<B>>::Output as Same<N3>>::Output;

    assert_eq!(<_0MinN3 as Integer>::to_i64(), <N3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Max_N3() {
    type A = Z0;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0MaxN3 = <<A as Max<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0MaxN3 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Gcd_N3() {
    type A = Z0;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type _0GcdN3 = <<A as Gcd<B>>::Output as Same<P3>>::Output;

    assert_eq!(<_0GcdN3 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Div_N3() {
    type A = Z0;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0DivN3 = <<A as Div<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0DivN3 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Rem_N3() {
    type A = Z0;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0RemN3 = <<A as Rem<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0RemN3 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_PartialDiv_N3() {
    type A = Z0;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0PartialDivN3 = <<A as PartialDiv<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0PartialDivN3 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Cmp_N3() {
    type A = Z0;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type _0CmpN3 = <A as Cmp<B>>::Output;
    assert_eq!(<_0CmpN3 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test__0_Add_N2() {
    type A = Z0;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type _0AddN2 = <<A as Add<B>>::Output as Same<N2>>::Output;

    assert_eq!(<_0AddN2 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Sub_N2() {
    type A = Z0;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type _0SubN2 = <<A as Sub<B>>::Output as Same<P2>>::Output;

    assert_eq!(<_0SubN2 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Mul_N2() {
    type A = Z0;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0MulN2 = <<A as Mul<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0MulN2 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Min_N2() {
    type A = Z0;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type _0MinN2 = <<A as Min<B>>::Output as Same<N2>>::Output;

    assert_eq!(<_0MinN2 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Max_N2() {
    type A = Z0;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0MaxN2 = <<A as Max<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0MaxN2 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Gcd_N2() {
    type A = Z0;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type _0GcdN2 = <<A as Gcd<B>>::Output as Same<P2>>::Output;

    assert_eq!(<_0GcdN2 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Div_N2() {
    type A = Z0;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0DivN2 = <<A as Div<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0DivN2 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Rem_N2() {
    type A = Z0;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0RemN2 = <<A as Rem<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0RemN2 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_PartialDiv_N2() {
    type A = Z0;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0PartialDivN2 = <<A as PartialDiv<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0PartialDivN2 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Cmp_N2() {
    type A = Z0;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type _0CmpN2 = <A as Cmp<B>>::Output;
    assert_eq!(<_0CmpN2 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test__0_Add_N1() {
    type A = Z0;
    type B = NInt<UInt<UTerm, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type _0AddN1 = <<A as Add<B>>::Output as Same<N1>>::Output;

    assert_eq!(<_0AddN1 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Sub_N1() {
    type A = Z0;
    type B = NInt<UInt<UTerm, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type _0SubN1 = <<A as Sub<B>>::Output as Same<P1>>::Output;

    assert_eq!(<_0SubN1 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Mul_N1() {
    type A = Z0;
    type B = NInt<UInt<UTerm, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0MulN1 = <<A as Mul<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0MulN1 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Min_N1() {
    type A = Z0;
    type B = NInt<UInt<UTerm, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type _0MinN1 = <<A as Min<B>>::Output as Same<N1>>::Output;

    assert_eq!(<_0MinN1 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Max_N1() {
    type A = Z0;
    type B = NInt<UInt<UTerm, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0MaxN1 = <<A as Max<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0MaxN1 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Gcd_N1() {
    type A = Z0;
    type B = NInt<UInt<UTerm, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type _0GcdN1 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<_0GcdN1 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Div_N1() {
    type A = Z0;
    type B = NInt<UInt<UTerm, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0DivN1 = <<A as Div<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0DivN1 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Rem_N1() {
    type A = Z0;
    type B = NInt<UInt<UTerm, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0RemN1 = <<A as Rem<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0RemN1 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_PartialDiv_N1() {
    type A = Z0;
    type B = NInt<UInt<UTerm, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0PartialDivN1 = <<A as PartialDiv<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0PartialDivN1 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Cmp_N1() {
    type A = Z0;
    type B = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type _0CmpN1 = <A as Cmp<B>>::Output;
    assert_eq!(<_0CmpN1 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test__0_Add__0() {
    type A = Z0;
    type B = Z0;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0Add_0 = <<A as Add<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0Add_0 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Sub__0() {
    type A = Z0;
    type B = Z0;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0Sub_0 = <<A as Sub<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0Sub_0 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Mul__0() {
    type A = Z0;
    type B = Z0;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0Mul_0 = <<A as Mul<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0Mul_0 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Min__0() {
    type A = Z0;
    type B = Z0;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0Min_0 = <<A as Min<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0Min_0 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Max__0() {
    type A = Z0;
    type B = Z0;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0Max_0 = <<A as Max<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0Max_0 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Gcd__0() {
    type A = Z0;
    type B = Z0;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0Gcd_0 = <<A as Gcd<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0Gcd_0 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Pow__0() {
    type A = Z0;
    type B = Z0;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type _0Pow_0 = <<A as Pow<B>>::Output as Same<P1>>::Output;

    assert_eq!(<_0Pow_0 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Cmp__0() {
    type A = Z0;
    type B = Z0;

    #[allow(non_camel_case_types)]
    type _0Cmp_0 = <A as Cmp<B>>::Output;
    assert_eq!(<_0Cmp_0 as Ord>::to_ordering(), Ordering::Equal);
}
#[test]
#[allow(non_snake_case)]
fn test__0_Add_P1() {
    type A = Z0;
    type B = PInt<UInt<UTerm, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type _0AddP1 = <<A as Add<B>>::Output as Same<P1>>::Output;

    assert_eq!(<_0AddP1 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Sub_P1() {
    type A = Z0;
    type B = PInt<UInt<UTerm, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type _0SubP1 = <<A as Sub<B>>::Output as Same<N1>>::Output;

    assert_eq!(<_0SubP1 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Mul_P1() {
    type A = Z0;
    type B = PInt<UInt<UTerm, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0MulP1 = <<A as Mul<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0MulP1 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Min_P1() {
    type A = Z0;
    type B = PInt<UInt<UTerm, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0MinP1 = <<A as Min<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0MinP1 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Max_P1() {
    type A = Z0;
    type B = PInt<UInt<UTerm, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type _0MaxP1 = <<A as Max<B>>::Output as Same<P1>>::Output;

    assert_eq!(<_0MaxP1 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Gcd_P1() {
    type A = Z0;
    type B = PInt<UInt<UTerm, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type _0GcdP1 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<_0GcdP1 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Div_P1() {
    type A = Z0;
    type B = PInt<UInt<UTerm, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0DivP1 = <<A as Div<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0DivP1 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Rem_P1() {
    type A = Z0;
    type B = PInt<UInt<UTerm, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0RemP1 = <<A as Rem<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0RemP1 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_PartialDiv_P1() {
    type A = Z0;
    type B = PInt<UInt<UTerm, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0PartialDivP1 = <<A as PartialDiv<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0PartialDivP1 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Pow_P1() {
    type A = Z0;
    type B = PInt<UInt<UTerm, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0PowP1 = <<A as Pow<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0PowP1 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Cmp_P1() {
    type A = Z0;
    type B = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type _0CmpP1 = <A as Cmp<B>>::Output;
    assert_eq!(<_0CmpP1 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test__0_Add_P2() {
    type A = Z0;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type _0AddP2 = <<A as Add<B>>::Output as Same<P2>>::Output;

    assert_eq!(<_0AddP2 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Sub_P2() {
    type A = Z0;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type _0SubP2 = <<A as Sub<B>>::Output as Same<N2>>::Output;

    assert_eq!(<_0SubP2 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Mul_P2() {
    type A = Z0;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0MulP2 = <<A as Mul<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0MulP2 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Min_P2() {
    type A = Z0;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0MinP2 = <<A as Min<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0MinP2 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Max_P2() {
    type A = Z0;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type _0MaxP2 = <<A as Max<B>>::Output as Same<P2>>::Output;

    assert_eq!(<_0MaxP2 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Gcd_P2() {
    type A = Z0;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type _0GcdP2 = <<A as Gcd<B>>::Output as Same<P2>>::Output;

    assert_eq!(<_0GcdP2 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Div_P2() {
    type A = Z0;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0DivP2 = <<A as Div<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0DivP2 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Rem_P2() {
    type A = Z0;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0RemP2 = <<A as Rem<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0RemP2 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_PartialDiv_P2() {
    type A = Z0;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0PartialDivP2 = <<A as PartialDiv<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0PartialDivP2 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Pow_P2() {
    type A = Z0;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0PowP2 = <<A as Pow<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0PowP2 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Cmp_P2() {
    type A = Z0;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type _0CmpP2 = <A as Cmp<B>>::Output;
    assert_eq!(<_0CmpP2 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test__0_Add_P3() {
    type A = Z0;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type _0AddP3 = <<A as Add<B>>::Output as Same<P3>>::Output;

    assert_eq!(<_0AddP3 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Sub_P3() {
    type A = Z0;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type N3 = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type _0SubP3 = <<A as Sub<B>>::Output as Same<N3>>::Output;

    assert_eq!(<_0SubP3 as Integer>::to_i64(), <N3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Mul_P3() {
    type A = Z0;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0MulP3 = <<A as Mul<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0MulP3 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Min_P3() {
    type A = Z0;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0MinP3 = <<A as Min<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0MinP3 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Max_P3() {
    type A = Z0;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type _0MaxP3 = <<A as Max<B>>::Output as Same<P3>>::Output;

    assert_eq!(<_0MaxP3 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Gcd_P3() {
    type A = Z0;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type _0GcdP3 = <<A as Gcd<B>>::Output as Same<P3>>::Output;

    assert_eq!(<_0GcdP3 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Div_P3() {
    type A = Z0;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0DivP3 = <<A as Div<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0DivP3 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Rem_P3() {
    type A = Z0;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0RemP3 = <<A as Rem<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0RemP3 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_PartialDiv_P3() {
    type A = Z0;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0PartialDivP3 = <<A as PartialDiv<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0PartialDivP3 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Pow_P3() {
    type A = Z0;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0PowP3 = <<A as Pow<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0PowP3 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Cmp_P3() {
    type A = Z0;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type _0CmpP3 = <A as Cmp<B>>::Output;
    assert_eq!(<_0CmpP3 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test__0_Add_P4() {
    type A = Z0;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type _0AddP4 = <<A as Add<B>>::Output as Same<P4>>::Output;

    assert_eq!(<_0AddP4 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Sub_P4() {
    type A = Z0;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N4 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type _0SubP4 = <<A as Sub<B>>::Output as Same<N4>>::Output;

    assert_eq!(<_0SubP4 as Integer>::to_i64(), <N4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Mul_P4() {
    type A = Z0;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0MulP4 = <<A as Mul<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0MulP4 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Min_P4() {
    type A = Z0;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0MinP4 = <<A as Min<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0MinP4 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Max_P4() {
    type A = Z0;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type _0MaxP4 = <<A as Max<B>>::Output as Same<P4>>::Output;

    assert_eq!(<_0MaxP4 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Gcd_P4() {
    type A = Z0;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type _0GcdP4 = <<A as Gcd<B>>::Output as Same<P4>>::Output;

    assert_eq!(<_0GcdP4 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Div_P4() {
    type A = Z0;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0DivP4 = <<A as Div<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0DivP4 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Rem_P4() {
    type A = Z0;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0RemP4 = <<A as Rem<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0RemP4 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_PartialDiv_P4() {
    type A = Z0;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0PartialDivP4 = <<A as PartialDiv<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0PartialDivP4 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Pow_P4() {
    type A = Z0;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0PowP4 = <<A as Pow<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0PowP4 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Cmp_P4() {
    type A = Z0;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type _0CmpP4 = <A as Cmp<B>>::Output;
    assert_eq!(<_0CmpP4 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test__0_Add_P5() {
    type A = Z0;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type _0AddP5 = <<A as Add<B>>::Output as Same<P5>>::Output;

    assert_eq!(<_0AddP5 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Sub_P5() {
    type A = Z0;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N5 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type _0SubP5 = <<A as Sub<B>>::Output as Same<N5>>::Output;

    assert_eq!(<_0SubP5 as Integer>::to_i64(), <N5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Mul_P5() {
    type A = Z0;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0MulP5 = <<A as Mul<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0MulP5 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Min_P5() {
    type A = Z0;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0MinP5 = <<A as Min<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0MinP5 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Max_P5() {
    type A = Z0;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type _0MaxP5 = <<A as Max<B>>::Output as Same<P5>>::Output;

    assert_eq!(<_0MaxP5 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Gcd_P5() {
    type A = Z0;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type _0GcdP5 = <<A as Gcd<B>>::Output as Same<P5>>::Output;

    assert_eq!(<_0GcdP5 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Div_P5() {
    type A = Z0;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0DivP5 = <<A as Div<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0DivP5 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Rem_P5() {
    type A = Z0;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0RemP5 = <<A as Rem<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0RemP5 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_PartialDiv_P5() {
    type A = Z0;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0PartialDivP5 = <<A as PartialDiv<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0PartialDivP5 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Pow_P5() {
    type A = Z0;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type _0PowP5 = <<A as Pow<B>>::Output as Same<_0>>::Output;

    assert_eq!(<_0PowP5 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Cmp_P5() {
    type A = Z0;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type _0CmpP5 = <A as Cmp<B>>::Output;
    assert_eq!(<_0CmpP5 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Add_N5() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N4 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P1AddN5 = <<A as Add<B>>::Output as Same<N4>>::Output;

    assert_eq!(<P1AddN5 as Integer>::to_i64(), <N4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Sub_N5() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P6 = PInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P1SubN5 = <<A as Sub<B>>::Output as Same<P6>>::Output;

    assert_eq!(<P1SubN5 as Integer>::to_i64(), <P6 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Mul_N5() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N5 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P1MulN5 = <<A as Mul<B>>::Output as Same<N5>>::Output;

    assert_eq!(<P1MulN5 as Integer>::to_i64(), <N5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Min_N5() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N5 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P1MinN5 = <<A as Min<B>>::Output as Same<N5>>::Output;

    assert_eq!(<P1MinN5 as Integer>::to_i64(), <N5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Max_N5() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1MaxN5 = <<A as Max<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P1MaxN5 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Gcd_N5() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1GcdN5 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P1GcdN5 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Div_N5() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P1DivN5 = <<A as Div<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P1DivN5 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Rem_N5() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1RemN5 = <<A as Rem<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P1RemN5 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Pow_N5() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1PowN5 = <<A as Pow<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P1PowN5 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Cmp_N5() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P1CmpN5 = <A as Cmp<B>>::Output;
    assert_eq!(<P1CmpN5 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Add_N4() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N3 = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P1AddN4 = <<A as Add<B>>::Output as Same<N3>>::Output;

    assert_eq!(<P1AddN4 as Integer>::to_i64(), <N3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Sub_N4() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P1SubN4 = <<A as Sub<B>>::Output as Same<P5>>::Output;

    assert_eq!(<P1SubN4 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Mul_N4() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N4 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P1MulN4 = <<A as Mul<B>>::Output as Same<N4>>::Output;

    assert_eq!(<P1MulN4 as Integer>::to_i64(), <N4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Min_N4() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N4 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P1MinN4 = <<A as Min<B>>::Output as Same<N4>>::Output;

    assert_eq!(<P1MinN4 as Integer>::to_i64(), <N4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Max_N4() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1MaxN4 = <<A as Max<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P1MaxN4 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Gcd_N4() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1GcdN4 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P1GcdN4 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Div_N4() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P1DivN4 = <<A as Div<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P1DivN4 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Rem_N4() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1RemN4 = <<A as Rem<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P1RemN4 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Pow_N4() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1PowN4 = <<A as Pow<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P1PowN4 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Cmp_N4() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P1CmpN4 = <A as Cmp<B>>::Output;
    assert_eq!(<P1CmpN4 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Add_N3() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P1AddN3 = <<A as Add<B>>::Output as Same<N2>>::Output;

    assert_eq!(<P1AddN3 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Sub_N3() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P1SubN3 = <<A as Sub<B>>::Output as Same<P4>>::Output;

    assert_eq!(<P1SubN3 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Mul_N3() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type N3 = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P1MulN3 = <<A as Mul<B>>::Output as Same<N3>>::Output;

    assert_eq!(<P1MulN3 as Integer>::to_i64(), <N3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Min_N3() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type N3 = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P1MinN3 = <<A as Min<B>>::Output as Same<N3>>::Output;

    assert_eq!(<P1MinN3 as Integer>::to_i64(), <N3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Max_N3() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1MaxN3 = <<A as Max<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P1MaxN3 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Gcd_N3() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1GcdN3 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P1GcdN3 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Div_N3() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P1DivN3 = <<A as Div<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P1DivN3 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Rem_N3() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1RemN3 = <<A as Rem<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P1RemN3 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Pow_N3() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1PowN3 = <<A as Pow<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P1PowN3 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Cmp_N3() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P1CmpN3 = <A as Cmp<B>>::Output;
    assert_eq!(<P1CmpN3 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Add_N2() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1AddN2 = <<A as Add<B>>::Output as Same<N1>>::Output;

    assert_eq!(<P1AddN2 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Sub_N2() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P1SubN2 = <<A as Sub<B>>::Output as Same<P3>>::Output;

    assert_eq!(<P1SubN2 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Mul_N2() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P1MulN2 = <<A as Mul<B>>::Output as Same<N2>>::Output;

    assert_eq!(<P1MulN2 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Min_N2() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P1MinN2 = <<A as Min<B>>::Output as Same<N2>>::Output;

    assert_eq!(<P1MinN2 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Max_N2() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1MaxN2 = <<A as Max<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P1MaxN2 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Gcd_N2() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1GcdN2 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P1GcdN2 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Div_N2() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P1DivN2 = <<A as Div<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P1DivN2 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Rem_N2() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1RemN2 = <<A as Rem<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P1RemN2 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Pow_N2() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1PowN2 = <<A as Pow<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P1PowN2 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Cmp_N2() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P1CmpN2 = <A as Cmp<B>>::Output;
    assert_eq!(<P1CmpN2 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Add_N1() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P1AddN1 = <<A as Add<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P1AddN1 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Sub_N1() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P1SubN1 = <<A as Sub<B>>::Output as Same<P2>>::Output;

    assert_eq!(<P1SubN1 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Mul_N1() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1MulN1 = <<A as Mul<B>>::Output as Same<N1>>::Output;

    assert_eq!(<P1MulN1 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Min_N1() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1MinN1 = <<A as Min<B>>::Output as Same<N1>>::Output;

    assert_eq!(<P1MinN1 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Max_N1() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1MaxN1 = <<A as Max<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P1MaxN1 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Gcd_N1() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1GcdN1 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P1GcdN1 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Div_N1() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1DivN1 = <<A as Div<B>>::Output as Same<N1>>::Output;

    assert_eq!(<P1DivN1 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Rem_N1() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P1RemN1 = <<A as Rem<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P1RemN1 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_PartialDiv_N1() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1PartialDivN1 = <<A as PartialDiv<B>>::Output as Same<N1>>::Output;

    assert_eq!(<P1PartialDivN1 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Pow_N1() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1PowN1 = <<A as Pow<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P1PowN1 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Cmp_N1() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1CmpN1 = <A as Cmp<B>>::Output;
    assert_eq!(<P1CmpN1 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Add__0() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = Z0;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1Add_0 = <<A as Add<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P1Add_0 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Sub__0() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = Z0;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1Sub_0 = <<A as Sub<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P1Sub_0 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Mul__0() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = Z0;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P1Mul_0 = <<A as Mul<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P1Mul_0 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Min__0() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = Z0;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P1Min_0 = <<A as Min<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P1Min_0 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Max__0() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = Z0;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1Max_0 = <<A as Max<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P1Max_0 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Gcd__0() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = Z0;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1Gcd_0 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P1Gcd_0 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Pow__0() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = Z0;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1Pow_0 = <<A as Pow<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P1Pow_0 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Cmp__0() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = Z0;

    #[allow(non_camel_case_types)]
    type P1Cmp_0 = <A as Cmp<B>>::Output;
    assert_eq!(<P1Cmp_0 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Add_P1() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P1AddP1 = <<A as Add<B>>::Output as Same<P2>>::Output;

    assert_eq!(<P1AddP1 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Sub_P1() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P1SubP1 = <<A as Sub<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P1SubP1 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Mul_P1() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1MulP1 = <<A as Mul<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P1MulP1 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Min_P1() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1MinP1 = <<A as Min<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P1MinP1 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Max_P1() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1MaxP1 = <<A as Max<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P1MaxP1 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Gcd_P1() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1GcdP1 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P1GcdP1 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Div_P1() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1DivP1 = <<A as Div<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P1DivP1 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Rem_P1() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P1RemP1 = <<A as Rem<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P1RemP1 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_PartialDiv_P1() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1PartialDivP1 = <<A as PartialDiv<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P1PartialDivP1 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Pow_P1() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1PowP1 = <<A as Pow<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P1PowP1 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Cmp_P1() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1CmpP1 = <A as Cmp<B>>::Output;
    assert_eq!(<P1CmpP1 as Ord>::to_ordering(), Ordering::Equal);
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Add_P2() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P1AddP2 = <<A as Add<B>>::Output as Same<P3>>::Output;

    assert_eq!(<P1AddP2 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Sub_P2() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1SubP2 = <<A as Sub<B>>::Output as Same<N1>>::Output;

    assert_eq!(<P1SubP2 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Mul_P2() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P1MulP2 = <<A as Mul<B>>::Output as Same<P2>>::Output;

    assert_eq!(<P1MulP2 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Min_P2() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1MinP2 = <<A as Min<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P1MinP2 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Max_P2() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P1MaxP2 = <<A as Max<B>>::Output as Same<P2>>::Output;

    assert_eq!(<P1MaxP2 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Gcd_P2() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1GcdP2 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P1GcdP2 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Div_P2() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P1DivP2 = <<A as Div<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P1DivP2 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Rem_P2() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1RemP2 = <<A as Rem<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P1RemP2 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Pow_P2() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1PowP2 = <<A as Pow<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P1PowP2 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Cmp_P2() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P1CmpP2 = <A as Cmp<B>>::Output;
    assert_eq!(<P1CmpP2 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Add_P3() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P1AddP3 = <<A as Add<B>>::Output as Same<P4>>::Output;

    assert_eq!(<P1AddP3 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Sub_P3() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P1SubP3 = <<A as Sub<B>>::Output as Same<N2>>::Output;

    assert_eq!(<P1SubP3 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Mul_P3() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P1MulP3 = <<A as Mul<B>>::Output as Same<P3>>::Output;

    assert_eq!(<P1MulP3 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Min_P3() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1MinP3 = <<A as Min<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P1MinP3 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Max_P3() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P1MaxP3 = <<A as Max<B>>::Output as Same<P3>>::Output;

    assert_eq!(<P1MaxP3 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Gcd_P3() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1GcdP3 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P1GcdP3 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Div_P3() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P1DivP3 = <<A as Div<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P1DivP3 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Rem_P3() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1RemP3 = <<A as Rem<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P1RemP3 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Pow_P3() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1PowP3 = <<A as Pow<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P1PowP3 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Cmp_P3() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P1CmpP3 = <A as Cmp<B>>::Output;
    assert_eq!(<P1CmpP3 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Add_P4() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P1AddP4 = <<A as Add<B>>::Output as Same<P5>>::Output;

    assert_eq!(<P1AddP4 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Sub_P4() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N3 = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P1SubP4 = <<A as Sub<B>>::Output as Same<N3>>::Output;

    assert_eq!(<P1SubP4 as Integer>::to_i64(), <N3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Mul_P4() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P1MulP4 = <<A as Mul<B>>::Output as Same<P4>>::Output;

    assert_eq!(<P1MulP4 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Min_P4() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1MinP4 = <<A as Min<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P1MinP4 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Max_P4() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P1MaxP4 = <<A as Max<B>>::Output as Same<P4>>::Output;

    assert_eq!(<P1MaxP4 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Gcd_P4() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1GcdP4 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P1GcdP4 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Div_P4() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P1DivP4 = <<A as Div<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P1DivP4 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Rem_P4() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1RemP4 = <<A as Rem<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P1RemP4 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Pow_P4() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1PowP4 = <<A as Pow<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P1PowP4 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Cmp_P4() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P1CmpP4 = <A as Cmp<B>>::Output;
    assert_eq!(<P1CmpP4 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Add_P5() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P6 = PInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P1AddP5 = <<A as Add<B>>::Output as Same<P6>>::Output;

    assert_eq!(<P1AddP5 as Integer>::to_i64(), <P6 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Sub_P5() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N4 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P1SubP5 = <<A as Sub<B>>::Output as Same<N4>>::Output;

    assert_eq!(<P1SubP5 as Integer>::to_i64(), <N4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Mul_P5() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P1MulP5 = <<A as Mul<B>>::Output as Same<P5>>::Output;

    assert_eq!(<P1MulP5 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Min_P5() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1MinP5 = <<A as Min<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P1MinP5 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Max_P5() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P1MaxP5 = <<A as Max<B>>::Output as Same<P5>>::Output;

    assert_eq!(<P1MaxP5 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Gcd_P5() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1GcdP5 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P1GcdP5 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Div_P5() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P1DivP5 = <<A as Div<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P1DivP5 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Rem_P5() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1RemP5 = <<A as Rem<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P1RemP5 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Pow_P5() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P1PowP5 = <<A as Pow<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P1PowP5 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Cmp_P5() {
    type A = PInt<UInt<UTerm, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P1CmpP5 = <A as Cmp<B>>::Output;
    assert_eq!(<P1CmpP5 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Add_N5() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N3 = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P2AddN5 = <<A as Add<B>>::Output as Same<N3>>::Output;

    assert_eq!(<P2AddN5 as Integer>::to_i64(), <N3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Sub_N5() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P7 = PInt<UInt<UInt<UInt<UTerm, B1>, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P2SubN5 = <<A as Sub<B>>::Output as Same<P7>>::Output;

    assert_eq!(<P2SubN5 as Integer>::to_i64(), <P7 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Mul_N5() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N10 = NInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P2MulN5 = <<A as Mul<B>>::Output as Same<N10>>::Output;

    assert_eq!(<P2MulN5 as Integer>::to_i64(), <N10 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Min_N5() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N5 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P2MinN5 = <<A as Min<B>>::Output as Same<N5>>::Output;

    assert_eq!(<P2MinN5 as Integer>::to_i64(), <N5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Max_N5() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P2MaxN5 = <<A as Max<B>>::Output as Same<P2>>::Output;

    assert_eq!(<P2MaxN5 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Gcd_N5() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P2GcdN5 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P2GcdN5 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Div_N5() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P2DivN5 = <<A as Div<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P2DivN5 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Rem_N5() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P2RemN5 = <<A as Rem<B>>::Output as Same<P2>>::Output;

    assert_eq!(<P2RemN5 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Cmp_N5() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P2CmpN5 = <A as Cmp<B>>::Output;
    assert_eq!(<P2CmpN5 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Add_N4() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P2AddN4 = <<A as Add<B>>::Output as Same<N2>>::Output;

    assert_eq!(<P2AddN4 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Sub_N4() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P6 = PInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P2SubN4 = <<A as Sub<B>>::Output as Same<P6>>::Output;

    assert_eq!(<P2SubN4 as Integer>::to_i64(), <P6 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Mul_N4() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N8 = NInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P2MulN4 = <<A as Mul<B>>::Output as Same<N8>>::Output;

    assert_eq!(<P2MulN4 as Integer>::to_i64(), <N8 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Min_N4() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N4 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P2MinN4 = <<A as Min<B>>::Output as Same<N4>>::Output;

    assert_eq!(<P2MinN4 as Integer>::to_i64(), <N4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Max_N4() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P2MaxN4 = <<A as Max<B>>::Output as Same<P2>>::Output;

    assert_eq!(<P2MaxN4 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Gcd_N4() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P2GcdN4 = <<A as Gcd<B>>::Output as Same<P2>>::Output;

    assert_eq!(<P2GcdN4 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Div_N4() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P2DivN4 = <<A as Div<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P2DivN4 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Rem_N4() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P2RemN4 = <<A as Rem<B>>::Output as Same<P2>>::Output;

    assert_eq!(<P2RemN4 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Cmp_N4() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P2CmpN4 = <A as Cmp<B>>::Output;
    assert_eq!(<P2CmpN4 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Add_N3() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P2AddN3 = <<A as Add<B>>::Output as Same<N1>>::Output;

    assert_eq!(<P2AddN3 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Sub_N3() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P2SubN3 = <<A as Sub<B>>::Output as Same<P5>>::Output;

    assert_eq!(<P2SubN3 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Mul_N3() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type N6 = NInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P2MulN3 = <<A as Mul<B>>::Output as Same<N6>>::Output;

    assert_eq!(<P2MulN3 as Integer>::to_i64(), <N6 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Min_N3() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type N3 = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P2MinN3 = <<A as Min<B>>::Output as Same<N3>>::Output;

    assert_eq!(<P2MinN3 as Integer>::to_i64(), <N3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Max_N3() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P2MaxN3 = <<A as Max<B>>::Output as Same<P2>>::Output;

    assert_eq!(<P2MaxN3 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Gcd_N3() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P2GcdN3 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P2GcdN3 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Div_N3() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P2DivN3 = <<A as Div<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P2DivN3 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Rem_N3() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P2RemN3 = <<A as Rem<B>>::Output as Same<P2>>::Output;

    assert_eq!(<P2RemN3 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Cmp_N3() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P2CmpN3 = <A as Cmp<B>>::Output;
    assert_eq!(<P2CmpN3 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Add_N2() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P2AddN2 = <<A as Add<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P2AddN2 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Sub_N2() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P2SubN2 = <<A as Sub<B>>::Output as Same<P4>>::Output;

    assert_eq!(<P2SubN2 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Mul_N2() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type N4 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P2MulN2 = <<A as Mul<B>>::Output as Same<N4>>::Output;

    assert_eq!(<P2MulN2 as Integer>::to_i64(), <N4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Min_N2() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P2MinN2 = <<A as Min<B>>::Output as Same<N2>>::Output;

    assert_eq!(<P2MinN2 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Max_N2() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P2MaxN2 = <<A as Max<B>>::Output as Same<P2>>::Output;

    assert_eq!(<P2MaxN2 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Gcd_N2() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P2GcdN2 = <<A as Gcd<B>>::Output as Same<P2>>::Output;

    assert_eq!(<P2GcdN2 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Div_N2() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P2DivN2 = <<A as Div<B>>::Output as Same<N1>>::Output;

    assert_eq!(<P2DivN2 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Rem_N2() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P2RemN2 = <<A as Rem<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P2RemN2 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_PartialDiv_N2() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P2PartialDivN2 = <<A as PartialDiv<B>>::Output as Same<N1>>::Output;

    assert_eq!(<P2PartialDivN2 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Cmp_N2() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P2CmpN2 = <A as Cmp<B>>::Output;
    assert_eq!(<P2CmpN2 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Add_N1() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UTerm, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P2AddN1 = <<A as Add<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P2AddN1 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Sub_N1() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UTerm, B1>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P2SubN1 = <<A as Sub<B>>::Output as Same<P3>>::Output;

    assert_eq!(<P2SubN1 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Mul_N1() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UTerm, B1>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P2MulN1 = <<A as Mul<B>>::Output as Same<N2>>::Output;

    assert_eq!(<P2MulN1 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Min_N1() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UTerm, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P2MinN1 = <<A as Min<B>>::Output as Same<N1>>::Output;

    assert_eq!(<P2MinN1 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Max_N1() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UTerm, B1>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P2MaxN1 = <<A as Max<B>>::Output as Same<P2>>::Output;

    assert_eq!(<P2MaxN1 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Gcd_N1() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UTerm, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P2GcdN1 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P2GcdN1 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Div_N1() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UTerm, B1>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P2DivN1 = <<A as Div<B>>::Output as Same<N2>>::Output;

    assert_eq!(<P2DivN1 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Rem_N1() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UTerm, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P2RemN1 = <<A as Rem<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P2RemN1 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_PartialDiv_N1() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UTerm, B1>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P2PartialDivN1 = <<A as PartialDiv<B>>::Output as Same<N2>>::Output;

    assert_eq!(<P2PartialDivN1 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Cmp_N1() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P2CmpN1 = <A as Cmp<B>>::Output;
    assert_eq!(<P2CmpN1 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Add__0() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = Z0;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P2Add_0 = <<A as Add<B>>::Output as Same<P2>>::Output;

    assert_eq!(<P2Add_0 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Sub__0() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = Z0;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P2Sub_0 = <<A as Sub<B>>::Output as Same<P2>>::Output;

    assert_eq!(<P2Sub_0 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Mul__0() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = Z0;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P2Mul_0 = <<A as Mul<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P2Mul_0 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Min__0() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = Z0;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P2Min_0 = <<A as Min<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P2Min_0 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Max__0() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = Z0;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P2Max_0 = <<A as Max<B>>::Output as Same<P2>>::Output;

    assert_eq!(<P2Max_0 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Gcd__0() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = Z0;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P2Gcd_0 = <<A as Gcd<B>>::Output as Same<P2>>::Output;

    assert_eq!(<P2Gcd_0 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Pow__0() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = Z0;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P2Pow_0 = <<A as Pow<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P2Pow_0 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Cmp__0() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = Z0;

    #[allow(non_camel_case_types)]
    type P2Cmp_0 = <A as Cmp<B>>::Output;
    assert_eq!(<P2Cmp_0 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Add_P1() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P2AddP1 = <<A as Add<B>>::Output as Same<P3>>::Output;

    assert_eq!(<P2AddP1 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Sub_P1() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P2SubP1 = <<A as Sub<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P2SubP1 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Mul_P1() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P2MulP1 = <<A as Mul<B>>::Output as Same<P2>>::Output;

    assert_eq!(<P2MulP1 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Min_P1() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P2MinP1 = <<A as Min<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P2MinP1 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Max_P1() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P2MaxP1 = <<A as Max<B>>::Output as Same<P2>>::Output;

    assert_eq!(<P2MaxP1 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Gcd_P1() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P2GcdP1 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P2GcdP1 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Div_P1() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P2DivP1 = <<A as Div<B>>::Output as Same<P2>>::Output;

    assert_eq!(<P2DivP1 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Rem_P1() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UTerm, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P2RemP1 = <<A as Rem<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P2RemP1 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_PartialDiv_P1() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P2PartialDivP1 = <<A as PartialDiv<B>>::Output as Same<P2>>::Output;

    assert_eq!(<P2PartialDivP1 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Pow_P1() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P2PowP1 = <<A as Pow<B>>::Output as Same<P2>>::Output;

    assert_eq!(<P2PowP1 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Cmp_P1() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P2CmpP1 = <A as Cmp<B>>::Output;
    assert_eq!(<P2CmpP1 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Add_P2() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P2AddP2 = <<A as Add<B>>::Output as Same<P4>>::Output;

    assert_eq!(<P2AddP2 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Sub_P2() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P2SubP2 = <<A as Sub<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P2SubP2 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Mul_P2() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P2MulP2 = <<A as Mul<B>>::Output as Same<P4>>::Output;

    assert_eq!(<P2MulP2 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Min_P2() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P2MinP2 = <<A as Min<B>>::Output as Same<P2>>::Output;

    assert_eq!(<P2MinP2 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Max_P2() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P2MaxP2 = <<A as Max<B>>::Output as Same<P2>>::Output;

    assert_eq!(<P2MaxP2 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Gcd_P2() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P2GcdP2 = <<A as Gcd<B>>::Output as Same<P2>>::Output;

    assert_eq!(<P2GcdP2 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Div_P2() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P2DivP2 = <<A as Div<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P2DivP2 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Rem_P2() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P2RemP2 = <<A as Rem<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P2RemP2 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_PartialDiv_P2() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P2PartialDivP2 = <<A as PartialDiv<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P2PartialDivP2 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Pow_P2() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P2PowP2 = <<A as Pow<B>>::Output as Same<P4>>::Output;

    assert_eq!(<P2PowP2 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Cmp_P2() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P2CmpP2 = <A as Cmp<B>>::Output;
    assert_eq!(<P2CmpP2 as Ord>::to_ordering(), Ordering::Equal);
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Add_P3() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P2AddP3 = <<A as Add<B>>::Output as Same<P5>>::Output;

    assert_eq!(<P2AddP3 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Sub_P3() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P2SubP3 = <<A as Sub<B>>::Output as Same<N1>>::Output;

    assert_eq!(<P2SubP3 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Mul_P3() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P6 = PInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P2MulP3 = <<A as Mul<B>>::Output as Same<P6>>::Output;

    assert_eq!(<P2MulP3 as Integer>::to_i64(), <P6 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Min_P3() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P2MinP3 = <<A as Min<B>>::Output as Same<P2>>::Output;

    assert_eq!(<P2MinP3 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Max_P3() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P2MaxP3 = <<A as Max<B>>::Output as Same<P3>>::Output;

    assert_eq!(<P2MaxP3 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Gcd_P3() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P2GcdP3 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P2GcdP3 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Div_P3() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P2DivP3 = <<A as Div<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P2DivP3 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Rem_P3() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P2RemP3 = <<A as Rem<B>>::Output as Same<P2>>::Output;

    assert_eq!(<P2RemP3 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Pow_P3() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P8 = PInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P2PowP3 = <<A as Pow<B>>::Output as Same<P8>>::Output;

    assert_eq!(<P2PowP3 as Integer>::to_i64(), <P8 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Cmp_P3() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P2CmpP3 = <A as Cmp<B>>::Output;
    assert_eq!(<P2CmpP3 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Add_P4() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P6 = PInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P2AddP4 = <<A as Add<B>>::Output as Same<P6>>::Output;

    assert_eq!(<P2AddP4 as Integer>::to_i64(), <P6 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Sub_P4() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P2SubP4 = <<A as Sub<B>>::Output as Same<N2>>::Output;

    assert_eq!(<P2SubP4 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Mul_P4() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P8 = PInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P2MulP4 = <<A as Mul<B>>::Output as Same<P8>>::Output;

    assert_eq!(<P2MulP4 as Integer>::to_i64(), <P8 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Min_P4() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P2MinP4 = <<A as Min<B>>::Output as Same<P2>>::Output;

    assert_eq!(<P2MinP4 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Max_P4() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P2MaxP4 = <<A as Max<B>>::Output as Same<P4>>::Output;

    assert_eq!(<P2MaxP4 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Gcd_P4() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P2GcdP4 = <<A as Gcd<B>>::Output as Same<P2>>::Output;

    assert_eq!(<P2GcdP4 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Div_P4() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P2DivP4 = <<A as Div<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P2DivP4 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Rem_P4() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P2RemP4 = <<A as Rem<B>>::Output as Same<P2>>::Output;

    assert_eq!(<P2RemP4 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Pow_P4() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P16 = PInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P2PowP4 = <<A as Pow<B>>::Output as Same<P16>>::Output;

    assert_eq!(<P2PowP4 as Integer>::to_i64(), <P16 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Cmp_P4() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P2CmpP4 = <A as Cmp<B>>::Output;
    assert_eq!(<P2CmpP4 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Add_P5() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P7 = PInt<UInt<UInt<UInt<UTerm, B1>, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P2AddP5 = <<A as Add<B>>::Output as Same<P7>>::Output;

    assert_eq!(<P2AddP5 as Integer>::to_i64(), <P7 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Sub_P5() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N3 = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P2SubP5 = <<A as Sub<B>>::Output as Same<N3>>::Output;

    assert_eq!(<P2SubP5 as Integer>::to_i64(), <N3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Mul_P5() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P10 = PInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P2MulP5 = <<A as Mul<B>>::Output as Same<P10>>::Output;

    assert_eq!(<P2MulP5 as Integer>::to_i64(), <P10 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Min_P5() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P2MinP5 = <<A as Min<B>>::Output as Same<P2>>::Output;

    assert_eq!(<P2MinP5 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Max_P5() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P2MaxP5 = <<A as Max<B>>::Output as Same<P5>>::Output;

    assert_eq!(<P2MaxP5 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Gcd_P5() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P2GcdP5 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P2GcdP5 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Div_P5() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P2DivP5 = <<A as Div<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P2DivP5 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Rem_P5() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P2RemP5 = <<A as Rem<B>>::Output as Same<P2>>::Output;

    assert_eq!(<P2RemP5 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Pow_P5() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P32 = PInt<UInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P2PowP5 = <<A as Pow<B>>::Output as Same<P32>>::Output;

    assert_eq!(<P2PowP5 as Integer>::to_i64(), <P32 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Cmp_P5() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P2CmpP5 = <A as Cmp<B>>::Output;
    assert_eq!(<P2CmpP5 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Add_N5() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P3AddN5 = <<A as Add<B>>::Output as Same<N2>>::Output;

    assert_eq!(<P3AddN5 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Sub_N5() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P8 = PInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P3SubN5 = <<A as Sub<B>>::Output as Same<P8>>::Output;

    assert_eq!(<P3SubN5 as Integer>::to_i64(), <P8 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Mul_N5() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N15 = NInt<UInt<UInt<UInt<UInt<UTerm, B1>, B1>, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P3MulN5 = <<A as Mul<B>>::Output as Same<N15>>::Output;

    assert_eq!(<P3MulN5 as Integer>::to_i64(), <N15 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Min_N5() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N5 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P3MinN5 = <<A as Min<B>>::Output as Same<N5>>::Output;

    assert_eq!(<P3MinN5 as Integer>::to_i64(), <N5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Max_N5() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P3MaxN5 = <<A as Max<B>>::Output as Same<P3>>::Output;

    assert_eq!(<P3MaxN5 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Gcd_N5() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P3GcdN5 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P3GcdN5 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Div_N5() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P3DivN5 = <<A as Div<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P3DivN5 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Rem_N5() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P3RemN5 = <<A as Rem<B>>::Output as Same<P3>>::Output;

    assert_eq!(<P3RemN5 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Cmp_N5() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P3CmpN5 = <A as Cmp<B>>::Output;
    assert_eq!(<P3CmpN5 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Add_N4() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P3AddN4 = <<A as Add<B>>::Output as Same<N1>>::Output;

    assert_eq!(<P3AddN4 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Sub_N4() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P7 = PInt<UInt<UInt<UInt<UTerm, B1>, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P3SubN4 = <<A as Sub<B>>::Output as Same<P7>>::Output;

    assert_eq!(<P3SubN4 as Integer>::to_i64(), <P7 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Mul_N4() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N12 = NInt<UInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P3MulN4 = <<A as Mul<B>>::Output as Same<N12>>::Output;

    assert_eq!(<P3MulN4 as Integer>::to_i64(), <N12 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Min_N4() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N4 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P3MinN4 = <<A as Min<B>>::Output as Same<N4>>::Output;

    assert_eq!(<P3MinN4 as Integer>::to_i64(), <N4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Max_N4() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P3MaxN4 = <<A as Max<B>>::Output as Same<P3>>::Output;

    assert_eq!(<P3MaxN4 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Gcd_N4() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P3GcdN4 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P3GcdN4 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Div_N4() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P3DivN4 = <<A as Div<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P3DivN4 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Rem_N4() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P3RemN4 = <<A as Rem<B>>::Output as Same<P3>>::Output;

    assert_eq!(<P3RemN4 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Cmp_N4() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P3CmpN4 = <A as Cmp<B>>::Output;
    assert_eq!(<P3CmpN4 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Add_N3() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P3AddN3 = <<A as Add<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P3AddN3 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Sub_N3() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type P6 = PInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P3SubN3 = <<A as Sub<B>>::Output as Same<P6>>::Output;

    assert_eq!(<P3SubN3 as Integer>::to_i64(), <P6 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Mul_N3() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type N9 = NInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P3MulN3 = <<A as Mul<B>>::Output as Same<N9>>::Output;

    assert_eq!(<P3MulN3 as Integer>::to_i64(), <N9 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Min_N3() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type N3 = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P3MinN3 = <<A as Min<B>>::Output as Same<N3>>::Output;

    assert_eq!(<P3MinN3 as Integer>::to_i64(), <N3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Max_N3() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P3MaxN3 = <<A as Max<B>>::Output as Same<P3>>::Output;

    assert_eq!(<P3MaxN3 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Gcd_N3() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P3GcdN3 = <<A as Gcd<B>>::Output as Same<P3>>::Output;

    assert_eq!(<P3GcdN3 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Div_N3() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P3DivN3 = <<A as Div<B>>::Output as Same<N1>>::Output;

    assert_eq!(<P3DivN3 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Rem_N3() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P3RemN3 = <<A as Rem<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P3RemN3 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_PartialDiv_N3() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P3PartialDivN3 = <<A as PartialDiv<B>>::Output as Same<N1>>::Output;

    assert_eq!(<P3PartialDivN3 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Cmp_N3() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P3CmpN3 = <A as Cmp<B>>::Output;
    assert_eq!(<P3CmpN3 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Add_N2() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P3AddN2 = <<A as Add<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P3AddN2 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Sub_N2() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P3SubN2 = <<A as Sub<B>>::Output as Same<P5>>::Output;

    assert_eq!(<P3SubN2 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Mul_N2() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type N6 = NInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P3MulN2 = <<A as Mul<B>>::Output as Same<N6>>::Output;

    assert_eq!(<P3MulN2 as Integer>::to_i64(), <N6 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Min_N2() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P3MinN2 = <<A as Min<B>>::Output as Same<N2>>::Output;

    assert_eq!(<P3MinN2 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Max_N2() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P3MaxN2 = <<A as Max<B>>::Output as Same<P3>>::Output;

    assert_eq!(<P3MaxN2 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Gcd_N2() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P3GcdN2 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P3GcdN2 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Div_N2() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P3DivN2 = <<A as Div<B>>::Output as Same<N1>>::Output;

    assert_eq!(<P3DivN2 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Rem_N2() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P3RemN2 = <<A as Rem<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P3RemN2 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Cmp_N2() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P3CmpN2 = <A as Cmp<B>>::Output;
    assert_eq!(<P3CmpN2 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Add_N1() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P3AddN1 = <<A as Add<B>>::Output as Same<P2>>::Output;

    assert_eq!(<P3AddN1 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Sub_N1() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P3SubN1 = <<A as Sub<B>>::Output as Same<P4>>::Output;

    assert_eq!(<P3SubN1 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Mul_N1() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type N3 = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P3MulN1 = <<A as Mul<B>>::Output as Same<N3>>::Output;

    assert_eq!(<P3MulN1 as Integer>::to_i64(), <N3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Min_N1() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P3MinN1 = <<A as Min<B>>::Output as Same<N1>>::Output;

    assert_eq!(<P3MinN1 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Max_N1() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P3MaxN1 = <<A as Max<B>>::Output as Same<P3>>::Output;

    assert_eq!(<P3MaxN1 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Gcd_N1() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P3GcdN1 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P3GcdN1 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Div_N1() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type N3 = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P3DivN1 = <<A as Div<B>>::Output as Same<N3>>::Output;

    assert_eq!(<P3DivN1 as Integer>::to_i64(), <N3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Rem_N1() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P3RemN1 = <<A as Rem<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P3RemN1 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_PartialDiv_N1() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type N3 = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P3PartialDivN1 = <<A as PartialDiv<B>>::Output as Same<N3>>::Output;

    assert_eq!(<P3PartialDivN1 as Integer>::to_i64(), <N3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Cmp_N1() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P3CmpN1 = <A as Cmp<B>>::Output;
    assert_eq!(<P3CmpN1 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Add__0() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = Z0;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P3Add_0 = <<A as Add<B>>::Output as Same<P3>>::Output;

    assert_eq!(<P3Add_0 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Sub__0() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = Z0;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P3Sub_0 = <<A as Sub<B>>::Output as Same<P3>>::Output;

    assert_eq!(<P3Sub_0 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Mul__0() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = Z0;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P3Mul_0 = <<A as Mul<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P3Mul_0 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Min__0() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = Z0;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P3Min_0 = <<A as Min<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P3Min_0 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Max__0() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = Z0;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P3Max_0 = <<A as Max<B>>::Output as Same<P3>>::Output;

    assert_eq!(<P3Max_0 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Gcd__0() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = Z0;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P3Gcd_0 = <<A as Gcd<B>>::Output as Same<P3>>::Output;

    assert_eq!(<P3Gcd_0 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Pow__0() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = Z0;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P3Pow_0 = <<A as Pow<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P3Pow_0 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Cmp__0() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = Z0;

    #[allow(non_camel_case_types)]
    type P3Cmp_0 = <A as Cmp<B>>::Output;
    assert_eq!(<P3Cmp_0 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Add_P1() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P3AddP1 = <<A as Add<B>>::Output as Same<P4>>::Output;

    assert_eq!(<P3AddP1 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Sub_P1() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P3SubP1 = <<A as Sub<B>>::Output as Same<P2>>::Output;

    assert_eq!(<P3SubP1 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Mul_P1() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P3MulP1 = <<A as Mul<B>>::Output as Same<P3>>::Output;

    assert_eq!(<P3MulP1 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Min_P1() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P3MinP1 = <<A as Min<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P3MinP1 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Max_P1() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P3MaxP1 = <<A as Max<B>>::Output as Same<P3>>::Output;

    assert_eq!(<P3MaxP1 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Gcd_P1() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P3GcdP1 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P3GcdP1 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Div_P1() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P3DivP1 = <<A as Div<B>>::Output as Same<P3>>::Output;

    assert_eq!(<P3DivP1 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Rem_P1() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P3RemP1 = <<A as Rem<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P3RemP1 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_PartialDiv_P1() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P3PartialDivP1 = <<A as PartialDiv<B>>::Output as Same<P3>>::Output;

    assert_eq!(<P3PartialDivP1 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Pow_P1() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P3PowP1 = <<A as Pow<B>>::Output as Same<P3>>::Output;

    assert_eq!(<P3PowP1 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Cmp_P1() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P3CmpP1 = <A as Cmp<B>>::Output;
    assert_eq!(<P3CmpP1 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Add_P2() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P3AddP2 = <<A as Add<B>>::Output as Same<P5>>::Output;

    assert_eq!(<P3AddP2 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Sub_P2() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P3SubP2 = <<A as Sub<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P3SubP2 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Mul_P2() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P6 = PInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P3MulP2 = <<A as Mul<B>>::Output as Same<P6>>::Output;

    assert_eq!(<P3MulP2 as Integer>::to_i64(), <P6 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Min_P2() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P3MinP2 = <<A as Min<B>>::Output as Same<P2>>::Output;

    assert_eq!(<P3MinP2 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Max_P2() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P3MaxP2 = <<A as Max<B>>::Output as Same<P3>>::Output;

    assert_eq!(<P3MaxP2 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Gcd_P2() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P3GcdP2 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P3GcdP2 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Div_P2() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P3DivP2 = <<A as Div<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P3DivP2 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Rem_P2() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P3RemP2 = <<A as Rem<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P3RemP2 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Pow_P2() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P9 = PInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P3PowP2 = <<A as Pow<B>>::Output as Same<P9>>::Output;

    assert_eq!(<P3PowP2 as Integer>::to_i64(), <P9 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Cmp_P2() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P3CmpP2 = <A as Cmp<B>>::Output;
    assert_eq!(<P3CmpP2 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Add_P3() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P6 = PInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P3AddP3 = <<A as Add<B>>::Output as Same<P6>>::Output;

    assert_eq!(<P3AddP3 as Integer>::to_i64(), <P6 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Sub_P3() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P3SubP3 = <<A as Sub<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P3SubP3 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Mul_P3() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P9 = PInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P3MulP3 = <<A as Mul<B>>::Output as Same<P9>>::Output;

    assert_eq!(<P3MulP3 as Integer>::to_i64(), <P9 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Min_P3() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P3MinP3 = <<A as Min<B>>::Output as Same<P3>>::Output;

    assert_eq!(<P3MinP3 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Max_P3() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P3MaxP3 = <<A as Max<B>>::Output as Same<P3>>::Output;

    assert_eq!(<P3MaxP3 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Gcd_P3() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P3GcdP3 = <<A as Gcd<B>>::Output as Same<P3>>::Output;

    assert_eq!(<P3GcdP3 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Div_P3() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P3DivP3 = <<A as Div<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P3DivP3 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Rem_P3() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P3RemP3 = <<A as Rem<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P3RemP3 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_PartialDiv_P3() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P3PartialDivP3 = <<A as PartialDiv<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P3PartialDivP3 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Pow_P3() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P27 = PInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P3PowP3 = <<A as Pow<B>>::Output as Same<P27>>::Output;

    assert_eq!(<P3PowP3 as Integer>::to_i64(), <P27 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Cmp_P3() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P3CmpP3 = <A as Cmp<B>>::Output;
    assert_eq!(<P3CmpP3 as Ord>::to_ordering(), Ordering::Equal);
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Add_P4() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P7 = PInt<UInt<UInt<UInt<UTerm, B1>, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P3AddP4 = <<A as Add<B>>::Output as Same<P7>>::Output;

    assert_eq!(<P3AddP4 as Integer>::to_i64(), <P7 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Sub_P4() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P3SubP4 = <<A as Sub<B>>::Output as Same<N1>>::Output;

    assert_eq!(<P3SubP4 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Mul_P4() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P12 = PInt<UInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P3MulP4 = <<A as Mul<B>>::Output as Same<P12>>::Output;

    assert_eq!(<P3MulP4 as Integer>::to_i64(), <P12 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Min_P4() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P3MinP4 = <<A as Min<B>>::Output as Same<P3>>::Output;

    assert_eq!(<P3MinP4 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Max_P4() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P3MaxP4 = <<A as Max<B>>::Output as Same<P4>>::Output;

    assert_eq!(<P3MaxP4 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Gcd_P4() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P3GcdP4 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P3GcdP4 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Div_P4() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P3DivP4 = <<A as Div<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P3DivP4 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Rem_P4() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P3RemP4 = <<A as Rem<B>>::Output as Same<P3>>::Output;

    assert_eq!(<P3RemP4 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Pow_P4() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P81 = PInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>, B0>, B0>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P3PowP4 = <<A as Pow<B>>::Output as Same<P81>>::Output;

    assert_eq!(<P3PowP4 as Integer>::to_i64(), <P81 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Cmp_P4() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P3CmpP4 = <A as Cmp<B>>::Output;
    assert_eq!(<P3CmpP4 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Add_P5() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P8 = PInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P3AddP5 = <<A as Add<B>>::Output as Same<P8>>::Output;

    assert_eq!(<P3AddP5 as Integer>::to_i64(), <P8 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Sub_P5() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P3SubP5 = <<A as Sub<B>>::Output as Same<N2>>::Output;

    assert_eq!(<P3SubP5 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Mul_P5() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P15 = PInt<UInt<UInt<UInt<UInt<UTerm, B1>, B1>, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P3MulP5 = <<A as Mul<B>>::Output as Same<P15>>::Output;

    assert_eq!(<P3MulP5 as Integer>::to_i64(), <P15 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Min_P5() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P3MinP5 = <<A as Min<B>>::Output as Same<P3>>::Output;

    assert_eq!(<P3MinP5 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Max_P5() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P3MaxP5 = <<A as Max<B>>::Output as Same<P5>>::Output;

    assert_eq!(<P3MaxP5 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Gcd_P5() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P3GcdP5 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P3GcdP5 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Div_P5() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P3DivP5 = <<A as Div<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P3DivP5 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Rem_P5() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P3RemP5 = <<A as Rem<B>>::Output as Same<P3>>::Output;

    assert_eq!(<P3RemP5 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Pow_P5() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P243 = PInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B1>, B1>, B1>, B0>, B0>, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P3PowP5 = <<A as Pow<B>>::Output as Same<P243>>::Output;

    assert_eq!(<P3PowP5 as Integer>::to_i64(), <P243 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Cmp_P5() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P3CmpP5 = <A as Cmp<B>>::Output;
    assert_eq!(<P3CmpP5 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Add_N5() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P4AddN5 = <<A as Add<B>>::Output as Same<N1>>::Output;

    assert_eq!(<P4AddN5 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Sub_N5() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P9 = PInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P4SubN5 = <<A as Sub<B>>::Output as Same<P9>>::Output;

    assert_eq!(<P4SubN5 as Integer>::to_i64(), <P9 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Mul_N5() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N20 = NInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P4MulN5 = <<A as Mul<B>>::Output as Same<N20>>::Output;

    assert_eq!(<P4MulN5 as Integer>::to_i64(), <N20 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Min_N5() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N5 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P4MinN5 = <<A as Min<B>>::Output as Same<N5>>::Output;

    assert_eq!(<P4MinN5 as Integer>::to_i64(), <N5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Max_N5() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P4MaxN5 = <<A as Max<B>>::Output as Same<P4>>::Output;

    assert_eq!(<P4MaxN5 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Gcd_N5() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P4GcdN5 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P4GcdN5 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Div_N5() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P4DivN5 = <<A as Div<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P4DivN5 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Rem_N5() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P4RemN5 = <<A as Rem<B>>::Output as Same<P4>>::Output;

    assert_eq!(<P4RemN5 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Cmp_N5() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P4CmpN5 = <A as Cmp<B>>::Output;
    assert_eq!(<P4CmpN5 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Add_N4() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P4AddN4 = <<A as Add<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P4AddN4 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Sub_N4() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P8 = PInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P4SubN4 = <<A as Sub<B>>::Output as Same<P8>>::Output;

    assert_eq!(<P4SubN4 as Integer>::to_i64(), <P8 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Mul_N4() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N16 = NInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P4MulN4 = <<A as Mul<B>>::Output as Same<N16>>::Output;

    assert_eq!(<P4MulN4 as Integer>::to_i64(), <N16 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Min_N4() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N4 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P4MinN4 = <<A as Min<B>>::Output as Same<N4>>::Output;

    assert_eq!(<P4MinN4 as Integer>::to_i64(), <N4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Max_N4() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P4MaxN4 = <<A as Max<B>>::Output as Same<P4>>::Output;

    assert_eq!(<P4MaxN4 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Gcd_N4() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P4GcdN4 = <<A as Gcd<B>>::Output as Same<P4>>::Output;

    assert_eq!(<P4GcdN4 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Div_N4() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P4DivN4 = <<A as Div<B>>::Output as Same<N1>>::Output;

    assert_eq!(<P4DivN4 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Rem_N4() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P4RemN4 = <<A as Rem<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P4RemN4 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_PartialDiv_N4() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P4PartialDivN4 = <<A as PartialDiv<B>>::Output as Same<N1>>::Output;

    assert_eq!(<P4PartialDivN4 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Cmp_N4() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P4CmpN4 = <A as Cmp<B>>::Output;
    assert_eq!(<P4CmpN4 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Add_N3() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P4AddN3 = <<A as Add<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P4AddN3 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Sub_N3() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type P7 = PInt<UInt<UInt<UInt<UTerm, B1>, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P4SubN3 = <<A as Sub<B>>::Output as Same<P7>>::Output;

    assert_eq!(<P4SubN3 as Integer>::to_i64(), <P7 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Mul_N3() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type N12 = NInt<UInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P4MulN3 = <<A as Mul<B>>::Output as Same<N12>>::Output;

    assert_eq!(<P4MulN3 as Integer>::to_i64(), <N12 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Min_N3() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type N3 = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P4MinN3 = <<A as Min<B>>::Output as Same<N3>>::Output;

    assert_eq!(<P4MinN3 as Integer>::to_i64(), <N3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Max_N3() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P4MaxN3 = <<A as Max<B>>::Output as Same<P4>>::Output;

    assert_eq!(<P4MaxN3 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Gcd_N3() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P4GcdN3 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P4GcdN3 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Div_N3() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P4DivN3 = <<A as Div<B>>::Output as Same<N1>>::Output;

    assert_eq!(<P4DivN3 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Rem_N3() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P4RemN3 = <<A as Rem<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P4RemN3 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Cmp_N3() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P4CmpN3 = <A as Cmp<B>>::Output;
    assert_eq!(<P4CmpN3 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Add_N2() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P4AddN2 = <<A as Add<B>>::Output as Same<P2>>::Output;

    assert_eq!(<P4AddN2 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Sub_N2() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type P6 = PInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P4SubN2 = <<A as Sub<B>>::Output as Same<P6>>::Output;

    assert_eq!(<P4SubN2 as Integer>::to_i64(), <P6 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Mul_N2() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type N8 = NInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P4MulN2 = <<A as Mul<B>>::Output as Same<N8>>::Output;

    assert_eq!(<P4MulN2 as Integer>::to_i64(), <N8 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Min_N2() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P4MinN2 = <<A as Min<B>>::Output as Same<N2>>::Output;

    assert_eq!(<P4MinN2 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Max_N2() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P4MaxN2 = <<A as Max<B>>::Output as Same<P4>>::Output;

    assert_eq!(<P4MaxN2 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Gcd_N2() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P4GcdN2 = <<A as Gcd<B>>::Output as Same<P2>>::Output;

    assert_eq!(<P4GcdN2 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Div_N2() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P4DivN2 = <<A as Div<B>>::Output as Same<N2>>::Output;

    assert_eq!(<P4DivN2 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Rem_N2() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P4RemN2 = <<A as Rem<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P4RemN2 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_PartialDiv_N2() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P4PartialDivN2 = <<A as PartialDiv<B>>::Output as Same<N2>>::Output;

    assert_eq!(<P4PartialDivN2 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Cmp_N2() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P4CmpN2 = <A as Cmp<B>>::Output;
    assert_eq!(<P4CmpN2 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Add_N1() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UTerm, B1>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P4AddN1 = <<A as Add<B>>::Output as Same<P3>>::Output;

    assert_eq!(<P4AddN1 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Sub_N1() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UTerm, B1>>;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P4SubN1 = <<A as Sub<B>>::Output as Same<P5>>::Output;

    assert_eq!(<P4SubN1 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Mul_N1() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UTerm, B1>>;
    type N4 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P4MulN1 = <<A as Mul<B>>::Output as Same<N4>>::Output;

    assert_eq!(<P4MulN1 as Integer>::to_i64(), <N4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Min_N1() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UTerm, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P4MinN1 = <<A as Min<B>>::Output as Same<N1>>::Output;

    assert_eq!(<P4MinN1 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Max_N1() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UTerm, B1>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P4MaxN1 = <<A as Max<B>>::Output as Same<P4>>::Output;

    assert_eq!(<P4MaxN1 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Gcd_N1() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UTerm, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P4GcdN1 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P4GcdN1 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Div_N1() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UTerm, B1>>;
    type N4 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P4DivN1 = <<A as Div<B>>::Output as Same<N4>>::Output;

    assert_eq!(<P4DivN1 as Integer>::to_i64(), <N4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Rem_N1() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UTerm, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P4RemN1 = <<A as Rem<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P4RemN1 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_PartialDiv_N1() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UTerm, B1>>;
    type N4 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P4PartialDivN1 = <<A as PartialDiv<B>>::Output as Same<N4>>::Output;

    assert_eq!(<P4PartialDivN1 as Integer>::to_i64(), <N4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Cmp_N1() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P4CmpN1 = <A as Cmp<B>>::Output;
    assert_eq!(<P4CmpN1 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Add__0() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = Z0;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P4Add_0 = <<A as Add<B>>::Output as Same<P4>>::Output;

    assert_eq!(<P4Add_0 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Sub__0() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = Z0;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P4Sub_0 = <<A as Sub<B>>::Output as Same<P4>>::Output;

    assert_eq!(<P4Sub_0 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Mul__0() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = Z0;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P4Mul_0 = <<A as Mul<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P4Mul_0 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Min__0() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = Z0;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P4Min_0 = <<A as Min<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P4Min_0 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Max__0() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = Z0;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P4Max_0 = <<A as Max<B>>::Output as Same<P4>>::Output;

    assert_eq!(<P4Max_0 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Gcd__0() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = Z0;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P4Gcd_0 = <<A as Gcd<B>>::Output as Same<P4>>::Output;

    assert_eq!(<P4Gcd_0 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Pow__0() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = Z0;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P4Pow_0 = <<A as Pow<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P4Pow_0 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Cmp__0() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = Z0;

    #[allow(non_camel_case_types)]
    type P4Cmp_0 = <A as Cmp<B>>::Output;
    assert_eq!(<P4Cmp_0 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Add_P1() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P4AddP1 = <<A as Add<B>>::Output as Same<P5>>::Output;

    assert_eq!(<P4AddP1 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Sub_P1() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P4SubP1 = <<A as Sub<B>>::Output as Same<P3>>::Output;

    assert_eq!(<P4SubP1 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Mul_P1() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P4MulP1 = <<A as Mul<B>>::Output as Same<P4>>::Output;

    assert_eq!(<P4MulP1 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Min_P1() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P4MinP1 = <<A as Min<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P4MinP1 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Max_P1() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P4MaxP1 = <<A as Max<B>>::Output as Same<P4>>::Output;

    assert_eq!(<P4MaxP1 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Gcd_P1() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P4GcdP1 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P4GcdP1 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Div_P1() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P4DivP1 = <<A as Div<B>>::Output as Same<P4>>::Output;

    assert_eq!(<P4DivP1 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Rem_P1() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UTerm, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P4RemP1 = <<A as Rem<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P4RemP1 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_PartialDiv_P1() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P4PartialDivP1 = <<A as PartialDiv<B>>::Output as Same<P4>>::Output;

    assert_eq!(<P4PartialDivP1 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Pow_P1() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P4PowP1 = <<A as Pow<B>>::Output as Same<P4>>::Output;

    assert_eq!(<P4PowP1 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Cmp_P1() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P4CmpP1 = <A as Cmp<B>>::Output;
    assert_eq!(<P4CmpP1 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Add_P2() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P6 = PInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P4AddP2 = <<A as Add<B>>::Output as Same<P6>>::Output;

    assert_eq!(<P4AddP2 as Integer>::to_i64(), <P6 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Sub_P2() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P4SubP2 = <<A as Sub<B>>::Output as Same<P2>>::Output;

    assert_eq!(<P4SubP2 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Mul_P2() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P8 = PInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P4MulP2 = <<A as Mul<B>>::Output as Same<P8>>::Output;

    assert_eq!(<P4MulP2 as Integer>::to_i64(), <P8 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Min_P2() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P4MinP2 = <<A as Min<B>>::Output as Same<P2>>::Output;

    assert_eq!(<P4MinP2 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Max_P2() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P4MaxP2 = <<A as Max<B>>::Output as Same<P4>>::Output;

    assert_eq!(<P4MaxP2 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Gcd_P2() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P4GcdP2 = <<A as Gcd<B>>::Output as Same<P2>>::Output;

    assert_eq!(<P4GcdP2 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Div_P2() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P4DivP2 = <<A as Div<B>>::Output as Same<P2>>::Output;

    assert_eq!(<P4DivP2 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Rem_P2() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P4RemP2 = <<A as Rem<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P4RemP2 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_PartialDiv_P2() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P4PartialDivP2 = <<A as PartialDiv<B>>::Output as Same<P2>>::Output;

    assert_eq!(<P4PartialDivP2 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Pow_P2() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P16 = PInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P4PowP2 = <<A as Pow<B>>::Output as Same<P16>>::Output;

    assert_eq!(<P4PowP2 as Integer>::to_i64(), <P16 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Cmp_P2() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P4CmpP2 = <A as Cmp<B>>::Output;
    assert_eq!(<P4CmpP2 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Add_P3() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P7 = PInt<UInt<UInt<UInt<UTerm, B1>, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P4AddP3 = <<A as Add<B>>::Output as Same<P7>>::Output;

    assert_eq!(<P4AddP3 as Integer>::to_i64(), <P7 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Sub_P3() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P4SubP3 = <<A as Sub<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P4SubP3 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Mul_P3() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P12 = PInt<UInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P4MulP3 = <<A as Mul<B>>::Output as Same<P12>>::Output;

    assert_eq!(<P4MulP3 as Integer>::to_i64(), <P12 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Min_P3() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P4MinP3 = <<A as Min<B>>::Output as Same<P3>>::Output;

    assert_eq!(<P4MinP3 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Max_P3() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P4MaxP3 = <<A as Max<B>>::Output as Same<P4>>::Output;

    assert_eq!(<P4MaxP3 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Gcd_P3() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P4GcdP3 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P4GcdP3 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Div_P3() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P4DivP3 = <<A as Div<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P4DivP3 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Rem_P3() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P4RemP3 = <<A as Rem<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P4RemP3 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Pow_P3() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P64 = PInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>, B0>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P4PowP3 = <<A as Pow<B>>::Output as Same<P64>>::Output;

    assert_eq!(<P4PowP3 as Integer>::to_i64(), <P64 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Cmp_P3() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P4CmpP3 = <A as Cmp<B>>::Output;
    assert_eq!(<P4CmpP3 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Add_P4() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P8 = PInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P4AddP4 = <<A as Add<B>>::Output as Same<P8>>::Output;

    assert_eq!(<P4AddP4 as Integer>::to_i64(), <P8 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Sub_P4() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P4SubP4 = <<A as Sub<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P4SubP4 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Mul_P4() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P16 = PInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P4MulP4 = <<A as Mul<B>>::Output as Same<P16>>::Output;

    assert_eq!(<P4MulP4 as Integer>::to_i64(), <P16 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Min_P4() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P4MinP4 = <<A as Min<B>>::Output as Same<P4>>::Output;

    assert_eq!(<P4MinP4 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Max_P4() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P4MaxP4 = <<A as Max<B>>::Output as Same<P4>>::Output;

    assert_eq!(<P4MaxP4 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Gcd_P4() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P4GcdP4 = <<A as Gcd<B>>::Output as Same<P4>>::Output;

    assert_eq!(<P4GcdP4 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Div_P4() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P4DivP4 = <<A as Div<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P4DivP4 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Rem_P4() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P4RemP4 = <<A as Rem<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P4RemP4 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_PartialDiv_P4() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P4PartialDivP4 = <<A as PartialDiv<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P4PartialDivP4 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Pow_P4() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P256 = PInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>, B0>, B0>, B0>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P4PowP4 = <<A as Pow<B>>::Output as Same<P256>>::Output;

    assert_eq!(<P4PowP4 as Integer>::to_i64(), <P256 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Cmp_P4() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P4CmpP4 = <A as Cmp<B>>::Output;
    assert_eq!(<P4CmpP4 as Ord>::to_ordering(), Ordering::Equal);
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Add_P5() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P9 = PInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P4AddP5 = <<A as Add<B>>::Output as Same<P9>>::Output;

    assert_eq!(<P4AddP5 as Integer>::to_i64(), <P9 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Sub_P5() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P4SubP5 = <<A as Sub<B>>::Output as Same<N1>>::Output;

    assert_eq!(<P4SubP5 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Mul_P5() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P20 = PInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P4MulP5 = <<A as Mul<B>>::Output as Same<P20>>::Output;

    assert_eq!(<P4MulP5 as Integer>::to_i64(), <P20 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Min_P5() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P4MinP5 = <<A as Min<B>>::Output as Same<P4>>::Output;

    assert_eq!(<P4MinP5 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Max_P5() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P4MaxP5 = <<A as Max<B>>::Output as Same<P5>>::Output;

    assert_eq!(<P4MaxP5 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Gcd_P5() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P4GcdP5 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P4GcdP5 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Div_P5() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P4DivP5 = <<A as Div<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P4DivP5 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Rem_P5() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P4RemP5 = <<A as Rem<B>>::Output as Same<P4>>::Output;

    assert_eq!(<P4RemP5 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Pow_P5() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P1024 = PInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>, B0>, B0>, B0>, B0>, B0>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P4PowP5 = <<A as Pow<B>>::Output as Same<P1024>>::Output;

    assert_eq!(<P4PowP5 as Integer>::to_i64(), <P1024 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Cmp_P5() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P4CmpP5 = <A as Cmp<B>>::Output;
    assert_eq!(<P4CmpP5 as Ord>::to_ordering(), Ordering::Less);
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Add_N5() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P5AddN5 = <<A as Add<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P5AddN5 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Sub_N5() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P10 = PInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P5SubN5 = <<A as Sub<B>>::Output as Same<P10>>::Output;

    assert_eq!(<P5SubN5 as Integer>::to_i64(), <P10 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Mul_N5() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N25 = NInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P5MulN5 = <<A as Mul<B>>::Output as Same<N25>>::Output;

    assert_eq!(<P5MulN5 as Integer>::to_i64(), <N25 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Min_N5() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N5 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P5MinN5 = <<A as Min<B>>::Output as Same<N5>>::Output;

    assert_eq!(<P5MinN5 as Integer>::to_i64(), <N5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Max_N5() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P5MaxN5 = <<A as Max<B>>::Output as Same<P5>>::Output;

    assert_eq!(<P5MaxN5 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Gcd_N5() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P5GcdN5 = <<A as Gcd<B>>::Output as Same<P5>>::Output;

    assert_eq!(<P5GcdN5 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Div_N5() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P5DivN5 = <<A as Div<B>>::Output as Same<N1>>::Output;

    assert_eq!(<P5DivN5 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Rem_N5() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P5RemN5 = <<A as Rem<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P5RemN5 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_PartialDiv_N5() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P5PartialDivN5 = <<A as PartialDiv<B>>::Output as Same<N1>>::Output;

    assert_eq!(<P5PartialDivN5 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Cmp_N5() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P5CmpN5 = <A as Cmp<B>>::Output;
    assert_eq!(<P5CmpN5 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Add_N4() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P5AddN4 = <<A as Add<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P5AddN4 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Sub_N4() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P9 = PInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P5SubN4 = <<A as Sub<B>>::Output as Same<P9>>::Output;

    assert_eq!(<P5SubN4 as Integer>::to_i64(), <P9 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Mul_N4() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N20 = NInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P5MulN4 = <<A as Mul<B>>::Output as Same<N20>>::Output;

    assert_eq!(<P5MulN4 as Integer>::to_i64(), <N20 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Min_N4() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N4 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P5MinN4 = <<A as Min<B>>::Output as Same<N4>>::Output;

    assert_eq!(<P5MinN4 as Integer>::to_i64(), <N4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Max_N4() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P5MaxN4 = <<A as Max<B>>::Output as Same<P5>>::Output;

    assert_eq!(<P5MaxN4 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Gcd_N4() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P5GcdN4 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P5GcdN4 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Div_N4() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P5DivN4 = <<A as Div<B>>::Output as Same<N1>>::Output;

    assert_eq!(<P5DivN4 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Rem_N4() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P5RemN4 = <<A as Rem<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P5RemN4 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Cmp_N4() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P5CmpN4 = <A as Cmp<B>>::Output;
    assert_eq!(<P5CmpN4 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Add_N3() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P5AddN3 = <<A as Add<B>>::Output as Same<P2>>::Output;

    assert_eq!(<P5AddN3 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Sub_N3() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type P8 = PInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P5SubN3 = <<A as Sub<B>>::Output as Same<P8>>::Output;

    assert_eq!(<P5SubN3 as Integer>::to_i64(), <P8 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Mul_N3() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type N15 = NInt<UInt<UInt<UInt<UInt<UTerm, B1>, B1>, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P5MulN3 = <<A as Mul<B>>::Output as Same<N15>>::Output;

    assert_eq!(<P5MulN3 as Integer>::to_i64(), <N15 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Min_N3() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type N3 = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P5MinN3 = <<A as Min<B>>::Output as Same<N3>>::Output;

    assert_eq!(<P5MinN3 as Integer>::to_i64(), <N3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Max_N3() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P5MaxN3 = <<A as Max<B>>::Output as Same<P5>>::Output;

    assert_eq!(<P5MaxN3 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Gcd_N3() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P5GcdN3 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P5GcdN3 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Div_N3() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P5DivN3 = <<A as Div<B>>::Output as Same<N1>>::Output;

    assert_eq!(<P5DivN3 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Rem_N3() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P5RemN3 = <<A as Rem<B>>::Output as Same<P2>>::Output;

    assert_eq!(<P5RemN3 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Cmp_N3() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P5CmpN3 = <A as Cmp<B>>::Output;
    assert_eq!(<P5CmpN3 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Add_N2() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P5AddN2 = <<A as Add<B>>::Output as Same<P3>>::Output;

    assert_eq!(<P5AddN2 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Sub_N2() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type P7 = PInt<UInt<UInt<UInt<UTerm, B1>, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P5SubN2 = <<A as Sub<B>>::Output as Same<P7>>::Output;

    assert_eq!(<P5SubN2 as Integer>::to_i64(), <P7 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Mul_N2() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type N10 = NInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P5MulN2 = <<A as Mul<B>>::Output as Same<N10>>::Output;

    assert_eq!(<P5MulN2 as Integer>::to_i64(), <N10 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Min_N2() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P5MinN2 = <<A as Min<B>>::Output as Same<N2>>::Output;

    assert_eq!(<P5MinN2 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Max_N2() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P5MaxN2 = <<A as Max<B>>::Output as Same<P5>>::Output;

    assert_eq!(<P5MaxN2 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Gcd_N2() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P5GcdN2 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P5GcdN2 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Div_N2() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P5DivN2 = <<A as Div<B>>::Output as Same<N2>>::Output;

    assert_eq!(<P5DivN2 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Rem_N2() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P5RemN2 = <<A as Rem<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P5RemN2 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Cmp_N2() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P5CmpN2 = <A as Cmp<B>>::Output;
    assert_eq!(<P5CmpN2 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Add_N1() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P5AddN1 = <<A as Add<B>>::Output as Same<P4>>::Output;

    assert_eq!(<P5AddN1 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Sub_N1() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type P6 = PInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P5SubN1 = <<A as Sub<B>>::Output as Same<P6>>::Output;

    assert_eq!(<P5SubN1 as Integer>::to_i64(), <P6 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Mul_N1() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type N5 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P5MulN1 = <<A as Mul<B>>::Output as Same<N5>>::Output;

    assert_eq!(<P5MulN1 as Integer>::to_i64(), <N5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Min_N1() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P5MinN1 = <<A as Min<B>>::Output as Same<N1>>::Output;

    assert_eq!(<P5MinN1 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Max_N1() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P5MaxN1 = <<A as Max<B>>::Output as Same<P5>>::Output;

    assert_eq!(<P5MaxN1 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Gcd_N1() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P5GcdN1 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P5GcdN1 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Div_N1() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type N5 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P5DivN1 = <<A as Div<B>>::Output as Same<N5>>::Output;

    assert_eq!(<P5DivN1 as Integer>::to_i64(), <N5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Rem_N1() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P5RemN1 = <<A as Rem<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P5RemN1 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_PartialDiv_N1() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UTerm, B1>>;
    type N5 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P5PartialDivN1 = <<A as PartialDiv<B>>::Output as Same<N5>>::Output;

    assert_eq!(<P5PartialDivN1 as Integer>::to_i64(), <N5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Cmp_N1() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P5CmpN1 = <A as Cmp<B>>::Output;
    assert_eq!(<P5CmpN1 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Add__0() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = Z0;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P5Add_0 = <<A as Add<B>>::Output as Same<P5>>::Output;

    assert_eq!(<P5Add_0 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Sub__0() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = Z0;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P5Sub_0 = <<A as Sub<B>>::Output as Same<P5>>::Output;

    assert_eq!(<P5Sub_0 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Mul__0() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = Z0;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P5Mul_0 = <<A as Mul<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P5Mul_0 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Min__0() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = Z0;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P5Min_0 = <<A as Min<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P5Min_0 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Max__0() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = Z0;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P5Max_0 = <<A as Max<B>>::Output as Same<P5>>::Output;

    assert_eq!(<P5Max_0 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Gcd__0() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = Z0;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P5Gcd_0 = <<A as Gcd<B>>::Output as Same<P5>>::Output;

    assert_eq!(<P5Gcd_0 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Pow__0() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = Z0;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P5Pow_0 = <<A as Pow<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P5Pow_0 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Cmp__0() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = Z0;

    #[allow(non_camel_case_types)]
    type P5Cmp_0 = <A as Cmp<B>>::Output;
    assert_eq!(<P5Cmp_0 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Add_P1() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P6 = PInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P5AddP1 = <<A as Add<B>>::Output as Same<P6>>::Output;

    assert_eq!(<P5AddP1 as Integer>::to_i64(), <P6 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Sub_P1() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P5SubP1 = <<A as Sub<B>>::Output as Same<P4>>::Output;

    assert_eq!(<P5SubP1 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Mul_P1() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P5MulP1 = <<A as Mul<B>>::Output as Same<P5>>::Output;

    assert_eq!(<P5MulP1 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Min_P1() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P5MinP1 = <<A as Min<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P5MinP1 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Max_P1() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P5MaxP1 = <<A as Max<B>>::Output as Same<P5>>::Output;

    assert_eq!(<P5MaxP1 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Gcd_P1() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P5GcdP1 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P5GcdP1 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Div_P1() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P5DivP1 = <<A as Div<B>>::Output as Same<P5>>::Output;

    assert_eq!(<P5DivP1 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Rem_P1() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P5RemP1 = <<A as Rem<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P5RemP1 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_PartialDiv_P1() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P5PartialDivP1 = <<A as PartialDiv<B>>::Output as Same<P5>>::Output;

    assert_eq!(<P5PartialDivP1 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Pow_P1() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UTerm, B1>>;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P5PowP1 = <<A as Pow<B>>::Output as Same<P5>>::Output;

    assert_eq!(<P5PowP1 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Cmp_P1() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P5CmpP1 = <A as Cmp<B>>::Output;
    assert_eq!(<P5CmpP1 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Add_P2() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P7 = PInt<UInt<UInt<UInt<UTerm, B1>, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P5AddP2 = <<A as Add<B>>::Output as Same<P7>>::Output;

    assert_eq!(<P5AddP2 as Integer>::to_i64(), <P7 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Sub_P2() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P5SubP2 = <<A as Sub<B>>::Output as Same<P3>>::Output;

    assert_eq!(<P5SubP2 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Mul_P2() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P10 = PInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P5MulP2 = <<A as Mul<B>>::Output as Same<P10>>::Output;

    assert_eq!(<P5MulP2 as Integer>::to_i64(), <P10 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Min_P2() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P5MinP2 = <<A as Min<B>>::Output as Same<P2>>::Output;

    assert_eq!(<P5MinP2 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Max_P2() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P5MaxP2 = <<A as Max<B>>::Output as Same<P5>>::Output;

    assert_eq!(<P5MaxP2 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Gcd_P2() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P5GcdP2 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P5GcdP2 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Div_P2() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P5DivP2 = <<A as Div<B>>::Output as Same<P2>>::Output;

    assert_eq!(<P5DivP2 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Rem_P2() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P5RemP2 = <<A as Rem<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P5RemP2 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Pow_P2() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P25 = PInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P5PowP2 = <<A as Pow<B>>::Output as Same<P25>>::Output;

    assert_eq!(<P5PowP2 as Integer>::to_i64(), <P25 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Cmp_P2() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P5CmpP2 = <A as Cmp<B>>::Output;
    assert_eq!(<P5CmpP2 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Add_P3() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P8 = PInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P5AddP3 = <<A as Add<B>>::Output as Same<P8>>::Output;

    assert_eq!(<P5AddP3 as Integer>::to_i64(), <P8 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Sub_P3() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P5SubP3 = <<A as Sub<B>>::Output as Same<P2>>::Output;

    assert_eq!(<P5SubP3 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Mul_P3() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P15 = PInt<UInt<UInt<UInt<UInt<UTerm, B1>, B1>, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P5MulP3 = <<A as Mul<B>>::Output as Same<P15>>::Output;

    assert_eq!(<P5MulP3 as Integer>::to_i64(), <P15 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Min_P3() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P5MinP3 = <<A as Min<B>>::Output as Same<P3>>::Output;

    assert_eq!(<P5MinP3 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Max_P3() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P5MaxP3 = <<A as Max<B>>::Output as Same<P5>>::Output;

    assert_eq!(<P5MaxP3 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Gcd_P3() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P5GcdP3 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P5GcdP3 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Div_P3() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P5DivP3 = <<A as Div<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P5DivP3 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Rem_P3() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P5RemP3 = <<A as Rem<B>>::Output as Same<P2>>::Output;

    assert_eq!(<P5RemP3 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Pow_P3() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P125 = PInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B1>, B1>, B1>, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P5PowP3 = <<A as Pow<B>>::Output as Same<P125>>::Output;

    assert_eq!(<P5PowP3 as Integer>::to_i64(), <P125 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Cmp_P3() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type P5CmpP3 = <A as Cmp<B>>::Output;
    assert_eq!(<P5CmpP3 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Add_P4() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P9 = PInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P5AddP4 = <<A as Add<B>>::Output as Same<P9>>::Output;

    assert_eq!(<P5AddP4 as Integer>::to_i64(), <P9 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Sub_P4() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P5SubP4 = <<A as Sub<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P5SubP4 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Mul_P4() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P20 = PInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P5MulP4 = <<A as Mul<B>>::Output as Same<P20>>::Output;

    assert_eq!(<P5MulP4 as Integer>::to_i64(), <P20 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Min_P4() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P5MinP4 = <<A as Min<B>>::Output as Same<P4>>::Output;

    assert_eq!(<P5MinP4 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Max_P4() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P5MaxP4 = <<A as Max<B>>::Output as Same<P5>>::Output;

    assert_eq!(<P5MaxP4 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Gcd_P4() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P5GcdP4 = <<A as Gcd<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P5GcdP4 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Div_P4() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P5DivP4 = <<A as Div<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P5DivP4 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Rem_P4() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P5RemP4 = <<A as Rem<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P5RemP4 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Pow_P4() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P625 = PInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>, B1>, B1>, B1>, B0>, B0>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P5PowP4 = <<A as Pow<B>>::Output as Same<P625>>::Output;

    assert_eq!(<P5PowP4 as Integer>::to_i64(), <P625 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Cmp_P4() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type P5CmpP4 = <A as Cmp<B>>::Output;
    assert_eq!(<P5CmpP4 as Ord>::to_ordering(), Ordering::Greater);
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Add_P5() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P10 = PInt<UInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type P5AddP5 = <<A as Add<B>>::Output as Same<P10>>::Output;

    assert_eq!(<P5AddP5 as Integer>::to_i64(), <P10 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Sub_P5() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P5SubP5 = <<A as Sub<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P5SubP5 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Mul_P5() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P25 = PInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P5MulP5 = <<A as Mul<B>>::Output as Same<P25>>::Output;

    assert_eq!(<P5MulP5 as Integer>::to_i64(), <P25 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Min_P5() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P5MinP5 = <<A as Min<B>>::Output as Same<P5>>::Output;

    assert_eq!(<P5MinP5 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Max_P5() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P5MaxP5 = <<A as Max<B>>::Output as Same<P5>>::Output;

    assert_eq!(<P5MaxP5 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Gcd_P5() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P5GcdP5 = <<A as Gcd<B>>::Output as Same<P5>>::Output;

    assert_eq!(<P5GcdP5 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Div_P5() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P5DivP5 = <<A as Div<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P5DivP5 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Rem_P5() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type P5RemP5 = <<A as Rem<B>>::Output as Same<_0>>::Output;

    assert_eq!(<P5RemP5 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_PartialDiv_P5() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type P5PartialDivP5 = <<A as PartialDiv<B>>::Output as Same<P1>>::Output;

    assert_eq!(<P5PartialDivP5 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Pow_P5() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P3125 = PInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UInt<UTerm, B1>, B1>, B0>, B0>, B0>, B0>, B1>, B1>, B0>, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P5PowP5 = <<A as Pow<B>>::Output as Same<P3125>>::Output;

    assert_eq!(<P5PowP5 as Integer>::to_i64(), <P3125 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Cmp_P5() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type B = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type P5CmpP5 = <A as Cmp<B>>::Output;
    assert_eq!(<P5CmpP5 as Ord>::to_ordering(), Ordering::Equal);
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Neg() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type NegN5 = <<A as Neg>::Output as Same<P5>>::Output;
    assert_eq!(<NegN5 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N5_Abs() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type AbsN5 = <<A as Abs>::Output as Same<P5>>::Output;
    assert_eq!(<AbsN5 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Neg() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type NegN4 = <<A as Neg>::Output as Same<P4>>::Output;
    assert_eq!(<NegN4 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N4_Abs() {
    type A = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type AbsN4 = <<A as Abs>::Output as Same<P4>>::Output;
    assert_eq!(<AbsN4 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Neg() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type NegN3 = <<A as Neg>::Output as Same<P3>>::Output;
    assert_eq!(<NegN3 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N3_Abs() {
    type A = NInt<UInt<UInt<UTerm, B1>, B1>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type AbsN3 = <<A as Abs>::Output as Same<P3>>::Output;
    assert_eq!(<AbsN3 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Neg() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type NegN2 = <<A as Neg>::Output as Same<P2>>::Output;
    assert_eq!(<NegN2 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N2_Abs() {
    type A = NInt<UInt<UInt<UTerm, B1>, B0>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type AbsN2 = <<A as Abs>::Output as Same<P2>>::Output;
    assert_eq!(<AbsN2 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Neg() {
    type A = NInt<UInt<UTerm, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type NegN1 = <<A as Neg>::Output as Same<P1>>::Output;
    assert_eq!(<NegN1 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_N1_Abs() {
    type A = NInt<UInt<UTerm, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type AbsN1 = <<A as Abs>::Output as Same<P1>>::Output;
    assert_eq!(<AbsN1 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Neg() {
    type A = Z0;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type Neg_0 = <<A as Neg>::Output as Same<_0>>::Output;
    assert_eq!(<Neg_0 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test__0_Abs() {
    type A = Z0;
    type _0 = Z0;

    #[allow(non_camel_case_types)]
    type Abs_0 = <<A as Abs>::Output as Same<_0>>::Output;
    assert_eq!(<Abs_0 as Integer>::to_i64(), <_0 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Neg() {
    type A = PInt<UInt<UTerm, B1>>;
    type N1 = NInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type NegP1 = <<A as Neg>::Output as Same<N1>>::Output;
    assert_eq!(<NegP1 as Integer>::to_i64(), <N1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P1_Abs() {
    type A = PInt<UInt<UTerm, B1>>;
    type P1 = PInt<UInt<UTerm, B1>>;

    #[allow(non_camel_case_types)]
    type AbsP1 = <<A as Abs>::Output as Same<P1>>::Output;
    assert_eq!(<AbsP1 as Integer>::to_i64(), <P1 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Neg() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type N2 = NInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type NegP2 = <<A as Neg>::Output as Same<N2>>::Output;
    assert_eq!(<NegP2 as Integer>::to_i64(), <N2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P2_Abs() {
    type A = PInt<UInt<UInt<UTerm, B1>, B0>>;
    type P2 = PInt<UInt<UInt<UTerm, B1>, B0>>;

    #[allow(non_camel_case_types)]
    type AbsP2 = <<A as Abs>::Output as Same<P2>>::Output;
    assert_eq!(<AbsP2 as Integer>::to_i64(), <P2 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Neg() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type N3 = NInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type NegP3 = <<A as Neg>::Output as Same<N3>>::Output;
    assert_eq!(<NegP3 as Integer>::to_i64(), <N3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P3_Abs() {
    type A = PInt<UInt<UInt<UTerm, B1>, B1>>;
    type P3 = PInt<UInt<UInt<UTerm, B1>, B1>>;

    #[allow(non_camel_case_types)]
    type AbsP3 = <<A as Abs>::Output as Same<P3>>::Output;
    assert_eq!(<AbsP3 as Integer>::to_i64(), <P3 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Neg() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type N4 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type NegP4 = <<A as Neg>::Output as Same<N4>>::Output;
    assert_eq!(<NegP4 as Integer>::to_i64(), <N4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P4_Abs() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;
    type P4 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B0>>;

    #[allow(non_camel_case_types)]
    type AbsP4 = <<A as Abs>::Output as Same<P4>>::Output;
    assert_eq!(<AbsP4 as Integer>::to_i64(), <P4 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Neg() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type N5 = NInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type NegP5 = <<A as Neg>::Output as Same<N5>>::Output;
    assert_eq!(<NegP5 as Integer>::to_i64(), <N5 as Integer>::to_i64());
}
#[test]
#[allow(non_snake_case)]
fn test_P5_Abs() {
    type A = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;
    type P5 = PInt<UInt<UInt<UInt<UTerm, B1>, B0>, B1>>;

    #[allow(non_camel_case_types)]
    type AbsP5 = <<A as Abs>::Output as Same<P5>>::Output;
    assert_eq!(<AbsP5 as Integer>::to_i64(), <P5 as Integer>::to_i64());
}
```

--- file: target/debug/build/zstd-sys-6db71bc350d87f54/out/flag_check.c ---
```c
int main(void) { return 0; }
```

--- file: target/debug/build/zstd-sys-6db71bc350d87f54/out/include/zdict.h ---
```h
/*
 * Copyright (c) Meta Platforms, Inc. and affiliates.
 * All rights reserved.
 *
 * This source code is licensed under both the BSD-style license (found in the
 * LICENSE file in the root directory of this source tree) and the GPLv2 (found
 * in the COPYING file in the root directory of this source tree).
 * You may select, at your option, one of the above-listed licenses.
 */

#ifndef ZSTD_ZDICT_H
#define ZSTD_ZDICT_H


/*======  Dependencies  ======*/
#include <stddef.h>  /* size_t */

#if defined (__cplusplus)
extern "C" {
#endif

/* =====   ZDICTLIB_API : control library symbols visibility   ===== */
#ifndef ZDICTLIB_VISIBLE
   /* Backwards compatibility with old macro name */
#  ifdef ZDICTLIB_VISIBILITY
#    define ZDICTLIB_VISIBLE ZDICTLIB_VISIBILITY
#  elif defined(__GNUC__) && (__GNUC__ >= 4) && !defined(__MINGW32__)
#    define ZDICTLIB_VISIBLE __attribute__ ((visibility ("default")))
#  else
#    define ZDICTLIB_VISIBLE
#  endif
#endif

#ifndef ZDICTLIB_HIDDEN
#  if defined(__GNUC__) && (__GNUC__ >= 4) && !defined(__MINGW32__)
#    define ZDICTLIB_HIDDEN __attribute__ ((visibility ("hidden")))
#  else
#    define ZDICTLIB_HIDDEN
#  endif
#endif

#if defined(ZSTD_DLL_EXPORT) && (ZSTD_DLL_EXPORT==1)
#  define ZDICTLIB_API __declspec(dllexport) ZDICTLIB_VISIBLE
#elif defined(ZSTD_DLL_IMPORT) && (ZSTD_DLL_IMPORT==1)
#  define ZDICTLIB_API __declspec(dllimport) ZDICTLIB_VISIBLE /* It isn't required but allows to generate better code, saving a function pointer load from the IAT and an indirect jump.*/
#else
#  define ZDICTLIB_API ZDICTLIB_VISIBLE
#endif

/*******************************************************************************
 * Zstd dictionary builder
 *
 * FAQ
 * ===
 * Why should I use a dictionary?
 * ------------------------------
 *
 * Zstd can use dictionaries to improve compression ratio of small data.
 * Traditionally small files don't compress well because there is very little
 * repetition in a single sample, since it is small. But, if you are compressing
 * many similar files, like a bunch of JSON records that share the same
 * structure, you can train a dictionary on ahead of time on some samples of
 * these files. Then, zstd can use the dictionary to find repetitions that are
 * present across samples. This can vastly improve compression ratio.
 *
 * When is a dictionary useful?
 * ----------------------------
 *
 * Dictionaries are useful when compressing many small files that are similar.
 * The larger a file is, the less benefit a dictionary will have. Generally,
 * we don't expect dictionary compression to be effective past 100KB. And the
 * smaller a file is, the more we would expect the dictionary to help.
 *
 * How do I use a dictionary?
 * --------------------------
 *
 * Simply pass the dictionary to the zstd compressor with
 * `ZSTD_CCtx_loadDictionary()`. The same dictionary must then be passed to
 * the decompressor, using `ZSTD_DCtx_loadDictionary()`. There are other
 * more advanced functions that allow selecting some options, see zstd.h for
 * complete documentation.
 *
 * What is a zstd dictionary?
 * --------------------------
 *
 * A zstd dictionary has two pieces: Its header, and its content. The header
 * contains a magic number, the dictionary ID, and entropy tables. These
 * entropy tables allow zstd to save on header costs in the compressed file,
 * which really matters for small data. The content is just bytes, which are
 * repeated content that is common across many samples.
 *
 * What is a raw content dictionary?
 * ---------------------------------
 *
 * A raw content dictionary is just bytes. It doesn't have a zstd dictionary
 * header, a dictionary ID, or entropy tables. Any buffer is a valid raw
 * content dictionary.
 *
 * How do I train a dictionary?
 * ----------------------------
 *
 * Gather samples from your use case. These samples should be similar to each
 * other. If you have several use cases, you could try to train one dictionary
 * per use case.
 *
 * Pass those samples to `ZDICT_trainFromBuffer()` and that will train your
 * dictionary. There are a few advanced versions of this function, but this
 * is a great starting point. If you want to further tune your dictionary
 * you could try `ZDICT_optimizeTrainFromBuffer_cover()`. If that is too slow
 * you can try `ZDICT_optimizeTrainFromBuffer_fastCover()`.
 *
 * If the dictionary training function fails, that is likely because you
 * either passed too few samples, or a dictionary would not be effective
 * for your data. Look at the messages that the dictionary trainer printed,
 * if it doesn't say too few samples, then a dictionary would not be effective.
 *
 * How large should my dictionary be?
 * ----------------------------------
 *
 * A reasonable dictionary size, the `dictBufferCapacity`, is about 100KB.
 * The zstd CLI defaults to a 110KB dictionary. You likely don't need a
 * dictionary larger than that. But, most use cases can get away with a
 * smaller dictionary. The advanced dictionary builders can automatically
 * shrink the dictionary for you, and select the smallest size that doesn't
 * hurt compression ratio too much. See the `shrinkDict` parameter.
 * A smaller dictionary can save memory, and potentially speed up
 * compression.
 *
 * How many samples should I provide to the dictionary builder?
 * ------------------------------------------------------------
 *
 * We generally recommend passing ~100x the size of the dictionary
 * in samples. A few thousand should suffice. Having too few samples
 * can hurt the dictionaries effectiveness. Having more samples will
 * only improve the dictionaries effectiveness. But having too many
 * samples can slow down the dictionary builder.
 *
 * How do I determine if a dictionary will be effective?
 * -----------------------------------------------------
 *
 * Simply train a dictionary and try it out. You can use zstd's built in
 * benchmarking tool to test the dictionary effectiveness.
 *
 *   # Benchmark levels 1-3 without a dictionary
 *   zstd -b1e3 -r /path/to/my/files
 *   # Benchmark levels 1-3 with a dictionary
 *   zstd -b1e3 -r /path/to/my/files -D /path/to/my/dictionary
 *
 * When should I retrain a dictionary?
 * -----------------------------------
 *
 * You should retrain a dictionary when its effectiveness drops. Dictionary
 * effectiveness drops as the data you are compressing changes. Generally, we do
 * expect dictionaries to "decay" over time, as your data changes, but the rate
 * at which they decay depends on your use case. Internally, we regularly
 * retrain dictionaries, and if the new dictionary performs significantly
 * better than the old dictionary, we will ship the new dictionary.
 *
 * I have a raw content dictionary, how do I turn it into a zstd dictionary?
 * -------------------------------------------------------------------------
 *
 * If you have a raw content dictionary, e.g. by manually constructing it, or
 * using a third-party dictionary builder, you can turn it into a zstd
 * dictionary by using `ZDICT_finalizeDictionary()`. You'll also have to
 * provide some samples of the data. It will add the zstd header to the
 * raw content, which contains a dictionary ID and entropy tables, which
 * will improve compression ratio, and allow zstd to write the dictionary ID
 * into the frame, if you so choose.
 *
 * Do I have to use zstd's dictionary builder?
 * -------------------------------------------
 *
 * No! You can construct dictionary content however you please, it is just
 * bytes. It will always be valid as a raw content dictionary. If you want
 * a zstd dictionary, which can improve compression ratio, use
 * `ZDICT_finalizeDictionary()`.
 *
 * What is the attack surface of a zstd dictionary?
 * ------------------------------------------------
 *
 * Zstd is heavily fuzz tested, including loading fuzzed dictionaries, so
 * zstd should never crash, or access out-of-bounds memory no matter what
 * the dictionary is. However, if an attacker can control the dictionary
 * during decompression, they can cause zstd to generate arbitrary bytes,
 * just like if they controlled the compressed data.
 *
 ******************************************************************************/


/*! ZDICT_trainFromBuffer():
 *  Train a dictionary from an array of samples.
 *  Redirect towards ZDICT_optimizeTrainFromBuffer_fastCover() single-threaded, with d=8, steps=4,
 *  f=20, and accel=1.
 *  Samples must be stored concatenated in a single flat buffer `samplesBuffer`,
 *  supplied with an array of sizes `samplesSizes`, providing the size of each sample, in order.
 *  The resulting dictionary will be saved into `dictBuffer`.
 * @return: size of dictionary stored into `dictBuffer` (<= `dictBufferCapacity`)
 *          or an error code, which can be tested with ZDICT_isError().
 *  Note:  Dictionary training will fail if there are not enough samples to construct a
 *         dictionary, or if most of the samples are too small (< 8 bytes being the lower limit).
 *         If dictionary training fails, you should use zstd without a dictionary, as the dictionary
 *         would've been ineffective anyways. If you believe your samples would benefit from a dictionary
 *         please open an issue with details, and we can look into it.
 *  Note: ZDICT_trainFromBuffer()'s memory usage is about 6 MB.
 *  Tips: In general, a reasonable dictionary has a size of ~ 100 KB.
 *        It's possible to select smaller or larger size, just by specifying `dictBufferCapacity`.
 *        In general, it's recommended to provide a few thousands samples, though this can vary a lot.
 *        It's recommended that total size of all samples be about ~x100 times the target size of dictionary.
 */
ZDICTLIB_API size_t ZDICT_trainFromBuffer(void* dictBuffer, size_t dictBufferCapacity,
                                    const void* samplesBuffer,
                                    const size_t* samplesSizes, unsigned nbSamples);

typedef struct {
    int      compressionLevel;   /**< optimize for a specific zstd compression level; 0 means default */
    unsigned notificationLevel;  /**< Write log to stderr; 0 = none (default); 1 = errors; 2 = progression; 3 = details; 4 = debug; */
    unsigned dictID;             /**< force dictID value; 0 means auto mode (32-bits random value)
                                  *   NOTE: The zstd format reserves some dictionary IDs for future use.
                                  *         You may use them in private settings, but be warned that they
                                  *         may be used by zstd in a public dictionary registry in the future.
                                  *         These dictionary IDs are:
                                  *           - low range  : <= 32767
                                  *           - high range : >= (2^31)
                                  */
} ZDICT_params_t;

/*! ZDICT_finalizeDictionary():
 * Given a custom content as a basis for dictionary, and a set of samples,
 * finalize dictionary by adding headers and statistics according to the zstd
 * dictionary format.
 *
 * Samples must be stored concatenated in a flat buffer `samplesBuffer`,
 * supplied with an array of sizes `samplesSizes`, providing the size of each
 * sample in order. The samples are used to construct the statistics, so they
 * should be representative of what you will compress with this dictionary.
 *
 * The compression level can be set in `parameters`. You should pass the
 * compression level you expect to use in production. The statistics for each
 * compression level differ, so tuning the dictionary for the compression level
 * can help quite a bit.
 *
 * You can set an explicit dictionary ID in `parameters`, or allow us to pick
 * a random dictionary ID for you, but we can't guarantee no collisions.
 *
 * The dstDictBuffer and the dictContent may overlap, and the content will be
 * appended to the end of the header. If the header + the content doesn't fit in
 * maxDictSize the beginning of the content is truncated to make room, since it
 * is presumed that the most profitable content is at the end of the dictionary,
 * since that is the cheapest to reference.
 *
 * `maxDictSize` must be >= max(dictContentSize, ZDICT_DICTSIZE_MIN).
 *
 * @return: size of dictionary stored into `dstDictBuffer` (<= `maxDictSize`),
 *          or an error code, which can be tested by ZDICT_isError().
 * Note: ZDICT_finalizeDictionary() will push notifications into stderr if
 *       instructed to, using notificationLevel>0.
 * NOTE: This function currently may fail in several edge cases including:
 *         * Not enough samples
 *         * Samples are uncompressible
 *         * Samples are all exactly the same
 */
ZDICTLIB_API size_t ZDICT_finalizeDictionary(void* dstDictBuffer, size_t maxDictSize,
                                const void* dictContent, size_t dictContentSize,
                                const void* samplesBuffer, const size_t* samplesSizes, unsigned nbSamples,
                                ZDICT_params_t parameters);


/*======   Helper functions   ======*/
ZDICTLIB_API unsigned ZDICT_getDictID(const void* dictBuffer, size_t dictSize);  /**< extracts dictID; @return zero if error (not a valid dictionary) */
ZDICTLIB_API size_t ZDICT_getDictHeaderSize(const void* dictBuffer, size_t dictSize);  /* returns dict header size; returns a ZSTD error code on failure */
ZDICTLIB_API unsigned ZDICT_isError(size_t errorCode);
ZDICTLIB_API const char* ZDICT_getErrorName(size_t errorCode);

#if defined (__cplusplus)
}
#endif

#endif   /* ZSTD_ZDICT_H */

#if defined(ZDICT_STATIC_LINKING_ONLY) && !defined(ZSTD_ZDICT_H_STATIC)
#define ZSTD_ZDICT_H_STATIC

#if defined (__cplusplus)
extern "C" {
#endif

/* This can be overridden externally to hide static symbols. */
#ifndef ZDICTLIB_STATIC_API
#  if defined(ZSTD_DLL_EXPORT) && (ZSTD_DLL_EXPORT==1)
#    define ZDICTLIB_STATIC_API __declspec(dllexport) ZDICTLIB_VISIBLE
#  elif defined(ZSTD_DLL_IMPORT) && (ZSTD_DLL_IMPORT==1)
#    define ZDICTLIB_STATIC_API __declspec(dllimport) ZDICTLIB_VISIBLE
#  else
#    define ZDICTLIB_STATIC_API ZDICTLIB_VISIBLE
#  endif
#endif

/* ====================================================================================
 * The definitions in this section are considered experimental.
 * They should never be used with a dynamic library, as they may change in the future.
 * They are provided for advanced usages.
 * Use them only in association with static linking.
 * ==================================================================================== */

#define ZDICT_DICTSIZE_MIN    256
/* Deprecated: Remove in v1.6.0 */
#define ZDICT_CONTENTSIZE_MIN 128

/*! ZDICT_cover_params_t:
 *  k and d are the only required parameters.
 *  For others, value 0 means default.
 */
typedef struct {
    unsigned k;                  /* Segment size : constraint: 0 < k : Reasonable range [16, 2048+] */
    unsigned d;                  /* dmer size : constraint: 0 < d <= k : Reasonable range [6, 16] */
    unsigned steps;              /* Number of steps : Only used for optimization : 0 means default (40) : Higher means more parameters checked */
    unsigned nbThreads;          /* Number of threads : constraint: 0 < nbThreads : 1 means single-threaded : Only used for optimization : Ignored if ZSTD_MULTITHREAD is not defined */
    double splitPoint;           /* Percentage of samples used for training: Only used for optimization : the first nbSamples * splitPoint samples will be used to training, the last nbSamples * (1 - splitPoint) samples will be used for testing, 0 means default (1.0), 1.0 when all samples are used for both training and testing */
    unsigned shrinkDict;         /* Train dictionaries to shrink in size starting from the minimum size and selects the smallest dictionary that is shrinkDictMaxRegression% worse than the largest dictionary. 0 means no shrinking and 1 means shrinking  */
    unsigned shrinkDictMaxRegression; /* Sets shrinkDictMaxRegression so that a smaller dictionary can be at worse shrinkDictMaxRegression% worse than the max dict size dictionary. */
    ZDICT_params_t zParams;
} ZDICT_cover_params_t;

typedef struct {
    unsigned k;                  /* Segment size : constraint: 0 < k : Reasonable range [16, 2048+] */
    unsigned d;                  /* dmer size : constraint: 0 < d <= k : Reasonable range [6, 16] */
    unsigned f;                  /* log of size of frequency array : constraint: 0 < f <= 31 : 1 means default(20)*/
    unsigned steps;              /* Number of steps : Only used for optimization : 0 means default (40) : Higher means more parameters checked */
    unsigned nbThreads;          /* Number of threads : constraint: 0 < nbThreads : 1 means single-threaded : Only used for optimization : Ignored if ZSTD_MULTITHREAD is not defined */
    double splitPoint;           /* Percentage of samples used for training: Only used for optimization : the first nbSamples * splitPoint samples will be used to training, the last nbSamples * (1 - splitPoint) samples will be used for testing, 0 means default (0.75), 1.0 when all samples are used for both training and testing */
    unsigned accel;              /* Acceleration level: constraint: 0 < accel <= 10, higher means faster and less accurate, 0 means default(1) */
    unsigned shrinkDict;         /* Train dictionaries to shrink in size starting from the minimum size and selects the smallest dictionary that is shrinkDictMaxRegression% worse than the largest dictionary. 0 means no shrinking and 1 means shrinking  */
    unsigned shrinkDictMaxRegression; /* Sets shrinkDictMaxRegression so that a smaller dictionary can be at worse shrinkDictMaxRegression% worse than the max dict size dictionary. */

    ZDICT_params_t zParams;
} ZDICT_fastCover_params_t;

/*! ZDICT_trainFromBuffer_cover():
 *  Train a dictionary from an array of samples using the COVER algorithm.
 *  Samples must be stored concatenated in a single flat buffer `samplesBuffer`,
 *  supplied with an array of sizes `samplesSizes`, providing the size of each sample, in order.
 *  The resulting dictionary will be saved into `dictBuffer`.
 * @return: size of dictionary stored into `dictBuffer` (<= `dictBufferCapacity`)
 *          or an error code, which can be tested with ZDICT_isError().
 *          See ZDICT_trainFromBuffer() for details on failure modes.
 *  Note: ZDICT_trainFromBuffer_cover() requires about 9 bytes of memory for each input byte.
 *  Tips: In general, a reasonable dictionary has a size of ~ 100 KB.
 *        It's possible to select smaller or larger size, just by specifying `dictBufferCapacity`.
 *        In general, it's recommended to provide a few thousands samples, though this can vary a lot.
 *        It's recommended that total size of all samples be about ~x100 times the target size of dictionary.
 */
ZDICTLIB_STATIC_API size_t ZDICT_trainFromBuffer_cover(
          void *dictBuffer, size_t dictBufferCapacity,
    const void *samplesBuffer, const size_t *samplesSizes, unsigned nbSamples,
          ZDICT_cover_params_t parameters);

/*! ZDICT_optimizeTrainFromBuffer_cover():
 * The same requirements as above hold for all the parameters except `parameters`.
 * This function tries many parameter combinations and picks the best parameters.
 * `*parameters` is filled with the best parameters found,
 * dictionary constructed with those parameters is stored in `dictBuffer`.
 *
 * All of the parameters d, k, steps are optional.
 * If d is non-zero then we don't check multiple values of d, otherwise we check d = {6, 8}.
 * if steps is zero it defaults to its default value.
 * If k is non-zero then we don't check multiple values of k, otherwise we check steps values in [50, 2000].
 *
 * @return: size of dictionary stored into `dictBuffer` (<= `dictBufferCapacity`)
 *          or an error code, which can be tested with ZDICT_isError().
 *          On success `*parameters` contains the parameters selected.
 *          See ZDICT_trainFromBuffer() for details on failure modes.
 * Note: ZDICT_optimizeTrainFromBuffer_cover() requires about 8 bytes of memory for each input byte and additionally another 5 bytes of memory for each byte of memory for each thread.
 */
ZDICTLIB_STATIC_API size_t ZDICT_optimizeTrainFromBuffer_cover(
          void* dictBuffer, size_t dictBufferCapacity,
    const void* samplesBuffer, const size_t* samplesSizes, unsigned nbSamples,
          ZDICT_cover_params_t* parameters);

/*! ZDICT_trainFromBuffer_fastCover():
 *  Train a dictionary from an array of samples using a modified version of COVER algorithm.
 *  Samples must be stored concatenated in a single flat buffer `samplesBuffer`,
 *  supplied with an array of sizes `samplesSizes`, providing the size of each sample, in order.
 *  d and k are required.
 *  All other parameters are optional, will use default values if not provided
 *  The resulting dictionary will be saved into `dictBuffer`.
 * @return: size of dictionary stored into `dictBuffer` (<= `dictBufferCapacity`)
 *          or an error code, which can be tested with ZDICT_isError().
 *          See ZDICT_trainFromBuffer() for details on failure modes.
 *  Note: ZDICT_trainFromBuffer_fastCover() requires 6 * 2^f bytes of memory.
 *  Tips: In general, a reasonable dictionary has a size of ~ 100 KB.
 *        It's possible to select smaller or larger size, just by specifying `dictBufferCapacity`.
 *        In general, it's recommended to provide a few thousands samples, though this can vary a lot.
 *        It's recommended that total size of all samples be about ~x100 times the target size of dictionary.
 */
ZDICTLIB_STATIC_API size_t ZDICT_trainFromBuffer_fastCover(void *dictBuffer,
                    size_t dictBufferCapacity, const void *samplesBuffer,
                    const size_t *samplesSizes, unsigned nbSamples,
                    ZDICT_fastCover_params_t parameters);

/*! ZDICT_optimizeTrainFromBuffer_fastCover():
 * The same requirements as above hold for all the parameters except `parameters`.
 * This function tries many parameter combinations (specifically, k and d combinations)
 * and picks the best parameters. `*parameters` is filled with the best parameters found,
 * dictionary constructed with those parameters is stored in `dictBuffer`.
 * All of the parameters d, k, steps, f, and accel are optional.
 * If d is non-zero then we don't check multiple values of d, otherwise we check d = {6, 8}.
 * if steps is zero it defaults to its default value.
 * If k is non-zero then we don't check multiple values of k, otherwise we check steps values in [50, 2000].
 * If f is zero, default value of 20 is used.
 * If accel is zero, default value of 1 is used.
 *
 * @return: size of dictionary stored into `dictBuffer` (<= `dictBufferCapacity`)
 *          or an error code, which can be tested with ZDICT_isError().
 *          On success `*parameters` contains the parameters selected.
 *          See ZDICT_trainFromBuffer() for details on failure modes.
 * Note: ZDICT_optimizeTrainFromBuffer_fastCover() requires about 6 * 2^f bytes of memory for each thread.
 */
ZDICTLIB_STATIC_API size_t ZDICT_optimizeTrainFromBuffer_fastCover(void* dictBuffer,
                    size_t dictBufferCapacity, const void* samplesBuffer,
                    const size_t* samplesSizes, unsigned nbSamples,
                    ZDICT_fastCover_params_t* parameters);

typedef struct {
    unsigned selectivityLevel;   /* 0 means default; larger => select more => larger dictionary */
    ZDICT_params_t zParams;
} ZDICT_legacy_params_t;

/*! ZDICT_trainFromBuffer_legacy():
 *  Train a dictionary from an array of samples.
 *  Samples must be stored concatenated in a single flat buffer `samplesBuffer`,
 *  supplied with an array of sizes `samplesSizes`, providing the size of each sample, in order.
 *  The resulting dictionary will be saved into `dictBuffer`.
 * `parameters` is optional and can be provided with values set to 0 to mean "default".
 * @return: size of dictionary stored into `dictBuffer` (<= `dictBufferCapacity`)
 *          or an error code, which can be tested with ZDICT_isError().
 *          See ZDICT_trainFromBuffer() for details on failure modes.
 *  Tips: In general, a reasonable dictionary has a size of ~ 100 KB.
 *        It's possible to select smaller or larger size, just by specifying `dictBufferCapacity`.
 *        In general, it's recommended to provide a few thousands samples, though this can vary a lot.
 *        It's recommended that total size of all samples be about ~x100 times the target size of dictionary.
 *  Note: ZDICT_trainFromBuffer_legacy() will send notifications into stderr if instructed to, using notificationLevel>0.
 */
ZDICTLIB_STATIC_API size_t ZDICT_trainFromBuffer_legacy(
    void* dictBuffer, size_t dictBufferCapacity,
    const void* samplesBuffer, const size_t* samplesSizes, unsigned nbSamples,
    ZDICT_legacy_params_t parameters);


/* Deprecation warnings */
/* It is generally possible to disable deprecation warnings from compiler,
   for example with -Wno-deprecated-declarations for gcc
   or _CRT_SECURE_NO_WARNINGS in Visual.
   Otherwise, it's also possible to manually define ZDICT_DISABLE_DEPRECATE_WARNINGS */
#ifdef ZDICT_DISABLE_DEPRECATE_WARNINGS
#  define ZDICT_DEPRECATED(message) /* disable deprecation warnings */
#else
#  define ZDICT_GCC_VERSION (__GNUC__ * 100 + __GNUC_MINOR__)
#  if defined (__cplusplus) && (__cplusplus >= 201402) /* C++14 or greater */
#    define ZDICT_DEPRECATED(message) [[deprecated(message)]]
#  elif defined(__clang__) || (ZDICT_GCC_VERSION >= 405)
#    define ZDICT_DEPRECATED(message) __attribute__((deprecated(message)))
#  elif (ZDICT_GCC_VERSION >= 301)
#    define ZDICT_DEPRECATED(message) __attribute__((deprecated))
#  elif defined(_MSC_VER)
#    define ZDICT_DEPRECATED(message) __declspec(deprecated(message))
#  else
#    pragma message("WARNING: You need to implement ZDICT_DEPRECATED for this compiler")
#    define ZDICT_DEPRECATED(message)
#  endif
#endif /* ZDICT_DISABLE_DEPRECATE_WARNINGS */

ZDICT_DEPRECATED("use ZDICT_finalizeDictionary() instead")
ZDICTLIB_STATIC_API
size_t ZDICT_addEntropyTablesFromBuffer(void* dictBuffer, size_t dictContentSize, size_t dictBufferCapacity,
                                  const void* samplesBuffer, const size_t* samplesSizes, unsigned nbSamples);

#if defined (__cplusplus)
}
#endif

#endif   /* ZSTD_ZDICT_H_STATIC */
```

--- file: target/debug/build/zstd-sys-6db71bc350d87f54/out/include/zstd.h ---
```h
/*
 * Copyright (c) Meta Platforms, Inc. and affiliates.
 * All rights reserved.
 *
 * This source code is licensed under both the BSD-style license (found in the
 * LICENSE file in the root directory of this source tree) and the GPLv2 (found
 * in the COPYING file in the root directory of this source tree).
 * You may select, at your option, one of the above-listed licenses.
 */

#ifndef ZSTD_H_235446
#define ZSTD_H_235446


/* ======   Dependencies   ======*/
#include <stddef.h>   /* size_t */

#include "zstd_errors.h" /* list of errors */
#if defined(ZSTD_STATIC_LINKING_ONLY) && !defined(ZSTD_H_ZSTD_STATIC_LINKING_ONLY)
#include <limits.h>   /* INT_MAX */
#endif /* ZSTD_STATIC_LINKING_ONLY */

#if defined (__cplusplus)
extern "C" {
#endif

/* =====   ZSTDLIB_API : control library symbols visibility   ===== */
#ifndef ZSTDLIB_VISIBLE
   /* Backwards compatibility with old macro name */
#  ifdef ZSTDLIB_VISIBILITY
#    define ZSTDLIB_VISIBLE ZSTDLIB_VISIBILITY
#  elif defined(__GNUC__) && (__GNUC__ >= 4) && !defined(__MINGW32__)
#    define ZSTDLIB_VISIBLE __attribute__ ((visibility ("default")))
#  else
#    define ZSTDLIB_VISIBLE
#  endif
#endif

#ifndef ZSTDLIB_HIDDEN
#  if defined(__GNUC__) && (__GNUC__ >= 4) && !defined(__MINGW32__)
#    define ZSTDLIB_HIDDEN __attribute__ ((visibility ("hidden")))
#  else
#    define ZSTDLIB_HIDDEN
#  endif
#endif

#if defined(ZSTD_DLL_EXPORT) && (ZSTD_DLL_EXPORT==1)
#  define ZSTDLIB_API __declspec(dllexport) ZSTDLIB_VISIBLE
#elif defined(ZSTD_DLL_IMPORT) && (ZSTD_DLL_IMPORT==1)
#  define ZSTDLIB_API __declspec(dllimport) ZSTDLIB_VISIBLE /* It isn't required but allows to generate better code, saving a function pointer load from the IAT and an indirect jump.*/
#else
#  define ZSTDLIB_API ZSTDLIB_VISIBLE
#endif

/* Deprecation warnings :
 * Should these warnings be a problem, it is generally possible to disable them,
 * typically with -Wno-deprecated-declarations for gcc or _CRT_SECURE_NO_WARNINGS in Visual.
 * Otherwise, it's also possible to define ZSTD_DISABLE_DEPRECATE_WARNINGS.
 */
#ifdef ZSTD_DISABLE_DEPRECATE_WARNINGS
#  define ZSTD_DEPRECATED(message) /* disable deprecation warnings */
#else
#  if defined (__cplusplus) && (__cplusplus >= 201402) /* C++14 or greater */
#    define ZSTD_DEPRECATED(message) [[deprecated(message)]]
#  elif (defined(GNUC) && (GNUC > 4 || (GNUC == 4 && GNUC_MINOR >= 5))) || defined(__clang__) || defined(__IAR_SYSTEMS_ICC__)
#    define ZSTD_DEPRECATED(message) __attribute__((deprecated(message)))
#  elif defined(__GNUC__) && (__GNUC__ >= 3)
#    define ZSTD_DEPRECATED(message) __attribute__((deprecated))
#  elif defined(_MSC_VER)
#    define ZSTD_DEPRECATED(message) __declspec(deprecated(message))
#  else
#    pragma message("WARNING: You need to implement ZSTD_DEPRECATED for this compiler")
#    define ZSTD_DEPRECATED(message)
#  endif
#endif /* ZSTD_DISABLE_DEPRECATE_WARNINGS */


/*******************************************************************************
  Introduction

  zstd, short for Zstandard, is a fast lossless compression algorithm, targeting
  real-time compression scenarios at zlib-level and better compression ratios.
  The zstd compression library provides in-memory compression and decompression
  functions.

  The library supports regular compression levels from 1 up to ZSTD_maxCLevel(),
  which is currently 22. Levels >= 20, labeled `--ultra`, should be used with
  caution, as they require more memory. The library also offers negative
  compression levels, which extend the range of speed vs. ratio preferences.
  The lower the level, the faster the speed (at the cost of compression).

  Compression can be done in:
    - a single step (described as Simple API)
    - a single step, reusing a context (described as Explicit context)
    - unbounded multiple steps (described as Streaming compression)

  The compression ratio achievable on small data can be highly improved using
  a dictionary. Dictionary compression can be performed in:
    - a single step (described as Simple dictionary API)
    - a single step, reusing a dictionary (described as Bulk-processing
      dictionary API)

  Advanced experimental functions can be accessed using
  `#define ZSTD_STATIC_LINKING_ONLY` before including zstd.h.

  Advanced experimental APIs should never be used with a dynamically-linked
  library. They are not "stable"; their definitions or signatures may change in
  the future. Only static linking is allowed.
*******************************************************************************/

/*------   Version   ------*/
#define ZSTD_VERSION_MAJOR    1
#define ZSTD_VERSION_MINOR    5
#define ZSTD_VERSION_RELEASE  7
#define ZSTD_VERSION_NUMBER  (ZSTD_VERSION_MAJOR *100*100 + ZSTD_VERSION_MINOR *100 + ZSTD_VERSION_RELEASE)

/*! ZSTD_versionNumber() :
 *  Return runtime library version, the value is (MAJOR*100*100 + MINOR*100 + RELEASE). */
ZSTDLIB_API unsigned ZSTD_versionNumber(void);

#define ZSTD_LIB_VERSION ZSTD_VERSION_MAJOR.ZSTD_VERSION_MINOR.ZSTD_VERSION_RELEASE
#define ZSTD_QUOTE(str) #str
#define ZSTD_EXPAND_AND_QUOTE(str) ZSTD_QUOTE(str)
#define ZSTD_VERSION_STRING ZSTD_EXPAND_AND_QUOTE(ZSTD_LIB_VERSION)

/*! ZSTD_versionString() :
 *  Return runtime library version, like "1.4.5". Requires v1.3.0+. */
ZSTDLIB_API const char* ZSTD_versionString(void);

/* *************************************
 *  Default constant
 ***************************************/
#ifndef ZSTD_CLEVEL_DEFAULT
#  define ZSTD_CLEVEL_DEFAULT 3
#endif

/* *************************************
 *  Constants
 ***************************************/

/* All magic numbers are supposed read/written to/from files/memory using little-endian convention */
#define ZSTD_MAGICNUMBER            0xFD2FB528    /* valid since v0.8.0 */
#define ZSTD_MAGIC_DICTIONARY       0xEC30A437    /* valid since v0.7.0 */
#define ZSTD_MAGIC_SKIPPABLE_START  0x184D2A50    /* all 16 values, from 0x184D2A50 to 0x184D2A5F, signal the beginning of a skippable frame */
#define ZSTD_MAGIC_SKIPPABLE_MASK   0xFFFFFFF0

#define ZSTD_BLOCKSIZELOG_MAX  17
#define ZSTD_BLOCKSIZE_MAX     (1<<ZSTD_BLOCKSIZELOG_MAX)


/***************************************
*  Simple Core API
***************************************/
/*! ZSTD_compress() :
 *  Compresses `src` content as a single zstd compressed frame into already allocated `dst`.
 *  NOTE: Providing `dstCapacity >= ZSTD_compressBound(srcSize)` guarantees that zstd will have
 *        enough space to successfully compress the data.
 *  @return : compressed size written into `dst` (<= `dstCapacity),
 *            or an error code if it fails (which can be tested using ZSTD_isError()). */
ZSTDLIB_API size_t ZSTD_compress( void* dst, size_t dstCapacity,
                            const void* src, size_t srcSize,
                                  int compressionLevel);

/*! ZSTD_decompress() :
 * `compressedSize` : must be the _exact_ size of some number of compressed and/or skippable frames.
 *  Multiple compressed frames can be decompressed at once with this method.
 *  The result will be the concatenation of all decompressed frames, back to back.
 * `dstCapacity` is an upper bound of originalSize to regenerate.
 *  First frame's decompressed size can be extracted using ZSTD_getFrameContentSize().
 *  If maximum upper bound isn't known, prefer using streaming mode to decompress data.
 * @return : the number of bytes decompressed into `dst` (<= `dstCapacity`),
 *           or an errorCode if it fails (which can be tested using ZSTD_isError()). */
ZSTDLIB_API size_t ZSTD_decompress( void* dst, size_t dstCapacity,
                              const void* src, size_t compressedSize);


/*======  Decompression helper functions  ======*/

/*! ZSTD_getFrameContentSize() : requires v1.3.0+
 * `src` should point to the start of a ZSTD encoded frame.
 * `srcSize` must be at least as large as the frame header.
 *           hint : any size >= `ZSTD_frameHeaderSize_max` is large enough.
 * @return : - decompressed size of `src` frame content, if known
 *           - ZSTD_CONTENTSIZE_UNKNOWN if the size cannot be determined
 *           - ZSTD_CONTENTSIZE_ERROR if an error occurred (e.g. invalid magic number, srcSize too small)
 *  note 1 : a 0 return value means the frame is valid but "empty".
 *           When invoking this method on a skippable frame, it will return 0.
 *  note 2 : decompressed size is an optional field, it may not be present (typically in streaming mode).
 *           When `return==ZSTD_CONTENTSIZE_UNKNOWN`, data to decompress could be any size.
 *           In which case, it's necessary to use streaming mode to decompress data.
 *           Optionally, application can rely on some implicit limit,
 *           as ZSTD_decompress() only needs an upper bound of decompressed size.
 *           (For example, data could be necessarily cut into blocks <= 16 KB).
 *  note 3 : decompressed size is always present when compression is completed using single-pass functions,
 *           such as ZSTD_compress(), ZSTD_compressCCtx() ZSTD_compress_usingDict() or ZSTD_compress_usingCDict().
 *  note 4 : decompressed size can be very large (64-bits value),
 *           potentially larger than what local system can handle as a single memory segment.
 *           In which case, it's necessary to use streaming mode to decompress data.
 *  note 5 : If source is untrusted, decompressed size could be wrong or intentionally modified.
 *           Always ensure return value fits within application's authorized limits.
 *           Each application can set its own limits.
 *  note 6 : This function replaces ZSTD_getDecompressedSize() */
#define ZSTD_CONTENTSIZE_UNKNOWN (0ULL - 1)
#define ZSTD_CONTENTSIZE_ERROR   (0ULL - 2)
ZSTDLIB_API unsigned long long ZSTD_getFrameContentSize(const void *src, size_t srcSize);

/*! ZSTD_getDecompressedSize() (obsolete):
 *  This function is now obsolete, in favor of ZSTD_getFrameContentSize().
 *  Both functions work the same way, but ZSTD_getDecompressedSize() blends
 *  "empty", "unknown" and "error" results to the same return value (0),
 *  while ZSTD_getFrameContentSize() gives them separate return values.
 * @return : decompressed size of `src` frame content _if known and not empty_, 0 otherwise. */
ZSTD_DEPRECATED("Replaced by ZSTD_getFrameContentSize")
ZSTDLIB_API unsigned long long ZSTD_getDecompressedSize(const void* src, size_t srcSize);

/*! ZSTD_findFrameCompressedSize() : Requires v1.4.0+
 * `src` should point to the start of a ZSTD frame or skippable frame.
 * `srcSize` must be >= first frame size
 * @return : the compressed size of the first frame starting at `src`,
 *           suitable to pass as `srcSize` to `ZSTD_decompress` or similar,
 *           or an error code if input is invalid
 *  Note 1: this method is called _find*() because it's not enough to read the header,
 *          it may have to scan through the frame's content, to reach its end.
 *  Note 2: this method also works with Skippable Frames. In which case,
 *          it returns the size of the complete skippable frame,
 *          which is always equal to its content size + 8 bytes for headers. */
ZSTDLIB_API size_t ZSTD_findFrameCompressedSize(const void* src, size_t srcSize);


/*======  Compression helper functions  ======*/

/*! ZSTD_compressBound() :
 * maximum compressed size in worst case single-pass scenario.
 * When invoking `ZSTD_compress()`, or any other one-pass compression function,
 * it's recommended to provide @dstCapacity >= ZSTD_compressBound(srcSize)
 * as it eliminates one potential failure scenario,
 * aka not enough room in dst buffer to write the compressed frame.
 * Note : ZSTD_compressBound() itself can fail, if @srcSize >= ZSTD_MAX_INPUT_SIZE .
 *        In which case, ZSTD_compressBound() will return an error code
 *        which can be tested using ZSTD_isError().
 *
 * ZSTD_COMPRESSBOUND() :
 * same as ZSTD_compressBound(), but as a macro.
 * It can be used to produce constants, which can be useful for static allocation,
 * for example to size a static array on stack.
 * Will produce constant value 0 if srcSize is too large.
 */
#define ZSTD_MAX_INPUT_SIZE ((sizeof(size_t)==8) ? 0xFF00FF00FF00FF00ULL : 0xFF00FF00U)
#define ZSTD_COMPRESSBOUND(srcSize)   (((size_t)(srcSize) >= ZSTD_MAX_INPUT_SIZE) ? 0 : (srcSize) + ((srcSize)>>8) + (((srcSize) < (128<<10)) ? (((128<<10) - (srcSize)) >> 11) /* margin, from 64 to 0 */ : 0))  /* this formula ensures that bound(A) + bound(B) <= bound(A+B) as long as A and B >= 128 KB */
ZSTDLIB_API size_t ZSTD_compressBound(size_t srcSize); /*!< maximum compressed size in worst case single-pass scenario */


/*======  Error helper functions  ======*/
/* ZSTD_isError() :
 * Most ZSTD_* functions returning a size_t value can be tested for error,
 * using ZSTD_isError().
 * @return 1 if error, 0 otherwise
 */
ZSTDLIB_API unsigned     ZSTD_isError(size_t result);      /*!< tells if a `size_t` function result is an error code */
ZSTDLIB_API ZSTD_ErrorCode ZSTD_getErrorCode(size_t functionResult); /* convert a result into an error code, which can be compared to error enum list */
ZSTDLIB_API const char*  ZSTD_getErrorName(size_t result); /*!< provides readable string from a function result */
ZSTDLIB_API int          ZSTD_minCLevel(void);             /*!< minimum negative compression level allowed, requires v1.4.0+ */
ZSTDLIB_API int          ZSTD_maxCLevel(void);             /*!< maximum compression level available */
ZSTDLIB_API int          ZSTD_defaultCLevel(void);         /*!< default compression level, specified by ZSTD_CLEVEL_DEFAULT, requires v1.5.0+ */


/***************************************
*  Explicit context
***************************************/
/*= Compression context
 *  When compressing many times,
 *  it is recommended to allocate a compression context just once,
 *  and reuse it for each successive compression operation.
 *  This will make the workload easier for system's memory.
 *  Note : re-using context is just a speed / resource optimization.
 *         It doesn't change the compression ratio, which remains identical.
 *  Note 2: For parallel execution in multi-threaded environments,
 *         use one different context per thread .
 */
typedef struct ZSTD_CCtx_s ZSTD_CCtx;
ZSTDLIB_API ZSTD_CCtx* ZSTD_createCCtx(void);
ZSTDLIB_API size_t     ZSTD_freeCCtx(ZSTD_CCtx* cctx);  /* compatible with NULL pointer */

/*! ZSTD_compressCCtx() :
 *  Same as ZSTD_compress(), using an explicit ZSTD_CCtx.
 *  Important : in order to mirror `ZSTD_compress()` behavior,
 *  this function compresses at the requested compression level,
 *  __ignoring any other advanced parameter__ .
 *  If any advanced parameter was set using the advanced API,
 *  they will all be reset. Only @compressionLevel remains.
 */
ZSTDLIB_API size_t ZSTD_compressCCtx(ZSTD_CCtx* cctx,
                                     void* dst, size_t dstCapacity,
                               const void* src, size_t srcSize,
                                     int compressionLevel);

/*= Decompression context
 *  When decompressing many times,
 *  it is recommended to allocate a context only once,
 *  and reuse it for each successive compression operation.
 *  This will make workload friendlier for system's memory.
 *  Use one context per thread for parallel execution. */
typedef struct ZSTD_DCtx_s ZSTD_DCtx;
ZSTDLIB_API ZSTD_DCtx* ZSTD_createDCtx(void);
ZSTDLIB_API size_t     ZSTD_freeDCtx(ZSTD_DCtx* dctx);  /* accept NULL pointer */

/*! ZSTD_decompressDCtx() :
 *  Same as ZSTD_decompress(),
 *  requires an allocated ZSTD_DCtx.
 *  Compatible with sticky parameters (see below).
 */
ZSTDLIB_API size_t ZSTD_decompressDCtx(ZSTD_DCtx* dctx,
                                       void* dst, size_t dstCapacity,
                                 const void* src, size_t srcSize);


/*********************************************
*  Advanced compression API (Requires v1.4.0+)
**********************************************/

/* API design :
 *   Parameters are pushed one by one into an existing context,
 *   using ZSTD_CCtx_set*() functions.
 *   Pushed parameters are sticky : they are valid for next compressed frame, and any subsequent frame.
 *   "sticky" parameters are applicable to `ZSTD_compress2()` and `ZSTD_compressStream*()` !
 *   __They do not apply to one-shot variants such as ZSTD_compressCCtx()__ .
 *
 *   It's possible to reset all parameters to "default" using ZSTD_CCtx_reset().
 *
 *   This API supersedes all other "advanced" API entry points in the experimental section.
 *   In the future, we expect to remove API entry points from experimental which are redundant with this API.
 */


/* Compression strategies, listed from fastest to strongest */
typedef enum { ZSTD_fast=1,
               ZSTD_dfast=2,
               ZSTD_greedy=3,
               ZSTD_lazy=4,
               ZSTD_lazy2=5,
               ZSTD_btlazy2=6,
               ZSTD_btopt=7,
               ZSTD_btultra=8,
               ZSTD_btultra2=9
               /* note : new strategies _might_ be added in the future.
                         Only the order (from fast to strong) is guaranteed */
} ZSTD_strategy;

typedef enum {

    /* compression parameters
     * Note: When compressing with a ZSTD_CDict these parameters are superseded
     * by the parameters used to construct the ZSTD_CDict.
     * See ZSTD_CCtx_refCDict() for more info (superseded-by-cdict). */
    ZSTD_c_compressionLevel=100, /* Set compression parameters according to pre-defined cLevel table.
                              * Note that exact compression parameters are dynamically determined,
                              * depending on both compression level and srcSize (when known).
                              * Default level is ZSTD_CLEVEL_DEFAULT==3.
                              * Special: value 0 means default, which is controlled by ZSTD_CLEVEL_DEFAULT.
                              * Note 1 : it's possible to pass a negative compression level.
                              * Note 2 : setting a level does not automatically set all other compression parameters
                              *   to default. Setting this will however eventually dynamically impact the compression
                              *   parameters which have not been manually set. The manually set
                              *   ones will 'stick'. */
    /* Advanced compression parameters :
     * It's possible to pin down compression parameters to some specific values.
     * In which case, these values are no longer dynamically selected by the compressor */
    ZSTD_c_windowLog=101,    /* Maximum allowed back-reference distance, expressed as power of 2.
                              * This will set a memory budget for streaming decompression,
                              * with larger values requiring more memory
                              * and typically compressing more.
                              * Must be clamped between ZSTD_WINDOWLOG_MIN and ZSTD_WINDOWLOG_MAX.
                              * Special: value 0 means "use default windowLog".
                              * Note: Using a windowLog greater than ZSTD_WINDOWLOG_LIMIT_DEFAULT
                              *       requires explicitly allowing such size at streaming decompression stage. */
    ZSTD_c_hashLog=102,      /* Size of the initial probe table, as a power of 2.
                              * Resulting memory usage is (1 << (hashLog+2)).
                              * Must be clamped between ZSTD_HASHLOG_MIN and ZSTD_HASHLOG_MAX.
                              * Larger tables improve compression ratio of strategies <= dFast,
                              * and improve speed of strategies > dFast.
                              * Special: value 0 means "use default hashLog". */
    ZSTD_c_chainLog=103,     /* Size of the multi-probe search table, as a power of 2.
                              * Resulting memory usage is (1 << (chainLog+2)).
                              * Must be clamped between ZSTD_CHAINLOG_MIN and ZSTD_CHAINLOG_MAX.
                              * Larger tables result in better and slower compression.
                              * This parameter is useless for "fast" strategy.
                              * It's still useful when using "dfast" strategy,
                              * in which case it defines a secondary probe table.
                              * Special: value 0 means "use default chainLog". */
    ZSTD_c_searchLog=104,    /* Number of search attempts, as a power of 2.
                              * More attempts result in better and slower compression.
                              * This parameter is useless for "fast" and "dFast" strategies.
                              * Special: value 0 means "use default searchLog". */
    ZSTD_c_minMatch=105,     /* Minimum size of searched matches.
                              * Note that Zstandard can still find matches of smaller size,
                              * it just tweaks its search algorithm to look for this size and larger.
                              * Larger values increase compression and decompression speed, but decrease ratio.
                              * Must be clamped between ZSTD_MINMATCH_MIN and ZSTD_MINMATCH_MAX.
                              * Note that currently, for all strategies < btopt, effective minimum is 4.
                              *                    , for all strategies > fast, effective maximum is 6.
                              * Special: value 0 means "use default minMatchLength". */
    ZSTD_c_targetLength=106, /* Impact of this field depends on strategy.
                              * For strategies btopt, btultra & btultra2:
                              *     Length of Match considered "good enough" to stop search.
                              *     Larger values make compression stronger, and slower.
                              * For strategy fast:
                              *     Distance between match sampling.
                              *     Larger values make compression faster, and weaker.
                              * Special: value 0 means "use default targetLength". */
    ZSTD_c_strategy=107,     /* See ZSTD_strategy enum definition.
                              * The higher the value of selected strategy, the more complex it is,
                              * resulting in stronger and slower compression.
                              * Special: value 0 means "use default strategy". */

    ZSTD_c_targetCBlockSize=130, /* v1.5.6+
                                  * Attempts to fit compressed block size into approximately targetCBlockSize.
                                  * Bound by ZSTD_TARGETCBLOCKSIZE_MIN and ZSTD_TARGETCBLOCKSIZE_MAX.
                                  * Note that it's not a guarantee, just a convergence target (default:0).
                                  * No target when targetCBlockSize == 0.
                                  * This is helpful in low bandwidth streaming environments to improve end-to-end latency,
                                  * when a client can make use of partial documents (a prominent example being Chrome).
                                  * Note: this parameter is stable since v1.5.6.
                                  * It was present as an experimental parameter in earlier versions,
                                  * but it's not recommended using it with earlier library versions
                                  * due to massive performance regressions.
                                  */
    /* LDM mode parameters */
    ZSTD_c_enableLongDistanceMatching=160, /* Enable long distance matching.
                                     * This parameter is designed to improve compression ratio
                                     * for large inputs, by finding large matches at long distance.
                                     * It increases memory usage and window size.
                                     * Note: enabling this parameter increases default ZSTD_c_windowLog to 128 MB
                                     * except when expressly set to a different value.
                                     * Note: will be enabled by default if ZSTD_c_windowLog >= 128 MB and
                                     * compression strategy >= ZSTD_btopt (== compression level 16+) */
    ZSTD_c_ldmHashLog=161,   /* Size of the table for long distance matching, as a power of 2.
                              * Larger values increase memory usage and compression ratio,
                              * but decrease compression speed.
                              * Must be clamped between ZSTD_HASHLOG_MIN and ZSTD_HASHLOG_MAX
                              * default: windowlog - 7.
                              * Special: value 0 means "automatically determine hashlog". */
    ZSTD_c_ldmMinMatch=162,  /* Minimum match size for long distance matcher.
                              * Larger/too small values usually decrease compression ratio.
                              * Must be clamped between ZSTD_LDM_MINMATCH_MIN and ZSTD_LDM_MINMATCH_MAX.
                              * Special: value 0 means "use default value" (default: 64). */
    ZSTD_c_ldmBucketSizeLog=163, /* Log size of each bucket in the LDM hash table for collision resolution.
                              * Larger values improve collision resolution but decrease compression speed.
                              * The maximum value is ZSTD_LDM_BUCKETSIZELOG_MAX.
                              * Special: value 0 means "use default value" (default: 3). */
    ZSTD_c_ldmHashRateLog=164, /* Frequency of inserting/looking up entries into the LDM hash table.
                              * Must be clamped between 0 and (ZSTD_WINDOWLOG_MAX - ZSTD_HASHLOG_MIN).
                              * Default is MAX(0, (windowLog - ldmHashLog)), optimizing hash table usage.
                              * Larger values improve compression speed.
                              * Deviating far from default value will likely result in a compression ratio decrease.
                              * Special: value 0 means "automatically determine hashRateLog". */

    /* frame parameters */
    ZSTD_c_contentSizeFlag=200, /* Content size will be written into frame header _whenever known_ (default:1)
                              * Content size must be known at the beginning of compression.
                              * This is automatically the case when using ZSTD_compress2(),
                              * For streaming scenarios, content size must be provided with ZSTD_CCtx_setPledgedSrcSize() */
    ZSTD_c_checksumFlag=201, /* A 32-bits checksum of content is written at end of frame (default:0) */
    ZSTD_c_dictIDFlag=202,   /* When applicable, dictionary's ID is written into frame header (default:1) */

    /* multi-threading parameters */
    /* These parameters are only active if multi-threading is enabled (compiled with build macro ZSTD_MULTITHREAD).
     * Otherwise, trying to set any other value than default (0) will be a no-op and return an error.
     * In a situation where it's unknown if the linked library supports multi-threading or not,
     * setting ZSTD_c_nbWorkers to any value >= 1 and consulting the return value provides a quick way to check this property.
     */
    ZSTD_c_nbWorkers=400,    /* Select how many threads will be spawned to compress in parallel.
                              * When nbWorkers >= 1, triggers asynchronous mode when invoking ZSTD_compressStream*() :
                              * ZSTD_compressStream*() consumes input and flush output if possible, but immediately gives back control to caller,
                              * while compression is performed in parallel, within worker thread(s).
                              * (note : a strong exception to this rule is when first invocation of ZSTD_compressStream2() sets ZSTD_e_end :
                              *  in which case, ZSTD_compressStream2() delegates to ZSTD_compress2(), which is always a blocking call).
                              * More workers improve speed, but also increase memory usage.
                              * Default value is `0`, aka "single-threaded mode" : no worker is spawned,
                              * compression is performed inside Caller's thread, and all invocations are blocking */
    ZSTD_c_jobSize=401,      /* Size of a compression job. This value is enforced only when nbWorkers >= 1.
                              * Each compression job is completed in parallel, so this value can indirectly impact the nb of active threads.
                              * 0 means default, which is dynamically determined based on compression parameters.
                              * Job size must be a minimum of overlap size, or ZSTDMT_JOBSIZE_MIN (= 512 KB), whichever is largest.
                              * The minimum size is automatically and transparently enforced. */
    ZSTD_c_overlapLog=402,   /* Control the overlap size, as a fraction of window size.
                              * The overlap size is an amount of data reloaded from previous job at the beginning of a new job.
                              * It helps preserve compression ratio, while each job is compressed in parallel.
                              * This value is enforced only when nbWorkers >= 1.
                              * Larger values increase compression ratio, but decrease speed.
                              * Possible values range from 0 to 9 :
                              * - 0 means "default" : value will be determined by the library, depending on strategy
                              * - 1 means "no overlap"
                              * - 9 means "full overlap", using a full window size.
                              * Each intermediate rank increases/decreases load size by a factor 2 :
                              * 9: full window;  8: w/2;  7: w/4;  6: w/8;  5:w/16;  4: w/32;  3:w/64;  2:w/128;  1:no overlap;  0:default
                              * default value varies between 6 and 9, depending on strategy */

    /* note : additional experimental parameters are also available
     * within the experimental section of the API.
     * At the time of this writing, they include :
     * ZSTD_c_rsyncable
     * ZSTD_c_format
     * ZSTD_c_forceMaxWindow
     * ZSTD_c_forceAttachDict
     * ZSTD_c_literalCompressionMode
     * ZSTD_c_srcSizeHint
     * ZSTD_c_enableDedicatedDictSearch
     * ZSTD_c_stableInBuffer
     * ZSTD_c_stableOutBuffer
     * ZSTD_c_blockDelimiters
     * ZSTD_c_validateSequences
     * ZSTD_c_blockSplitterLevel
     * ZSTD_c_splitAfterSequences
     * ZSTD_c_useRowMatchFinder
     * ZSTD_c_prefetchCDictTables
     * ZSTD_c_enableSeqProducerFallback
     * ZSTD_c_maxBlockSize
     * Because they are not stable, it's necessary to define ZSTD_STATIC_LINKING_ONLY to access them.
     * note : never ever use experimentalParam? names directly;
     *        also, the enums values themselves are unstable and can still change.
     */
     ZSTD_c_experimentalParam1=500,
     ZSTD_c_experimentalParam2=10,
     ZSTD_c_experimentalParam3=1000,
     ZSTD_c_experimentalParam4=1001,
     ZSTD_c_experimentalParam5=1002,
     /* was ZSTD_c_experimentalParam6=1003; is now ZSTD_c_targetCBlockSize */
     ZSTD_c_experimentalParam7=1004,
     ZSTD_c_experimentalParam8=1005,
     ZSTD_c_experimentalParam9=1006,
     ZSTD_c_experimentalParam10=1007,
     ZSTD_c_experimentalParam11=1008,
     ZSTD_c_experimentalParam12=1009,
     ZSTD_c_experimentalParam13=1010,
     ZSTD_c_experimentalParam14=1011,
     ZSTD_c_experimentalParam15=1012,
     ZSTD_c_experimentalParam16=1013,
     ZSTD_c_experimentalParam17=1014,
     ZSTD_c_experimentalParam18=1015,
     ZSTD_c_experimentalParam19=1016,
     ZSTD_c_experimentalParam20=1017
} ZSTD_cParameter;

typedef struct {
    size_t error;
    int lowerBound;
    int upperBound;
} ZSTD_bounds;

/*! ZSTD_cParam_getBounds() :
 *  All parameters must belong to an interval with lower and upper bounds,
 *  otherwise they will either trigger an error or be automatically clamped.
 * @return : a structure, ZSTD_bounds, which contains
 *         - an error status field, which must be tested using ZSTD_isError()
 *         - lower and upper bounds, both inclusive
 */
ZSTDLIB_API ZSTD_bounds ZSTD_cParam_getBounds(ZSTD_cParameter cParam);

/*! ZSTD_CCtx_setParameter() :
 *  Set one compression parameter, selected by enum ZSTD_cParameter.
 *  All parameters have valid bounds. Bounds can be queried using ZSTD_cParam_getBounds().
 *  Providing a value beyond bound will either clamp it, or trigger an error (depending on parameter).
 *  Setting a parameter is generally only possible during frame initialization (before starting compression).
 *  Exception : when using multi-threading mode (nbWorkers >= 1),
 *              the following parameters can be updated _during_ compression (within same frame):
 *              => compressionLevel, hashLog, chainLog, searchLog, minMatch, targetLength and strategy.
 *              new parameters will be active for next job only (after a flush()).
 * @return : an error code (which can be tested using ZSTD_isError()).
 */
ZSTDLIB_API size_t ZSTD_CCtx_setParameter(ZSTD_CCtx* cctx, ZSTD_cParameter param, int value);

/*! ZSTD_CCtx_setPledgedSrcSize() :
 *  Total input data size to be compressed as a single frame.
 *  Value will be written in frame header, unless if explicitly forbidden using ZSTD_c_contentSizeFlag.
 *  This value will also be controlled at end of frame, and trigger an error if not respected.
 * @result : 0, or an error code (which can be tested with ZSTD_isError()).
 *  Note 1 : pledgedSrcSize==0 actually means zero, aka an empty frame.
 *           In order to mean "unknown content size", pass constant ZSTD_CONTENTSIZE_UNKNOWN.
 *           ZSTD_CONTENTSIZE_UNKNOWN is default value for any new frame.
 *  Note 2 : pledgedSrcSize is only valid once, for the next frame.
 *           It's discarded at the end of the frame, and replaced by ZSTD_CONTENTSIZE_UNKNOWN.
 *  Note 3 : Whenever all input data is provided and consumed in a single round,
 *           for example with ZSTD_compress2(),
 *           or invoking immediately ZSTD_compressStream2(,,,ZSTD_e_end),
 *           this value is automatically overridden by srcSize instead.
 */
ZSTDLIB_API size_t ZSTD_CCtx_setPledgedSrcSize(ZSTD_CCtx* cctx, unsigned long long pledgedSrcSize);

typedef enum {
    ZSTD_reset_session_only = 1,
    ZSTD_reset_parameters = 2,
    ZSTD_reset_session_and_parameters = 3
} ZSTD_ResetDirective;

/*! ZSTD_CCtx_reset() :
 *  There are 2 different things that can be reset, independently or jointly :
 *  - The session : will stop compressing current frame, and make CCtx ready to start a new one.
 *                  Useful after an error, or to interrupt any ongoing compression.
 *                  Any internal data not yet flushed is cancelled.
 *                  Compression parameters and dictionary remain unchanged.
 *                  They will be used to compress next frame.
 *                  Resetting session never fails.
 *  - The parameters : changes all parameters back to "default".
 *                  This also removes any reference to any dictionary or external sequence producer.
 *                  Parameters can only be changed between 2 sessions (i.e. no compression is currently ongoing)
 *                  otherwise the reset fails, and function returns an error value (which can be tested using ZSTD_isError())
 *  - Both : similar to resetting the session, followed by resetting parameters.
 */
ZSTDLIB_API size_t ZSTD_CCtx_reset(ZSTD_CCtx* cctx, ZSTD_ResetDirective reset);

/*! ZSTD_compress2() :
 *  Behave the same as ZSTD_compressCCtx(), but compression parameters are set using the advanced API.
 *  (note that this entry point doesn't even expose a compression level parameter).
 *  ZSTD_compress2() always starts a new frame.
 *  Should cctx hold data from a previously unfinished frame, everything about it is forgotten.
 *  - Compression parameters are pushed into CCtx before starting compression, using ZSTD_CCtx_set*()
 *  - The function is always blocking, returns when compression is completed.
 *  NOTE: Providing `dstCapacity >= ZSTD_compressBound(srcSize)` guarantees that zstd will have
 *        enough space to successfully compress the data, though it is possible it fails for other reasons.
 * @return : compressed size written into `dst` (<= `dstCapacity),
 *           or an error code if it fails (which can be tested using ZSTD_isError()).
 */
ZSTDLIB_API size_t ZSTD_compress2( ZSTD_CCtx* cctx,
                                   void* dst, size_t dstCapacity,
                             const void* src, size_t srcSize);


/***********************************************
*  Advanced decompression API (Requires v1.4.0+)
************************************************/

/* The advanced API pushes parameters one by one into an existing DCtx context.
 * Parameters are sticky, and remain valid for all following frames
 * using the same DCtx context.
 * It's possible to reset parameters to default values using ZSTD_DCtx_reset().
 * Note : This API is compatible with existing ZSTD_decompressDCtx() and ZSTD_decompressStream().
 *        Therefore, no new decompression function is necessary.
 */

typedef enum {

    ZSTD_d_windowLogMax=100, /* Select a size limit (in power of 2) beyond which
                              * the streaming API will refuse to allocate memory buffer
                              * in order to protect the host from unreasonable memory requirements.
                              * This parameter is only useful in streaming mode, since no internal buffer is allocated in single-pass mode.
                              * By default, a decompression context accepts window sizes <= (1 << ZSTD_WINDOWLOG_LIMIT_DEFAULT).
                              * Special: value 0 means "use default maximum windowLog". */

    /* note : additional experimental parameters are also available
     * within the experimental section of the API.
     * At the time of this writing, they include :
     * ZSTD_d_format
     * ZSTD_d_stableOutBuffer
     * ZSTD_d_forceIgnoreChecksum
     * ZSTD_d_refMultipleDDicts
     * ZSTD_d_disableHuffmanAssembly
     * ZSTD_d_maxBlockSize
     * Because they are not stable, it's necessary to define ZSTD_STATIC_LINKING_ONLY to access them.
     * note : never ever use experimentalParam? names directly
     */
     ZSTD_d_experimentalParam1=1000,
     ZSTD_d_experimentalParam2=1001,
     ZSTD_d_experimentalParam3=1002,
     ZSTD_d_experimentalParam4=1003,
     ZSTD_d_experimentalParam5=1004,
     ZSTD_d_experimentalParam6=1005

} ZSTD_dParameter;

/*! ZSTD_dParam_getBounds() :
 *  All parameters must belong to an interval with lower and upper bounds,
 *  otherwise they will either trigger an error or be automatically clamped.
 * @return : a structure, ZSTD_bounds, which contains
 *         - an error status field, which must be tested using ZSTD_isError()
 *         - both lower and upper bounds, inclusive
 */
ZSTDLIB_API ZSTD_bounds ZSTD_dParam_getBounds(ZSTD_dParameter dParam);

/*! ZSTD_DCtx_setParameter() :
 *  Set one compression parameter, selected by enum ZSTD_dParameter.
 *  All parameters have valid bounds. Bounds can be queried using ZSTD_dParam_getBounds().
 *  Providing a value beyond bound will either clamp it, or trigger an error (depending on parameter).
 *  Setting a parameter is only possible during frame initialization (before starting decompression).
 * @return : 0, or an error code (which can be tested using ZSTD_isError()).
 */
ZSTDLIB_API size_t ZSTD_DCtx_setParameter(ZSTD_DCtx* dctx, ZSTD_dParameter param, int value);

/*! ZSTD_DCtx_reset() :
 *  Return a DCtx to clean state.
 *  Session and parameters can be reset jointly or separately.
 *  Parameters can only be reset when no active frame is being decompressed.
 * @return : 0, or an error code, which can be tested with ZSTD_isError()
 */
ZSTDLIB_API size_t ZSTD_DCtx_reset(ZSTD_DCtx* dctx, ZSTD_ResetDirective reset);


/****************************
*  Streaming
****************************/

typedef struct ZSTD_inBuffer_s {
  const void* src;    /**< start of input buffer */
  size_t size;        /**< size of input buffer */
  size_t pos;         /**< position where reading stopped. Will be updated. Necessarily 0 <= pos <= size */
} ZSTD_inBuffer;

typedef struct ZSTD_outBuffer_s {
  void*  dst;         /**< start of output buffer */
  size_t size;        /**< size of output buffer */
  size_t pos;         /**< position where writing stopped. Will be updated. Necessarily 0 <= pos <= size */
} ZSTD_outBuffer;



/*-***********************************************************************
*  Streaming compression - HowTo
*
*  A ZSTD_CStream object is required to track streaming operation.
*  Use ZSTD_createCStream() and ZSTD_freeCStream() to create/release resources.
*  ZSTD_CStream objects can be reused multiple times on consecutive compression operations.
*  It is recommended to reuse ZSTD_CStream since it will play nicer with system's memory, by re-using already allocated memory.
*
*  For parallel execution, use one separate ZSTD_CStream per thread.
*
*  note : since v1.3.0, ZSTD_CStream and ZSTD_CCtx are the same thing.
*
*  Parameters are sticky : when starting a new compression on the same context,
*  it will reuse the same sticky parameters as previous compression session.
*  When in doubt, it's recommended to fully initialize the context before usage.
*  Use ZSTD_CCtx_reset() to reset the context and ZSTD_CCtx_setParameter(),
*  ZSTD_CCtx_setPledgedSrcSize(), or ZSTD_CCtx_loadDictionary() and friends to
*  set more specific parameters, the pledged source size, or load a dictionary.
*
*  Use ZSTD_compressStream2() with ZSTD_e_continue as many times as necessary to
*  consume input stream. The function will automatically update both `pos`
*  fields within `input` and `output`.
*  Note that the function may not consume the entire input, for example, because
*  the output buffer is already full, in which case `input.pos < input.size`.
*  The caller must check if input has been entirely consumed.
*  If not, the caller must make some room to receive more compressed data,
*  and then present again remaining input data.
*  note: ZSTD_e_continue is guaranteed to make some forward progress when called,
*        but doesn't guarantee maximal forward progress. This is especially relevant
*        when compressing with multiple threads. The call won't block if it can
*        consume some input, but if it can't it will wait for some, but not all,
*        output to be flushed.
* @return : provides a minimum amount of data remaining to be flushed from internal buffers
*           or an error code, which can be tested using ZSTD_isError().
*
*  At any moment, it's possible to flush whatever data might remain stuck within internal buffer,
*  using ZSTD_compressStream2() with ZSTD_e_flush. `output->pos` will be updated.
*  Note that, if `output->size` is too small, a single invocation with ZSTD_e_flush might not be enough (return code > 0).
*  In which case, make some room to receive more compressed data, and call again ZSTD_compressStream2() with ZSTD_e_flush.
*  You must continue calling ZSTD_compressStream2() with ZSTD_e_flush until it returns 0, at which point you can change the
*  operation.
*  note: ZSTD_e_flush will flush as much output as possible, meaning when compressing with multiple threads, it will
*        block until the flush is complete or the output buffer is full.
*  @return : 0 if internal buffers are entirely flushed,
*            >0 if some data still present within internal buffer (the value is minimal estimation of remaining size),
*            or an error code, which can be tested using ZSTD_isError().
*
*  Calling ZSTD_compressStream2() with ZSTD_e_end instructs to finish a frame.
*  It will perform a flush and write frame epilogue.
*  The epilogue is required for decoders to consider a frame completed.
*  flush operation is the same, and follows same rules as calling ZSTD_compressStream2() with ZSTD_e_flush.
*  You must continue calling ZSTD_compressStream2() with ZSTD_e_end until it returns 0, at which point you are free to
*  start a new frame.
*  note: ZSTD_e_end will flush as much output as possible, meaning when compressing with multiple threads, it will
*        block until the flush is complete or the output buffer is full.
*  @return : 0 if frame fully completed and fully flushed,
*            >0 if some data still present within internal buffer (the value is minimal estimation of remaining size),
*            or an error code, which can be tested using ZSTD_isError().
*
* *******************************************************************/

typedef ZSTD_CCtx ZSTD_CStream;  /**< CCtx and CStream are now effectively same object (>= v1.3.0) */
                                 /* Continue to distinguish them for compatibility with older versions <= v1.2.0 */
/*===== ZSTD_CStream management functions =====*/
ZSTDLIB_API ZSTD_CStream* ZSTD_createCStream(void);
ZSTDLIB_API size_t ZSTD_freeCStream(ZSTD_CStream* zcs);  /* accept NULL pointer */

/*===== Streaming compression functions =====*/
typedef enum {
    ZSTD_e_continue=0, /* collect more data, encoder decides when to output compressed result, for optimal compression ratio */
    ZSTD_e_flush=1,    /* flush any data provided so far,
                        * it creates (at least) one new block, that can be decoded immediately on reception;
                        * frame will continue: any future data can still reference previously compressed data, improving compression.
                        * note : multithreaded compression will block to flush as much output as possible. */
    ZSTD_e_end=2       /* flush any remaining data _and_ close current frame.
                        * note that frame is only closed after compressed data is fully flushed (return value == 0).
                        * After that point, any additional data starts a new frame.
                        * note : each frame is independent (does not reference any content from previous frame).
                        : note : multithreaded compression will block to flush as much output as possible. */
} ZSTD_EndDirective;

/*! ZSTD_compressStream2() : Requires v1.4.0+
 *  Behaves about the same as ZSTD_compressStream, with additional control on end directive.
 *  - Compression parameters are pushed into CCtx before starting compression, using ZSTD_CCtx_set*()
 *  - Compression parameters cannot be changed once compression is started (save a list of exceptions in multi-threading mode)
 *  - output->pos must be <= dstCapacity, input->pos must be <= srcSize
 *  - output->pos and input->pos will be updated. They are guaranteed to remain below their respective limit.
 *  - endOp must be a valid directive
 *  - When nbWorkers==0 (default), function is blocking : it completes its job before returning to caller.
 *  - When nbWorkers>=1, function is non-blocking : it copies a portion of input, distributes jobs to internal worker threads, flush to output whatever is available,
 *                                                  and then immediately returns, just indicating that there is some data remaining to be flushed.
 *                                                  The function nonetheless guarantees forward progress : it will return only after it reads or write at least 1+ byte.
 *  - Exception : if the first call requests a ZSTD_e_end directive and provides enough dstCapacity, the function delegates to ZSTD_compress2() which is always blocking.
 *  - @return provides a minimum amount of data remaining to be flushed from internal buffers
 *            or an error code, which can be tested using ZSTD_isError().
 *            if @return != 0, flush is not fully completed, there is still some data left within internal buffers.
 *            This is useful for ZSTD_e_flush, since in this case more flushes are necessary to empty all buffers.
 *            For ZSTD_e_end, @return == 0 when internal buffers are fully flushed and frame is completed.
 *  - after a ZSTD_e_end directive, if internal buffer is not fully flushed (@return != 0),
 *            only ZSTD_e_end or ZSTD_e_flush operations are allowed.
 *            Before starting a new compression job, or changing compression parameters,
 *            it is required to fully flush internal buffers.
 *  - note: if an operation ends with an error, it may leave @cctx in an undefined state.
 *          Therefore, it's UB to invoke ZSTD_compressStream2() of ZSTD_compressStream() on such a state.
 *          In order to be re-employed after an error, a state must be reset,
 *          which can be done explicitly (ZSTD_CCtx_reset()),
 *          or is sometimes implied by methods starting a new compression job (ZSTD_initCStream(), ZSTD_compressCCtx())
 */
ZSTDLIB_API size_t ZSTD_compressStream2( ZSTD_CCtx* cctx,
                                         ZSTD_outBuffer* output,
                                         ZSTD_inBuffer* input,
                                         ZSTD_EndDirective endOp);


/* These buffer sizes are softly recommended.
 * They are not required : ZSTD_compressStream*() happily accepts any buffer size, for both input and output.
 * Respecting the recommended size just makes it a bit easier for ZSTD_compressStream*(),
 * reducing the amount of memory shuffling and buffering, resulting in minor performance savings.
 *
 * However, note that these recommendations are from the perspective of a C caller program.
 * If the streaming interface is invoked from some other language,
 * especially managed ones such as Java or Go, through a foreign function interface such as jni or cgo,
 * a major performance rule is to reduce crossing such interface to an absolute minimum.
 * It's not rare that performance ends being spent more into the interface, rather than compression itself.
 * In which cases, prefer using large buffers, as large as practical,
 * for both input and output, to reduce the nb of roundtrips.
 */
ZSTDLIB_API size_t ZSTD_CStreamInSize(void);    /**< recommended size for input buffer */
ZSTDLIB_API size_t ZSTD_CStreamOutSize(void);   /**< recommended size for output buffer. Guarantee to successfully flush at least one complete compressed block. */


/* *****************************************************************************
 * This following is a legacy streaming API, available since v1.0+ .
 * It can be replaced by ZSTD_CCtx_reset() and ZSTD_compressStream2().
 * It is redundant, but remains fully supported.
 ******************************************************************************/

/*!
 * Equivalent to:
 *
 *     ZSTD_CCtx_reset(zcs, ZSTD_reset_session_only);
 *     ZSTD_CCtx_refCDict(zcs, NULL); // clear the dictionary (if any)
 *     ZSTD_CCtx_setParameter(zcs, ZSTD_c_compressionLevel, compressionLevel);
 *
 * Note that ZSTD_initCStream() clears any previously set dictionary. Use the new API
 * to compress with a dictionary.
 */
ZSTDLIB_API size_t ZSTD_initCStream(ZSTD_CStream* zcs, int compressionLevel);
/*!
 * Alternative for ZSTD_compressStream2(zcs, output, input, ZSTD_e_continue).
 * NOTE: The return value is different. ZSTD_compressStream() returns a hint for
 * the next read size (if non-zero and not an error). ZSTD_compressStream2()
 * returns the minimum nb of bytes left to flush (if non-zero and not an error).
 */
ZSTDLIB_API size_t ZSTD_compressStream(ZSTD_CStream* zcs, ZSTD_outBuffer* output, ZSTD_inBuffer* input);
/*! Equivalent to ZSTD_compressStream2(zcs, output, &emptyInput, ZSTD_e_flush). */
ZSTDLIB_API size_t ZSTD_flushStream(ZSTD_CStream* zcs, ZSTD_outBuffer* output);
/*! Equivalent to ZSTD_compressStream2(zcs, output, &emptyInput, ZSTD_e_end). */
ZSTDLIB_API size_t ZSTD_endStream(ZSTD_CStream* zcs, ZSTD_outBuffer* output);


/*-***************************************************************************
*  Streaming decompression - HowTo
*
*  A ZSTD_DStream object is required to track streaming operations.
*  Use ZSTD_createDStream() and ZSTD_freeDStream() to create/release resources.
*  ZSTD_DStream objects can be re-employed multiple times.
*
*  Use ZSTD_initDStream() to start a new decompression operation.
* @return : recommended first input size
*  Alternatively, use advanced API to set specific properties.
*
*  Use ZSTD_decompressStream() repetitively to consume your input.
*  The function will update both `pos` fields.
*  If `input.pos < input.size`, some input has not been consumed.
*  It's up to the caller to present again remaining data.
*
*  The function tries to flush all data decoded immediately, respecting output buffer size.
*  If `output.pos < output.size`, decoder has flushed everything it could.
*
*  However, when `output.pos == output.size`, it's more difficult to know.
*  If @return > 0, the frame is not complete, meaning
*  either there is still some data left to flush within internal buffers,
*  or there is more input to read to complete the frame (or both).
*  In which case, call ZSTD_decompressStream() again to flush whatever remains in the buffer.
*  Note : with no additional input provided, amount of data flushed is necessarily <= ZSTD_BLOCKSIZE_MAX.
* @return : 0 when a frame is completely decoded and fully flushed,
*        or an error code, which can be tested using ZSTD_isError(),
*        or any other value > 0, which means there is still some decoding or flushing to do to complete current frame :
*                                the return value is a suggested next input size (just a hint for better latency)
*                                that will never request more than the remaining content of the compressed frame.
* *******************************************************************************/

typedef ZSTD_DCtx ZSTD_DStream;  /**< DCtx and DStream are now effectively same object (>= v1.3.0) */
                                 /* For compatibility with versions <= v1.2.0, prefer differentiating them. */
/*===== ZSTD_DStream management functions =====*/
ZSTDLIB_API ZSTD_DStream* ZSTD_createDStream(void);
ZSTDLIB_API size_t ZSTD_freeDStream(ZSTD_DStream* zds);  /* accept NULL pointer */

/*===== Streaming decompression functions =====*/

/*! ZSTD_initDStream() :
 * Initialize/reset DStream state for new decompression operation.
 * Call before new decompression operation using same DStream.
 *
 * Note : This function is redundant with the advanced API and equivalent to:
 *     ZSTD_DCtx_reset(zds, ZSTD_reset_session_only);
 *     ZSTD_DCtx_refDDict(zds, NULL);
 */
ZSTDLIB_API size_t ZSTD_initDStream(ZSTD_DStream* zds);

/*! ZSTD_decompressStream() :
 * Streaming decompression function.
 * Call repetitively to consume full input updating it as necessary.
 * Function will update both input and output `pos` fields exposing current state via these fields:
 * - `input.pos < input.size`, some input remaining and caller should provide remaining input
 *   on the next call.
 * - `output.pos < output.size`, decoder flushed internal output buffer.
 * - `output.pos == output.size`, unflushed data potentially present in the internal buffers,
 *   check ZSTD_decompressStream() @return value,
 *   if > 0, invoke it again to flush remaining data to output.
 * Note : with no additional input, amount of data flushed <= ZSTD_BLOCKSIZE_MAX.
 *
 * @return : 0 when a frame is completely decoded and fully flushed,
 *           or an error code, which can be tested using ZSTD_isError(),
 *           or any other value > 0, which means there is some decoding or flushing to do to complete current frame.
 *
 * Note: when an operation returns with an error code, the @zds state may be left in undefined state.
 *       It's UB to invoke `ZSTD_decompressStream()` on such a state.
 *       In order to re-use such a state, it must be first reset,
 *       which can be done explicitly (`ZSTD_DCtx_reset()`),
 *       or is implied for operations starting some new decompression job (`ZSTD_initDStream`, `ZSTD_decompressDCtx()`, `ZSTD_decompress_usingDict()`)
 */
ZSTDLIB_API size_t ZSTD_decompressStream(ZSTD_DStream* zds, ZSTD_outBuffer* output, ZSTD_inBuffer* input);

ZSTDLIB_API size_t ZSTD_DStreamInSize(void);    /*!< recommended size for input buffer */
ZSTDLIB_API size_t ZSTD_DStreamOutSize(void);   /*!< recommended size for output buffer. Guarantee to successfully flush at least one complete block in all circumstances. */


/**************************
*  Simple dictionary API
***************************/
/*! ZSTD_compress_usingDict() :
 *  Compression at an explicit compression level using a Dictionary.
 *  A dictionary can be any arbitrary data segment (also called a prefix),
 *  or a buffer with specified information (see zdict.h).
 *  Note : This function loads the dictionary, resulting in significant startup delay.
 *         It's intended for a dictionary used only once.
 *  Note 2 : When `dict == NULL || dictSize < 8` no dictionary is used. */
ZSTDLIB_API size_t ZSTD_compress_usingDict(ZSTD_CCtx* ctx,
                                           void* dst, size_t dstCapacity,
                                     const void* src, size_t srcSize,
                                     const void* dict,size_t dictSize,
                                           int compressionLevel);

/*! ZSTD_decompress_usingDict() :
 *  Decompression using a known Dictionary.
 *  Dictionary must be identical to the one used during compression.
 *  Note : This function loads the dictionary, resulting in significant startup delay.
 *         It's intended for a dictionary used only once.
 *  Note : When `dict == NULL || dictSize < 8` no dictionary is used. */
ZSTDLIB_API size_t ZSTD_decompress_usingDict(ZSTD_DCtx* dctx,
                                             void* dst, size_t dstCapacity,
                                       const void* src, size_t srcSize,
                                       const void* dict,size_t dictSize);


/***********************************
 *  Bulk processing dictionary API
 **********************************/
typedef struct ZSTD_CDict_s ZSTD_CDict;

/*! ZSTD_createCDict() :
 *  When compressing multiple messages or blocks using the same dictionary,
 *  it's recommended to digest the dictionary only once, since it's a costly operation.
 *  ZSTD_createCDict() will create a state from digesting a dictionary.
 *  The resulting state can be used for future compression operations with very limited startup cost.
 *  ZSTD_CDict can be created once and shared by multiple threads concurrently, since its usage is read-only.
 * @dictBuffer can be released after ZSTD_CDict creation, because its content is copied within CDict.
 *  Note 1 : Consider experimental function `ZSTD_createCDict_byReference()` if you prefer to not duplicate @dictBuffer content.
 *  Note 2 : A ZSTD_CDict can be created from an empty @dictBuffer,
 *      in which case the only thing that it transports is the @compressionLevel.
 *      This can be useful in a pipeline featuring ZSTD_compress_usingCDict() exclusively,
 *      expecting a ZSTD_CDict parameter with any data, including those without a known dictionary. */
ZSTDLIB_API ZSTD_CDict* ZSTD_createCDict(const void* dictBuffer, size_t dictSize,
                                         int compressionLevel);

/*! ZSTD_freeCDict() :
 *  Function frees memory allocated by ZSTD_createCDict().
 *  If a NULL pointer is passed, no operation is performed. */
ZSTDLIB_API size_t      ZSTD_freeCDict(ZSTD_CDict* CDict);

/*! ZSTD_compress_usingCDict() :
 *  Compression using a digested Dictionary.
 *  Recommended when same dictionary is used multiple times.
 *  Note : compression level is _decided at dictionary creation time_,
 *     and frame parameters are hardcoded (dictID=yes, contentSize=yes, checksum=no) */
ZSTDLIB_API size_t ZSTD_compress_usingCDict(ZSTD_CCtx* cctx,
                                            void* dst, size_t dstCapacity,
                                      const void* src, size_t srcSize,
                                      const ZSTD_CDict* cdict);


typedef struct ZSTD_DDict_s ZSTD_DDict;

/*! ZSTD_createDDict() :
 *  Create a digested dictionary, ready to start decompression operation without startup delay.
 *  dictBuffer can be released after DDict creation, as its content is copied inside DDict. */
ZSTDLIB_API ZSTD_DDict* ZSTD_createDDict(const void* dictBuffer, size_t dictSize);

/*! ZSTD_freeDDict() :
 *  Function frees memory allocated with ZSTD_createDDict()
 *  If a NULL pointer is passed, no operation is performed. */
ZSTDLIB_API size_t      ZSTD_freeDDict(ZSTD_DDict* ddict);

/*! ZSTD_decompress_usingDDict() :
 *  Decompression using a digested Dictionary.
 *  Recommended when same dictionary is used multiple times. */
ZSTDLIB_API size_t ZSTD_decompress_usingDDict(ZSTD_DCtx* dctx,
                                              void* dst, size_t dstCapacity,
                                        const void* src, size_t srcSize,
                                        const ZSTD_DDict* ddict);


/********************************
 *  Dictionary helper functions
 *******************************/

/*! ZSTD_getDictID_fromDict() : Requires v1.4.0+
 *  Provides the dictID stored within dictionary.
 *  if @return == 0, the dictionary is not conformant with Zstandard specification.
 *  It can still be loaded, but as a content-only dictionary. */
ZSTDLIB_API unsigned ZSTD_getDictID_fromDict(const void* dict, size_t dictSize);

/*! ZSTD_getDictID_fromCDict() : Requires v1.5.0+
 *  Provides the dictID of the dictionary loaded into `cdict`.
 *  If @return == 0, the dictionary is not conformant to Zstandard specification, or empty.
 *  Non-conformant dictionaries can still be loaded, but as content-only dictionaries. */
ZSTDLIB_API unsigned ZSTD_getDictID_fromCDict(const ZSTD_CDict* cdict);

/*! ZSTD_getDictID_fromDDict() : Requires v1.4.0+
 *  Provides the dictID of the dictionary loaded into `ddict`.
 *  If @return == 0, the dictionary is not conformant to Zstandard specification, or empty.
 *  Non-conformant dictionaries can still be loaded, but as content-only dictionaries. */
ZSTDLIB_API unsigned ZSTD_getDictID_fromDDict(const ZSTD_DDict* ddict);

/*! ZSTD_getDictID_fromFrame() : Requires v1.4.0+
 *  Provides the dictID required to decompressed the frame stored within `src`.
 *  If @return == 0, the dictID could not be decoded.
 *  This could for one of the following reasons :
 *  - The frame does not require a dictionary to be decoded (most common case).
 *  - The frame was built with dictID intentionally removed. Whatever dictionary is necessary is a hidden piece of information.
 *    Note : this use case also happens when using a non-conformant dictionary.
 *  - `srcSize` is too small, and as a result, the frame header could not be decoded (only possible if `srcSize < ZSTD_FRAMEHEADERSIZE_MAX`).
 *  - This is not a Zstandard frame.
 *  When identifying the exact failure cause, it's possible to use ZSTD_getFrameHeader(), which will provide a more precise error code. */
ZSTDLIB_API unsigned ZSTD_getDictID_fromFrame(const void* src, size_t srcSize);


/*******************************************************************************
 * Advanced dictionary and prefix API (Requires v1.4.0+)
 *
 * This API allows dictionaries to be used with ZSTD_compress2(),
 * ZSTD_compressStream2(), and ZSTD_decompressDCtx().
 * Dictionaries are sticky, they remain valid when same context is reused,
 * they only reset when the context is reset
 * with ZSTD_reset_parameters or ZSTD_reset_session_and_parameters.
 * In contrast, Prefixes are single-use.
 ******************************************************************************/


/*! ZSTD_CCtx_loadDictionary() : Requires v1.4.0+
 *  Create an internal CDict from `dict` buffer.
 *  Decompression will have to use same dictionary.
 * @result : 0, or an error code (which can be tested with ZSTD_isError()).
 *  Special: Loading a NULL (or 0-size) dictionary invalidates previous dictionary,
 *           meaning "return to no-dictionary mode".
 *  Note 1 : Dictionary is sticky, it will be used for all future compressed frames,
 *           until parameters are reset, a new dictionary is loaded, or the dictionary
 *           is explicitly invalidated by loading a NULL dictionary.
 *  Note 2 : Loading a dictionary involves building tables.
 *           It's also a CPU consuming operation, with non-negligible impact on latency.
 *           Tables are dependent on compression parameters, and for this reason,
 *           compression parameters can no longer be changed after loading a dictionary.
 *  Note 3 :`dict` content will be copied internally.
 *           Use experimental ZSTD_CCtx_loadDictionary_byReference() to reference content instead.
 *           In such a case, dictionary buffer must outlive its users.
 *  Note 4 : Use ZSTD_CCtx_loadDictionary_advanced()
 *           to precisely select how dictionary content must be interpreted.
 *  Note 5 : This method does not benefit from LDM (long distance mode).
 *           If you want to employ LDM on some large dictionary content,
 *           prefer employing ZSTD_CCtx_refPrefix() described below.
 */
ZSTDLIB_API size_t ZSTD_CCtx_loadDictionary(ZSTD_CCtx* cctx, const void* dict, size_t dictSize);

/*! ZSTD_CCtx_refCDict() : Requires v1.4.0+
 *  Reference a prepared dictionary, to be used for all future compressed frames.
 *  Note that compression parameters are enforced from within CDict,
 *  and supersede any compression parameter previously set within CCtx.
 *  The parameters ignored are labelled as "superseded-by-cdict" in the ZSTD_cParameter enum docs.
 *  The ignored parameters will be used again if the CCtx is returned to no-dictionary mode.
 *  The dictionary will remain valid for future compressed frames using same CCtx.
 * @result : 0, or an error code (which can be tested with ZSTD_isError()).
 *  Special : Referencing a NULL CDict means "return to no-dictionary mode".
 *  Note 1 : Currently, only one dictionary can be managed.
 *           Referencing a new dictionary effectively "discards" any previous one.
 *  Note 2 : CDict is just referenced, its lifetime must outlive its usage within CCtx. */
ZSTDLIB_API size_t ZSTD_CCtx_refCDict(ZSTD_CCtx* cctx, const ZSTD_CDict* cdict);

/*! ZSTD_CCtx_refPrefix() : Requires v1.4.0+
 *  Reference a prefix (single-usage dictionary) for next compressed frame.
 *  A prefix is **only used once**. Tables are discarded at end of frame (ZSTD_e_end).
 *  Decompression will need same prefix to properly regenerate data.
 *  Compressing with a prefix is similar in outcome as performing a diff and compressing it,
 *  but performs much faster, especially during decompression (compression speed is tunable with compression level).
 *  This method is compatible with LDM (long distance mode).
 * @result : 0, or an error code (which can be tested with ZSTD_isError()).
 *  Special: Adding any prefix (including NULL) invalidates any previous prefix or dictionary
 *  Note 1 : Prefix buffer is referenced. It **must** outlive compression.
 *           Its content must remain unmodified during compression.
 *  Note 2 : If the intention is to diff some large src data blob with some prior version of itself,
 *           ensure that the window size is large enough to contain the entire source.
 *           See ZSTD_c_windowLog.
 *  Note 3 : Referencing a prefix involves building tables, which are dependent on compression parameters.
 *           It's a CPU consuming operation, with non-negligible impact on latency.
 *           If there is a need to use the same prefix multiple times, consider loadDictionary instead.
 *  Note 4 : By default, the prefix is interpreted as raw content (ZSTD_dct_rawContent).
 *           Use experimental ZSTD_CCtx_refPrefix_advanced() to alter dictionary interpretation. */
ZSTDLIB_API size_t ZSTD_CCtx_refPrefix(ZSTD_CCtx* cctx,
                                 const void* prefix, size_t prefixSize);

/*! ZSTD_DCtx_loadDictionary() : Requires v1.4.0+
 *  Create an internal DDict from dict buffer, to be used to decompress all future frames.
 *  The dictionary remains valid for all future frames, until explicitly invalidated, or
 *  a new dictionary is loaded.
 * @result : 0, or an error code (which can be tested with ZSTD_isError()).
 *  Special : Adding a NULL (or 0-size) dictionary invalidates any previous dictionary,
 *            meaning "return to no-dictionary mode".
 *  Note 1 : Loading a dictionary involves building tables,
 *           which has a non-negligible impact on CPU usage and latency.
 *           It's recommended to "load once, use many times", to amortize the cost
 *  Note 2 :`dict` content will be copied internally, so `dict` can be released after loading.
 *           Use ZSTD_DCtx_loadDictionary_byReference() to reference dictionary content instead.
 *  Note 3 : Use ZSTD_DCtx_loadDictionary_advanced() to take control of
 *           how dictionary content is loaded and interpreted.
 */
ZSTDLIB_API size_t ZSTD_DCtx_loadDictionary(ZSTD_DCtx* dctx, const void* dict, size_t dictSize);

/*! ZSTD_DCtx_refDDict() : Requires v1.4.0+
 *  Reference a prepared dictionary, to be used to decompress next frames.
 *  The dictionary remains active for decompression of future frames using same DCtx.
 *
 *  If called with ZSTD_d_refMultipleDDicts enabled, repeated calls of this function
 *  will store the DDict references in a table, and the DDict used for decompression
 *  will be determined at decompression time, as per the dict ID in the frame.
 *  The memory for the table is allocated on the first call to refDDict, and can be
 *  freed with ZSTD_freeDCtx().
 *
 *  If called with ZSTD_d_refMultipleDDicts disabled (the default), only one dictionary
 *  will be managed, and referencing a dictionary effectively "discards" any previous one.
 *
 * @result : 0, or an error code (which can be tested with ZSTD_isError()).
 *  Special: referencing a NULL DDict means "return to no-dictionary mode".
 *  Note 2 : DDict is just referenced, its lifetime must outlive its usage from DCtx.
 */
ZSTDLIB_API size_t ZSTD_DCtx_refDDict(ZSTD_DCtx* dctx, const ZSTD_DDict* ddict);

/*! ZSTD_DCtx_refPrefix() : Requires v1.4.0+
 *  Reference a prefix (single-usage dictionary) to decompress next frame.
 *  This is the reverse operation of ZSTD_CCtx_refPrefix(),
 *  and must use the same prefix as the one used during compression.
 *  Prefix is **only used once**. Reference is discarded at end of frame.
 *  End of frame is reached when ZSTD_decompressStream() returns 0.
 * @result : 0, or an error code (which can be tested with ZSTD_isError()).
 *  Note 1 : Adding any prefix (including NULL) invalidates any previously set prefix or dictionary
 *  Note 2 : Prefix buffer is referenced. It **must** outlive decompression.
 *           Prefix buffer must remain unmodified up to the end of frame,
 *           reached when ZSTD_decompressStream() returns 0.
 *  Note 3 : By default, the prefix is treated as raw content (ZSTD_dct_rawContent).
 *           Use ZSTD_CCtx_refPrefix_advanced() to alter dictMode (Experimental section)
 *  Note 4 : Referencing a raw content prefix has almost no cpu nor memory cost.
 *           A full dictionary is more costly, as it requires building tables.
 */
ZSTDLIB_API size_t ZSTD_DCtx_refPrefix(ZSTD_DCtx* dctx,
                                 const void* prefix, size_t prefixSize);

/* ===   Memory management   === */

/*! ZSTD_sizeof_*() : Requires v1.4.0+
 *  These functions give the _current_ memory usage of selected object.
 *  Note that object memory usage can evolve (increase or decrease) over time. */
ZSTDLIB_API size_t ZSTD_sizeof_CCtx(const ZSTD_CCtx* cctx);
ZSTDLIB_API size_t ZSTD_sizeof_DCtx(const ZSTD_DCtx* dctx);
ZSTDLIB_API size_t ZSTD_sizeof_CStream(const ZSTD_CStream* zcs);
ZSTDLIB_API size_t ZSTD_sizeof_DStream(const ZSTD_DStream* zds);
ZSTDLIB_API size_t ZSTD_sizeof_CDict(const ZSTD_CDict* cdict);
ZSTDLIB_API size_t ZSTD_sizeof_DDict(const ZSTD_DDict* ddict);

#if defined (__cplusplus)
}
#endif

#endif  /* ZSTD_H_235446 */


/* **************************************************************************************
 *   ADVANCED AND EXPERIMENTAL FUNCTIONS
 ****************************************************************************************
 * The definitions in the following section are considered experimental.
 * They are provided for advanced scenarios.
 * They should never be used with a dynamic library, as prototypes may change in the future.
 * Use them only in association with static linking.
 * ***************************************************************************************/

#if defined(ZSTD_STATIC_LINKING_ONLY) && !defined(ZSTD_H_ZSTD_STATIC_LINKING_ONLY)
#define ZSTD_H_ZSTD_STATIC_LINKING_ONLY

#if defined (__cplusplus)
extern "C" {
#endif

/* This can be overridden externally to hide static symbols. */
#ifndef ZSTDLIB_STATIC_API
#  if defined(ZSTD_DLL_EXPORT) && (ZSTD_DLL_EXPORT==1)
#    define ZSTDLIB_STATIC_API __declspec(dllexport) ZSTDLIB_VISIBLE
#  elif defined(ZSTD_DLL_IMPORT) && (ZSTD_DLL_IMPORT==1)
#    define ZSTDLIB_STATIC_API __declspec(dllimport) ZSTDLIB_VISIBLE
#  else
#    define ZSTDLIB_STATIC_API ZSTDLIB_VISIBLE
#  endif
#endif

/****************************************************************************************
 *   experimental API (static linking only)
 ****************************************************************************************
 * The following symbols and constants
 * are not planned to join "stable API" status in the near future.
 * They can still change in future versions.
 * Some of them are planned to remain in the static_only section indefinitely.
 * Some of them might be removed in the future (especially when redundant with existing stable functions)
 * ***************************************************************************************/

#define ZSTD_FRAMEHEADERSIZE_PREFIX(format) ((format) == ZSTD_f_zstd1 ? 5 : 1)   /* minimum input size required to query frame header size */
#define ZSTD_FRAMEHEADERSIZE_MIN(format)    ((format) == ZSTD_f_zstd1 ? 6 : 2)
#define ZSTD_FRAMEHEADERSIZE_MAX   18   /* can be useful for static allocation */
#define ZSTD_SKIPPABLEHEADERSIZE    8

/* compression parameter bounds */
#define ZSTD_WINDOWLOG_MAX_32    30
#define ZSTD_WINDOWLOG_MAX_64    31
#define ZSTD_WINDOWLOG_MAX     ((int)(sizeof(size_t) == 4 ? ZSTD_WINDOWLOG_MAX_32 : ZSTD_WINDOWLOG_MAX_64))
#define ZSTD_WINDOWLOG_MIN       10
#define ZSTD_HASHLOG_MAX       ((ZSTD_WINDOWLOG_MAX < 30) ? ZSTD_WINDOWLOG_MAX : 30)
#define ZSTD_HASHLOG_MIN          6
#define ZSTD_CHAINLOG_MAX_32     29
#define ZSTD_CHAINLOG_MAX_64     30
#define ZSTD_CHAINLOG_MAX      ((int)(sizeof(size_t) == 4 ? ZSTD_CHAINLOG_MAX_32 : ZSTD_CHAINLOG_MAX_64))
#define ZSTD_CHAINLOG_MIN        ZSTD_HASHLOG_MIN
#define ZSTD_SEARCHLOG_MAX      (ZSTD_WINDOWLOG_MAX-1)
#define ZSTD_SEARCHLOG_MIN        1
#define ZSTD_MINMATCH_MAX         7   /* only for ZSTD_fast, other strategies are limited to 6 */
#define ZSTD_MINMATCH_MIN         3   /* only for ZSTD_btopt+, faster strategies are limited to 4 */
#define ZSTD_TARGETLENGTH_MAX    ZSTD_BLOCKSIZE_MAX
#define ZSTD_TARGETLENGTH_MIN     0   /* note : comparing this constant to an unsigned results in a tautological test */
#define ZSTD_STRATEGY_MIN        ZSTD_fast
#define ZSTD_STRATEGY_MAX        ZSTD_btultra2
#define ZSTD_BLOCKSIZE_MAX_MIN (1 << 10) /* The minimum valid max blocksize. Maximum blocksizes smaller than this make compressBound() inaccurate. */


#define ZSTD_OVERLAPLOG_MIN       0
#define ZSTD_OVERLAPLOG_MAX       9

#define ZSTD_WINDOWLOG_LIMIT_DEFAULT 27   /* by default, the streaming decoder will refuse any frame
                                           * requiring larger than (1<<ZSTD_WINDOWLOG_LIMIT_DEFAULT) window size,
                                           * to preserve host's memory from unreasonable requirements.
                                           * This limit can be overridden using ZSTD_DCtx_setParameter(,ZSTD_d_windowLogMax,).
                                           * The limit does not apply for one-pass decoders (such as ZSTD_decompress()), since no additional memory is allocated */


/* LDM parameter bounds */
#define ZSTD_LDM_HASHLOG_MIN      ZSTD_HASHLOG_MIN
#define ZSTD_LDM_HASHLOG_MAX      ZSTD_HASHLOG_MAX
#define ZSTD_LDM_MINMATCH_MIN        4
#define ZSTD_LDM_MINMATCH_MAX     4096
#define ZSTD_LDM_BUCKETSIZELOG_MIN   1
#define ZSTD_LDM_BUCKETSIZELOG_MAX   8
#define ZSTD_LDM_HASHRATELOG_MIN     0
#define ZSTD_LDM_HASHRATELOG_MAX (ZSTD_WINDOWLOG_MAX - ZSTD_HASHLOG_MIN)

/* Advanced parameter bounds */
#define ZSTD_TARGETCBLOCKSIZE_MIN   1340 /* suitable to fit into an ethernet / wifi / 4G transport frame */
#define ZSTD_TARGETCBLOCKSIZE_MAX   ZSTD_BLOCKSIZE_MAX
#define ZSTD_SRCSIZEHINT_MIN        0
#define ZSTD_SRCSIZEHINT_MAX        INT_MAX


/* ---  Advanced types  --- */

typedef struct ZSTD_CCtx_params_s ZSTD_CCtx_params;

typedef struct {
    unsigned int offset;      /* The offset of the match. (NOT the same as the offset code)
                               * If offset == 0 and matchLength == 0, this sequence represents the last
                               * literals in the block of litLength size.
                               */

    unsigned int litLength;   /* Literal length of the sequence. */
    unsigned int matchLength; /* Match length of the sequence. */

                              /* Note: Users of this API may provide a sequence with matchLength == litLength == offset == 0.
                               * In this case, we will treat the sequence as a marker for a block boundary.
                               */

    unsigned int rep;         /* Represents which repeat offset is represented by the field 'offset'.
                               * Ranges from [0, 3].
                               *
                               * Repeat offsets are essentially previous offsets from previous sequences sorted in
                               * recency order. For more detail, see doc/zstd_compression_format.md
                               *
                               * If rep == 0, then 'offset' does not contain a repeat offset.
                               * If rep > 0:
                               *  If litLength != 0:
                               *      rep == 1 --> offset == repeat_offset_1
                               *      rep == 2 --> offset == repeat_offset_2
                               *      rep == 3 --> offset == repeat_offset_3
                               *  If litLength == 0:
                               *      rep == 1 --> offset == repeat_offset_2
                               *      rep == 2 --> offset == repeat_offset_3
                               *      rep == 3 --> offset == repeat_offset_1 - 1
                               *
                               * Note: This field is optional. ZSTD_generateSequences() will calculate the value of
                               * 'rep', but repeat offsets do not necessarily need to be calculated from an external
                               * sequence provider perspective. For example, ZSTD_compressSequences() does not
                               * use this 'rep' field at all (as of now).
                               */
} ZSTD_Sequence;

typedef struct {
    unsigned windowLog;       /**< largest match distance : larger == more compression, more memory needed during decompression */
    unsigned chainLog;        /**< fully searched segment : larger == more compression, slower, more memory (useless for fast) */
    unsigned hashLog;         /**< dispatch table : larger == faster, more memory */
    unsigned searchLog;       /**< nb of searches : larger == more compression, slower */
    unsigned minMatch;        /**< match length searched : larger == faster decompression, sometimes less compression */
    unsigned targetLength;    /**< acceptable match size for optimal parser (only) : larger == more compression, slower */
    ZSTD_strategy strategy;   /**< see ZSTD_strategy definition above */
} ZSTD_compressionParameters;

typedef struct {
    int contentSizeFlag; /**< 1: content size will be in frame header (when known) */
    int checksumFlag;    /**< 1: generate a 32-bits checksum using XXH64 algorithm at end of frame, for error detection */
    int noDictIDFlag;    /**< 1: no dictID will be saved into frame header (dictID is only useful for dictionary compression) */
} ZSTD_frameParameters;

typedef struct {
    ZSTD_compressionParameters cParams;
    ZSTD_frameParameters fParams;
} ZSTD_parameters;

typedef enum {
    ZSTD_dct_auto = 0,       /* dictionary is "full" when starting with ZSTD_MAGIC_DICTIONARY, otherwise it is "rawContent" */
    ZSTD_dct_rawContent = 1, /* ensures dictionary is always loaded as rawContent, even if it starts with ZSTD_MAGIC_DICTIONARY */
    ZSTD_dct_fullDict = 2    /* refuses to load a dictionary if it does not respect Zstandard's specification, starting with ZSTD_MAGIC_DICTIONARY */
} ZSTD_dictContentType_e;

typedef enum {
    ZSTD_dlm_byCopy = 0,  /**< Copy dictionary content internally */
    ZSTD_dlm_byRef = 1    /**< Reference dictionary content -- the dictionary buffer must outlive its users. */
} ZSTD_dictLoadMethod_e;

typedef enum {
    ZSTD_f_zstd1 = 0,           /* zstd frame format, specified in zstd_compression_format.md (default) */
    ZSTD_f_zstd1_magicless = 1  /* Variant of zstd frame format, without initial 4-bytes magic number.
                                 * Useful to save 4 bytes per generated frame.
                                 * Decoder cannot recognise automatically this format, requiring this instruction. */
} ZSTD_format_e;

typedef enum {
    /* Note: this enum controls ZSTD_d_forceIgnoreChecksum */
    ZSTD_d_validateChecksum = 0,
    ZSTD_d_ignoreChecksum = 1
} ZSTD_forceIgnoreChecksum_e;

typedef enum {
    /* Note: this enum controls ZSTD_d_refMultipleDDicts */
    ZSTD_rmd_refSingleDDict = 0,
    ZSTD_rmd_refMultipleDDicts = 1
} ZSTD_refMultipleDDicts_e;

typedef enum {
    /* Note: this enum and the behavior it controls are effectively internal
     * implementation details of the compressor. They are expected to continue
     * to evolve and should be considered only in the context of extremely
     * advanced performance tuning.
     *
     * Zstd currently supports the use of a CDict in three ways:
     *
     * - The contents of the CDict can be copied into the working context. This
     *   means that the compression can search both the dictionary and input
     *   while operating on a single set of internal tables. This makes
     *   the compression faster per-byte of input. However, the initial copy of
     *   the CDict's tables incurs a fixed cost at the beginning of the
     *   compression. For small compressions (< 8 KB), that copy can dominate
     *   the cost of the compression.
     *
     * - The CDict's tables can be used in-place. In this model, compression is
     *   slower per input byte, because the compressor has to search two sets of
     *   tables. However, this model incurs no start-up cost (as long as the
     *   working context's tables can be reused). For small inputs, this can be
     *   faster than copying the CDict's tables.
     *
     * - The CDict's tables are not used at all, and instead we use the working
     *   context alone to reload the dictionary and use params based on the source
     *   size. See ZSTD_compress_insertDictionary() and ZSTD_compress_usingDict().
     *   This method is effective when the dictionary sizes are very small relative
     *   to the input size, and the input size is fairly large to begin with.
     *
     * Zstd has a simple internal heuristic that selects which strategy to use
     * at the beginning of a compression. However, if experimentation shows that
     * Zstd is making poor choices, it is possible to override that choice with
     * this enum.
     */
    ZSTD_dictDefaultAttach = 0, /* Use the default heuristic. */
    ZSTD_dictForceAttach   = 1, /* Never copy the dictionary. */
    ZSTD_dictForceCopy     = 2, /* Always copy the dictionary. */
    ZSTD_dictForceLoad     = 3  /* Always reload the dictionary */
} ZSTD_dictAttachPref_e;

typedef enum {
  ZSTD_lcm_auto = 0,          /**< Automatically determine the compression mode based on the compression level.
                               *   Negative compression levels will be uncompressed, and positive compression
                               *   levels will be compressed. */
  ZSTD_lcm_huffman = 1,       /**< Always attempt Huffman compression. Uncompressed literals will still be
                               *   emitted if Huffman compression is not profitable. */
  ZSTD_lcm_uncompressed = 2   /**< Always emit uncompressed literals. */
} ZSTD_literalCompressionMode_e;

typedef enum {
  /* Note: This enum controls features which are conditionally beneficial.
   * Zstd can take a decision on whether or not to enable the feature (ZSTD_ps_auto),
   * but setting the switch to ZSTD_ps_enable or ZSTD_ps_disable force enable/disable the feature.
   */
  ZSTD_ps_auto = 0,         /* Let the library automatically determine whether the feature shall be enabled */
  ZSTD_ps_enable = 1,       /* Force-enable the feature */
  ZSTD_ps_disable = 2       /* Do not use the feature */
} ZSTD_ParamSwitch_e;
#define ZSTD_paramSwitch_e ZSTD_ParamSwitch_e  /* old name */

/***************************************
*  Frame header and size functions
***************************************/

/*! ZSTD_findDecompressedSize() :
 *  `src` should point to the start of a series of ZSTD encoded and/or skippable frames
 *  `srcSize` must be the _exact_ size of this series
 *       (i.e. there should be a frame boundary at `src + srcSize`)
 *  @return : - decompressed size of all data in all successive frames
 *            - if the decompressed size cannot be determined: ZSTD_CONTENTSIZE_UNKNOWN
 *            - if an error occurred: ZSTD_CONTENTSIZE_ERROR
 *
 *   note 1 : decompressed size is an optional field, that may not be present, especially in streaming mode.
 *            When `return==ZSTD_CONTENTSIZE_UNKNOWN`, data to decompress could be any size.
 *            In which case, it's necessary to use streaming mode to decompress data.
 *   note 2 : decompressed size is always present when compression is done with ZSTD_compress()
 *   note 3 : decompressed size can be very large (64-bits value),
 *            potentially larger than what local system can handle as a single memory segment.
 *            In which case, it's necessary to use streaming mode to decompress data.
 *   note 4 : If source is untrusted, decompressed size could be wrong or intentionally modified.
 *            Always ensure result fits within application's authorized limits.
 *            Each application can set its own limits.
 *   note 5 : ZSTD_findDecompressedSize handles multiple frames, and so it must traverse the input to
 *            read each contained frame header.  This is fast as most of the data is skipped,
 *            however it does mean that all frame data must be present and valid. */
ZSTDLIB_STATIC_API unsigned long long ZSTD_findDecompressedSize(const void* src, size_t srcSize);

/*! ZSTD_decompressBound() :
 *  `src` should point to the start of a series of ZSTD encoded and/or skippable frames
 *  `srcSize` must be the _exact_ size of this series
 *       (i.e. there should be a frame boundary at `src + srcSize`)
 *  @return : - upper-bound for the decompressed size of all data in all successive frames
 *            - if an error occurred: ZSTD_CONTENTSIZE_ERROR
 *
 *  note 1  : an error can occur if `src` contains an invalid or incorrectly formatted frame.
 *  note 2  : the upper-bound is exact when the decompressed size field is available in every ZSTD encoded frame of `src`.
 *            in this case, `ZSTD_findDecompressedSize` and `ZSTD_decompressBound` return the same value.
 *  note 3  : when the decompressed size field isn't available, the upper-bound for that frame is calculated by:
 *              upper-bound = # blocks * min(128 KB, Window_Size)
 */
ZSTDLIB_STATIC_API unsigned long long ZSTD_decompressBound(const void* src, size_t srcSize);

/*! ZSTD_frameHeaderSize() :
 *  srcSize must be large enough, aka >= ZSTD_FRAMEHEADERSIZE_PREFIX.
 * @return : size of the Frame Header,
 *           or an error code (if srcSize is too small) */
ZSTDLIB_STATIC_API size_t ZSTD_frameHeaderSize(const void* src, size_t srcSize);

typedef enum { ZSTD_frame, ZSTD_skippableFrame } ZSTD_FrameType_e;
#define ZSTD_frameType_e ZSTD_FrameType_e /* old name */
typedef struct {
    unsigned long long frameContentSize; /* if == ZSTD_CONTENTSIZE_UNKNOWN, it means this field is not available. 0 means "empty" */
    unsigned long long windowSize;       /* can be very large, up to <= frameContentSize */
    unsigned blockSizeMax;
    ZSTD_FrameType_e frameType;          /* if == ZSTD_skippableFrame, frameContentSize is the size of skippable content */
    unsigned headerSize;
    unsigned dictID;                     /* for ZSTD_skippableFrame, contains the skippable magic variant [0-15] */
    unsigned checksumFlag;
    unsigned _reserved1;
    unsigned _reserved2;
} ZSTD_FrameHeader;
#define ZSTD_frameHeader ZSTD_FrameHeader /* old name */

/*! ZSTD_getFrameHeader() :
 *  decode Frame Header into `zfhPtr`, or requires larger `srcSize`.
 * @return : 0 => header is complete, `zfhPtr` is correctly filled,
 *          >0 => `srcSize` is too small, @return value is the wanted `srcSize` amount, `zfhPtr` is not filled,
 *           or an error code, which can be tested using ZSTD_isError() */
ZSTDLIB_STATIC_API size_t ZSTD_getFrameHeader(ZSTD_FrameHeader* zfhPtr, const void* src, size_t srcSize);
/*! ZSTD_getFrameHeader_advanced() :
 *  same as ZSTD_getFrameHeader(),
 *  with added capability to select a format (like ZSTD_f_zstd1_magicless) */
ZSTDLIB_STATIC_API size_t ZSTD_getFrameHeader_advanced(ZSTD_FrameHeader* zfhPtr, const void* src, size_t srcSize, ZSTD_format_e format);

/*! ZSTD_decompressionMargin() :
 * Zstd supports in-place decompression, where the input and output buffers overlap.
 * In this case, the output buffer must be at least (Margin + Output_Size) bytes large,
 * and the input buffer must be at the end of the output buffer.
 *
 *  _______________________ Output Buffer ________________________
 * |                                                              |
 * |                                        ____ Input Buffer ____|
 * |                                       |                      |
 * v                                       v                      v
 * |---------------------------------------|-----------|----------|
 * ^                                                   ^          ^
 * |___________________ Output_Size ___________________|_ Margin _|
 *
 * NOTE: See also ZSTD_DECOMPRESSION_MARGIN().
 * NOTE: This applies only to single-pass decompression through ZSTD_decompress() or
 * ZSTD_decompressDCtx().
 * NOTE: This function supports multi-frame input.
 *
 * @param src The compressed frame(s)
 * @param srcSize The size of the compressed frame(s)
 * @returns The decompression margin or an error that can be checked with ZSTD_isError().
 */
ZSTDLIB_STATIC_API size_t ZSTD_decompressionMargin(const void* src, size_t srcSize);

/*! ZSTD_DECOMPRESS_MARGIN() :
 * Similar to ZSTD_decompressionMargin(), but instead of computing the margin from
 * the compressed frame, compute it from the original size and the blockSizeLog.
 * See ZSTD_decompressionMargin() for details.
 *
 * WARNING: This macro does not support multi-frame input, the input must be a single
 * zstd frame. If you need that support use the function, or implement it yourself.
 *
 * @param originalSize The original uncompressed size of the data.
 * @param blockSize    The block size == MIN(windowSize, ZSTD_BLOCKSIZE_MAX).
 *                     Unless you explicitly set the windowLog smaller than
 *                     ZSTD_BLOCKSIZELOG_MAX you can just use ZSTD_BLOCKSIZE_MAX.
 */
#define ZSTD_DECOMPRESSION_MARGIN(originalSize, blockSize) ((size_t)(                                              \
        ZSTD_FRAMEHEADERSIZE_MAX                                                              /* Frame header */ + \
        4                                                                                         /* checksum */ + \
        ((originalSize) == 0 ? 0 : 3 * (((originalSize) + (blockSize) - 1) / blockSize)) /* 3 bytes per block */ + \
        (blockSize)                                                                    /* One block of margin */   \
    ))

typedef enum {
  ZSTD_sf_noBlockDelimiters = 0,         /* ZSTD_Sequence[] has no block delimiters, just sequences */
  ZSTD_sf_explicitBlockDelimiters = 1    /* ZSTD_Sequence[] contains explicit block delimiters */
} ZSTD_SequenceFormat_e;
#define ZSTD_sequenceFormat_e ZSTD_SequenceFormat_e /* old name */

/*! ZSTD_sequenceBound() :
 * `srcSize` : size of the input buffer
 *  @return : upper-bound for the number of sequences that can be generated
 *            from a buffer of srcSize bytes
 *
 *  note : returns number of sequences - to get bytes, multiply by sizeof(ZSTD_Sequence).
 */
ZSTDLIB_STATIC_API size_t ZSTD_sequenceBound(size_t srcSize);

/*! ZSTD_generateSequences() :
 * WARNING: This function is meant for debugging and informational purposes ONLY!
 * Its implementation is flawed, and it will be deleted in a future version.
 * It is not guaranteed to succeed, as there are several cases where it will give
 * up and fail. You should NOT use this function in production code.
 *
 * This function is deprecated, and will be removed in a future version.
 *
 * Generate sequences using ZSTD_compress2(), given a source buffer.
 *
 * @param zc The compression context to be used for ZSTD_compress2(). Set any
 *           compression parameters you need on this context.
 * @param outSeqs The output sequences buffer of size @p outSeqsSize
 * @param outSeqsCapacity The size of the output sequences buffer.
 *                    ZSTD_sequenceBound(srcSize) is an upper bound on the number
 *                    of sequences that can be generated.
 * @param src The source buffer to generate sequences from of size @p srcSize.
 * @param srcSize The size of the source buffer.
 *
 * Each block will end with a dummy sequence
 * with offset == 0, matchLength == 0, and litLength == length of last literals.
 * litLength may be == 0, and if so, then the sequence of (of: 0 ml: 0 ll: 0)
 * simply acts as a block delimiter.
 *
 * @returns The number of sequences generated, necessarily less than
 *          ZSTD_sequenceBound(srcSize), or an error code that can be checked
 *          with ZSTD_isError().
 */
ZSTD_DEPRECATED("For debugging only, will be replaced by ZSTD_extractSequences()")
ZSTDLIB_STATIC_API size_t
ZSTD_generateSequences(ZSTD_CCtx* zc,
                       ZSTD_Sequence* outSeqs, size_t outSeqsCapacity,
                       const void* src, size_t srcSize);

/*! ZSTD_mergeBlockDelimiters() :
 * Given an array of ZSTD_Sequence, remove all sequences that represent block delimiters/last literals
 * by merging them into the literals of the next sequence.
 *
 * As such, the final generated result has no explicit representation of block boundaries,
 * and the final last literals segment is not represented in the sequences.
 *
 * The output of this function can be fed into ZSTD_compressSequences() with CCtx
 * setting of ZSTD_c_blockDelimiters as ZSTD_sf_noBlockDelimiters
 * @return : number of sequences left after merging
 */
ZSTDLIB_STATIC_API size_t ZSTD_mergeBlockDelimiters(ZSTD_Sequence* sequences, size_t seqsSize);

/*! ZSTD_compressSequences() :
 * Compress an array of ZSTD_Sequence, associated with @src buffer, into dst.
 * @src contains the entire input (not just the literals).
 * If @srcSize > sum(sequence.length), the remaining bytes are considered all literals
 * If a dictionary is included, then the cctx should reference the dict (see: ZSTD_CCtx_refCDict(), ZSTD_CCtx_loadDictionary(), etc.).
 * The entire source is compressed into a single frame.
 *
 * The compression behavior changes based on cctx params. In particular:
 *    If ZSTD_c_blockDelimiters == ZSTD_sf_noBlockDelimiters, the array of ZSTD_Sequence is expected to contain
 *    no block delimiters (defined in ZSTD_Sequence). Block boundaries are roughly determined based on
 *    the block size derived from the cctx, and sequences may be split. This is the default setting.
 *
 *    If ZSTD_c_blockDelimiters == ZSTD_sf_explicitBlockDelimiters, the array of ZSTD_Sequence is expected to contain
 *    valid block delimiters (defined in ZSTD_Sequence). Behavior is undefined if no block delimiters are provided.
 *
 *    When ZSTD_c_blockDelimiters == ZSTD_sf_explicitBlockDelimiters, it's possible to decide generating repcodes
 *    using the advanced parameter ZSTD_c_repcodeResolution. Repcodes will improve compression ratio, though the benefit
 *    can vary greatly depending on Sequences. On the other hand, repcode resolution is an expensive operation.
 *    By default, it's disabled at low (<10) compression levels, and enabled above the threshold (>=10).
 *    ZSTD_c_repcodeResolution makes it possible to directly manage this processing in either direction.
 *
 *    If ZSTD_c_validateSequences == 0, this function blindly accepts the Sequences provided. Invalid Sequences cause undefined
 *    behavior. If ZSTD_c_validateSequences == 1, then the function will detect invalid Sequences (see doc/zstd_compression_format.md for
 *    specifics regarding offset/matchlength requirements) and then bail out and return an error.
 *
 *    In addition to the two adjustable experimental params, there are other important cctx params.
 *    - ZSTD_c_minMatch MUST be set as less than or equal to the smallest match generated by the match finder. It has a minimum value of ZSTD_MINMATCH_MIN.
 *    - ZSTD_c_compressionLevel accordingly adjusts the strength of the entropy coder, as it would in typical compression.
 *    - ZSTD_c_windowLog affects offset validation: this function will return an error at higher debug levels if a provided offset
 *      is larger than what the spec allows for a given window log and dictionary (if present). See: doc/zstd_compression_format.md
 *
 * Note: Repcodes are, as of now, always re-calculated within this function, ZSTD_Sequence.rep is effectively unused.
 * Dev Note: Once ability to ingest repcodes become available, the explicit block delims mode must respect those repcodes exactly,
 *         and cannot emit an RLE block that disagrees with the repcode history.
 * @return : final compressed size, or a ZSTD error code.
 */
ZSTDLIB_STATIC_API size_t
ZSTD_compressSequences(ZSTD_CCtx* cctx,
                       void* dst, size_t dstCapacity,
                 const ZSTD_Sequence* inSeqs, size_t inSeqsSize,
                 const void* src, size_t srcSize);


/*! ZSTD_compressSequencesAndLiterals() :
 * This is a variant of ZSTD_compressSequences() which,
 * instead of receiving (src,srcSize) as input parameter, receives (literals,litSize),
 * aka all the literals, already extracted and laid out into a single continuous buffer.
 * This can be useful if the process generating the sequences also happens to generate the buffer of literals,
 * thus skipping an extraction + caching stage.
 * It's a speed optimization, useful when the right conditions are met,
 * but it also features the following limitations:
 * - Only supports explicit delimiter mode
 * - Currently does not support Sequences validation (so input Sequences are trusted)
 * - Not compatible with frame checksum, which must be disabled
 * - If any block is incompressible, will fail and return an error
 * - @litSize must be == sum of all @.litLength fields in @inSeqs. Any discrepancy will generate an error.
 * - @litBufCapacity is the size of the underlying buffer into which literals are written, starting at address @literals.
 *   @litBufCapacity must be at least 8 bytes larger than @litSize.
 * - @decompressedSize must be correct, and correspond to the sum of all Sequences. Any discrepancy will generate an error.
 * @return : final compressed size, or a ZSTD error code.
 */
ZSTDLIB_STATIC_API size_t
ZSTD_compressSequencesAndLiterals(ZSTD_CCtx* cctx,
                                  void* dst, size_t dstCapacity,
                            const ZSTD_Sequence* inSeqs, size_t nbSequences,
                            const void* literals, size_t litSize, size_t litBufCapacity,
                            size_t decompressedSize);


/*! ZSTD_writeSkippableFrame() :
 * Generates a zstd skippable frame containing data given by src, and writes it to dst buffer.
 *
 * Skippable frames begin with a 4-byte magic number. There are 16 possible choices of magic number,
 * ranging from ZSTD_MAGIC_SKIPPABLE_START to ZSTD_MAGIC_SKIPPABLE_START+15.
 * As such, the parameter magicVariant controls the exact skippable frame magic number variant used,
 * so the magic number used will be ZSTD_MAGIC_SKIPPABLE_START + magicVariant.
 *
 * Returns an error if destination buffer is not large enough, if the source size is not representable
 * with a 4-byte unsigned int, or if the parameter magicVariant is greater than 15 (and therefore invalid).
 *
 * @return : number of bytes written or a ZSTD error.
 */
ZSTDLIB_STATIC_API size_t ZSTD_writeSkippableFrame(void* dst, size_t dstCapacity,
                                             const void* src, size_t srcSize,
                                                   unsigned magicVariant);

/*! ZSTD_readSkippableFrame() :
 * Retrieves the content of a zstd skippable frame starting at @src, and writes it to @dst buffer.
 *
 * The parameter @magicVariant will receive the magicVariant that was supplied when the frame was written,
 * i.e. magicNumber - ZSTD_MAGIC_SKIPPABLE_START.
 * This can be NULL if the caller is not interested in the magicVariant.
 *
 * Returns an error if destination buffer is not large enough, or if the frame is not skippable.
 *
 * @return : number of bytes written or a ZSTD error.
 */
ZSTDLIB_STATIC_API size_t ZSTD_readSkippableFrame(void* dst, size_t dstCapacity,
                                                  unsigned* magicVariant,
                                                  const void* src, size_t srcSize);

/*! ZSTD_isSkippableFrame() :
 *  Tells if the content of `buffer` starts with a valid Frame Identifier for a skippable frame.
 */
ZSTDLIB_STATIC_API unsigned ZSTD_isSkippableFrame(const void* buffer, size_t size);



/***************************************
*  Memory management
***************************************/

/*! ZSTD_estimate*() :
 *  These functions make it possible to estimate memory usage
 *  of a future {D,C}Ctx, before its creation.
 *  This is useful in combination with ZSTD_initStatic(),
 *  which makes it possible to employ a static buffer for ZSTD_CCtx* state.
 *
 *  ZSTD_estimateCCtxSize() will provide a memory budget large enough
 *  to compress data of any size using one-shot compression ZSTD_compressCCtx() or ZSTD_compress2()
 *  associated with any compression level up to max specified one.
 *  The estimate will assume the input may be arbitrarily large,
 *  which is the worst case.
 *
 *  Note that the size estimation is specific for one-shot compression,
 *  it is not valid for streaming (see ZSTD_estimateCStreamSize*())
 *  nor other potential ways of using a ZSTD_CCtx* state.
 *
 *  When srcSize can be bound by a known and rather "small" value,
 *  this knowledge can be used to provide a tighter budget estimation
 *  because the ZSTD_CCtx* state will need less memory for small inputs.
 *  This tighter estimation can be provided by employing more advanced functions
 *  ZSTD_estimateCCtxSize_usingCParams(), which can be used in tandem with ZSTD_getCParams(),
 *  and ZSTD_estimateCCtxSize_usingCCtxParams(), which can be used in tandem with ZSTD_CCtxParams_setParameter().
 *  Both can be used to estimate memory using custom compression parameters and arbitrary srcSize limits.
 *
 *  Note : only single-threaded compression is supported.
 *  ZSTD_estimateCCtxSize_usingCCtxParams() will return an error code if ZSTD_c_nbWorkers is >= 1.
 */
ZSTDLIB_STATIC_API size_t ZSTD_estimateCCtxSize(int maxCompressionLevel);
ZSTDLIB_STATIC_API size_t ZSTD_estimateCCtxSize_usingCParams(ZSTD_compressionParameters cParams);
ZSTDLIB_STATIC_API size_t ZSTD_estimateCCtxSize_usingCCtxParams(const ZSTD_CCtx_params* params);
ZSTDLIB_STATIC_API size_t ZSTD_estimateDCtxSize(void);

/*! ZSTD_estimateCStreamSize() :
 *  ZSTD_estimateCStreamSize() will provide a memory budget large enough for streaming compression
 *  using any compression level up to the max specified one.
 *  It will also consider src size to be arbitrarily "large", which is a worst case scenario.
 *  If srcSize is known to always be small, ZSTD_estimateCStreamSize_usingCParams() can provide a tighter estimation.
 *  ZSTD_estimateCStreamSize_usingCParams() can be used in tandem with ZSTD_getCParams() to create cParams from compressionLevel.
 *  ZSTD_estimateCStreamSize_usingCCtxParams() can be used in tandem with ZSTD_CCtxParams_setParameter(). Only single-threaded compression is supported. This function will return an error code if ZSTD_c_nbWorkers is >= 1.
 *  Note : CStream size estimation is only correct for single-threaded compression.
 *  ZSTD_estimateCStreamSize_usingCCtxParams() will return an error code if ZSTD_c_nbWorkers is >= 1.
 *  Note 2 : ZSTD_estimateCStreamSize* functions are not compatible with the Block-Level Sequence Producer API at this time.
 *  Size estimates assume that no external sequence producer is registered.
 *
 *  ZSTD_DStream memory budget depends on frame's window Size.
 *  This information can be passed manually, using ZSTD_estimateDStreamSize,
 *  or deducted from a valid frame Header, using ZSTD_estimateDStreamSize_fromFrame();
 *  Any frame requesting a window size larger than max specified one will be rejected.
 *  Note : if streaming is init with function ZSTD_init?Stream_usingDict(),
 *         an internal ?Dict will be created, which additional size is not estimated here.
 *         In this case, get total size by adding ZSTD_estimate?DictSize
 */
ZSTDLIB_STATIC_API size_t ZSTD_estimateCStreamSize(int maxCompressionLevel);
ZSTDLIB_STATIC_API size_t ZSTD_estimateCStreamSize_usingCParams(ZSTD_compressionParameters cParams);
ZSTDLIB_STATIC_API size_t ZSTD_estimateCStreamSize_usingCCtxParams(const ZSTD_CCtx_params* params);
ZSTDLIB_STATIC_API size_t ZSTD_estimateDStreamSize(size_t maxWindowSize);
ZSTDLIB_STATIC_API size_t ZSTD_estimateDStreamSize_fromFrame(const void* src, size_t srcSize);

/*! ZSTD_estimate?DictSize() :
 *  ZSTD_estimateCDictSize() will bet that src size is relatively "small", and content is copied, like ZSTD_createCDict().
 *  ZSTD_estimateCDictSize_advanced() makes it possible to control compression parameters precisely, like ZSTD_createCDict_advanced().
 *  Note : dictionaries created by reference (`ZSTD_dlm_byRef`) are logically smaller.
 */
ZSTDLIB_STATIC_API size_t ZSTD_estimateCDictSize(size_t dictSize, int compressionLevel);
ZSTDLIB_STATIC_API size_t ZSTD_estimateCDictSize_advanced(size_t dictSize, ZSTD_compressionParameters cParams, ZSTD_dictLoadMethod_e dictLoadMethod);
ZSTDLIB_STATIC_API size_t ZSTD_estimateDDictSize(size_t dictSize, ZSTD_dictLoadMethod_e dictLoadMethod);

/*! ZSTD_initStatic*() :
 *  Initialize an object using a pre-allocated fixed-size buffer.
 *  workspace: The memory area to emplace the object into.
 *             Provided pointer *must be 8-bytes aligned*.
 *             Buffer must outlive object.
 *  workspaceSize: Use ZSTD_estimate*Size() to determine
 *                 how large workspace must be to support target scenario.
 * @return : pointer to object (same address as workspace, just different type),
 *           or NULL if error (size too small, incorrect alignment, etc.)
 *  Note : zstd will never resize nor malloc() when using a static buffer.
 *         If the object requires more memory than available,
 *         zstd will just error out (typically ZSTD_error_memory_allocation).
 *  Note 2 : there is no corresponding "free" function.
 *           Since workspace is allocated externally, it must be freed externally too.
 *  Note 3 : cParams : use ZSTD_getCParams() to convert a compression level
 *           into its associated cParams.
 *  Limitation 1 : currently not compatible with internal dictionary creation, triggered by
 *                 ZSTD_CCtx_loadDictionary(), ZSTD_initCStream_usingDict() or ZSTD_initDStream_usingDict().
 *  Limitation 2 : static cctx currently not compatible with multi-threading.
 *  Limitation 3 : static dctx is incompatible with legacy support.
 */
ZSTDLIB_STATIC_API ZSTD_CCtx*    ZSTD_initStaticCCtx(void* workspace, size_t workspaceSize);
ZSTDLIB_STATIC_API ZSTD_CStream* ZSTD_initStaticCStream(void* workspace, size_t workspaceSize);    /**< same as ZSTD_initStaticCCtx() */

ZSTDLIB_STATIC_API ZSTD_DCtx*    ZSTD_initStaticDCtx(void* workspace, size_t workspaceSize);
ZSTDLIB_STATIC_API ZSTD_DStream* ZSTD_initStaticDStream(void* workspace, size_t workspaceSize);    /**< same as ZSTD_initStaticDCtx() */

ZSTDLIB_STATIC_API const ZSTD_CDict* ZSTD_initStaticCDict(
                                        void* workspace, size_t workspaceSize,
                                        const void* dict, size_t dictSize,
                                        ZSTD_dictLoadMethod_e dictLoadMethod,
                                        ZSTD_dictContentType_e dictContentType,
                                        ZSTD_compressionParameters cParams);

ZSTDLIB_STATIC_API const ZSTD_DDict* ZSTD_initStaticDDict(
                                        void* workspace, size_t workspaceSize,
                                        const void* dict, size_t dictSize,
                                        ZSTD_dictLoadMethod_e dictLoadMethod,
                                        ZSTD_dictContentType_e dictContentType);


/*! Custom memory allocation :
 *  These prototypes make it possible to pass your own allocation/free functions.
 *  ZSTD_customMem is provided at creation time, using ZSTD_create*_advanced() variants listed below.
 *  All allocation/free operations will be completed using these custom variants instead of regular <stdlib.h> ones.
 */
typedef void* (*ZSTD_allocFunction) (void* opaque, size_t size);
typedef void  (*ZSTD_freeFunction) (void* opaque, void* address);
typedef struct { ZSTD_allocFunction customAlloc; ZSTD_freeFunction customFree; void* opaque; } ZSTD_customMem;
static
#ifdef __GNUC__
__attribute__((__unused__))
#endif

#if defined(__clang__) && __clang_major__ >= 5
#pragma clang diagnostic push
#pragma clang diagnostic ignored "-Wzero-as-null-pointer-constant"
#endif
ZSTD_customMem const ZSTD_defaultCMem = { NULL, NULL, NULL };  /**< this constant defers to stdlib's functions */
#if defined(__clang__) && __clang_major__ >= 5
#pragma clang diagnostic pop
#endif

ZSTDLIB_STATIC_API ZSTD_CCtx*    ZSTD_createCCtx_advanced(ZSTD_customMem customMem);
ZSTDLIB_STATIC_API ZSTD_CStream* ZSTD_createCStream_advanced(ZSTD_customMem customMem);
ZSTDLIB_STATIC_API ZSTD_DCtx*    ZSTD_createDCtx_advanced(ZSTD_customMem customMem);
ZSTDLIB_STATIC_API ZSTD_DStream* ZSTD_createDStream_advanced(ZSTD_customMem customMem);

ZSTDLIB_STATIC_API ZSTD_CDict* ZSTD_createCDict_advanced(const void* dict, size_t dictSize,
                                                  ZSTD_dictLoadMethod_e dictLoadMethod,
                                                  ZSTD_dictContentType_e dictContentType,
                                                  ZSTD_compressionParameters cParams,
                                                  ZSTD_customMem customMem);

/*! Thread pool :
 *  These prototypes make it possible to share a thread pool among multiple compression contexts.
 *  This can limit resources for applications with multiple threads where each one uses
 *  a threaded compression mode (via ZSTD_c_nbWorkers parameter).
 *  ZSTD_createThreadPool creates a new thread pool with a given number of threads.
 *  Note that the lifetime of such pool must exist while being used.
 *  ZSTD_CCtx_refThreadPool assigns a thread pool to a context (use NULL argument value
 *  to use an internal thread pool).
 *  ZSTD_freeThreadPool frees a thread pool, accepts NULL pointer.
 */
typedef struct POOL_ctx_s ZSTD_threadPool;
ZSTDLIB_STATIC_API ZSTD_threadPool* ZSTD_createThreadPool(size_t numThreads);
ZSTDLIB_STATIC_API void ZSTD_freeThreadPool (ZSTD_threadPool* pool);  /* accept NULL pointer */
ZSTDLIB_STATIC_API size_t ZSTD_CCtx_refThreadPool(ZSTD_CCtx* cctx, ZSTD_threadPool* pool);


/*
 * This API is temporary and is expected to change or disappear in the future!
 */
ZSTDLIB_STATIC_API ZSTD_CDict* ZSTD_createCDict_advanced2(
    const void* dict, size_t dictSize,
    ZSTD_dictLoadMethod_e dictLoadMethod,
    ZSTD_dictContentType_e dictContentType,
    const ZSTD_CCtx_params* cctxParams,
    ZSTD_customMem customMem);

ZSTDLIB_STATIC_API ZSTD_DDict* ZSTD_createDDict_advanced(
    const void* dict, size_t dictSize,
    ZSTD_dictLoadMethod_e dictLoadMethod,
    ZSTD_dictContentType_e dictContentType,
    ZSTD_customMem customMem);


/***************************************
*  Advanced compression functions
***************************************/

/*! ZSTD_createCDict_byReference() :
 *  Create a digested dictionary for compression
 *  Dictionary content is just referenced, not duplicated.
 *  As a consequence, `dictBuffer` **must** outlive CDict,
 *  and its content must remain unmodified throughout the lifetime of CDict.
 *  note: equivalent to ZSTD_createCDict_advanced(), with dictLoadMethod==ZSTD_dlm_byRef */
ZSTDLIB_STATIC_API ZSTD_CDict* ZSTD_createCDict_byReference(const void* dictBuffer, size_t dictSize, int compressionLevel);

/*! ZSTD_getCParams() :
 * @return ZSTD_compressionParameters structure for a selected compression level and estimated srcSize.
 * `estimatedSrcSize` value is optional, select 0 if not known */
ZSTDLIB_STATIC_API ZSTD_compressionParameters ZSTD_getCParams(int compressionLevel, unsigned long long estimatedSrcSize, size_t dictSize);

/*! ZSTD_getParams() :
 *  same as ZSTD_getCParams(), but @return a full `ZSTD_parameters` object instead of sub-component `ZSTD_compressionParameters`.
 *  All fields of `ZSTD_frameParameters` are set to default : contentSize=1, checksum=0, noDictID=0 */
ZSTDLIB_STATIC_API ZSTD_parameters ZSTD_getParams(int compressionLevel, unsigned long long estimatedSrcSize, size_t dictSize);

/*! ZSTD_checkCParams() :
 *  Ensure param values remain within authorized range.
 * @return 0 on success, or an error code (can be checked with ZSTD_isError()) */
ZSTDLIB_STATIC_API size_t ZSTD_checkCParams(ZSTD_compressionParameters params);

/*! ZSTD_adjustCParams() :
 *  optimize params for a given `srcSize` and `dictSize`.
 * `srcSize` can be unknown, in which case use ZSTD_CONTENTSIZE_UNKNOWN.
 * `dictSize` must be `0` when there is no dictionary.
 *  cPar can be invalid : all parameters will be clamped within valid range in the @return struct.
 *  This function never fails (wide contract) */
ZSTDLIB_STATIC_API ZSTD_compressionParameters ZSTD_adjustCParams(ZSTD_compressionParameters cPar, unsigned long long srcSize, size_t dictSize);

/*! ZSTD_CCtx_setCParams() :
 *  Set all parameters provided within @p cparams into the working @p cctx.
 *  Note : if modifying parameters during compression (MT mode only),
 *         note that changes to the .windowLog parameter will be ignored.
 * @return 0 on success, or an error code (can be checked with ZSTD_isError()).
 *         On failure, no parameters are updated.
 */
ZSTDLIB_STATIC_API size_t ZSTD_CCtx_setCParams(ZSTD_CCtx* cctx, ZSTD_compressionParameters cparams);

/*! ZSTD_CCtx_setFParams() :
 *  Set all parameters provided within @p fparams into the working @p cctx.
 * @return 0 on success, or an error code (can be checked with ZSTD_isError()).
 */
ZSTDLIB_STATIC_API size_t ZSTD_CCtx_setFParams(ZSTD_CCtx* cctx, ZSTD_frameParameters fparams);

/*! ZSTD_CCtx_setParams() :
 *  Set all parameters provided within @p params into the working @p cctx.
 * @return 0 on success, or an error code (can be checked with ZSTD_isError()).
 */
ZSTDLIB_STATIC_API size_t ZSTD_CCtx_setParams(ZSTD_CCtx* cctx, ZSTD_parameters params);

/*! ZSTD_compress_advanced() :
 *  Note : this function is now DEPRECATED.
 *         It can be replaced by ZSTD_compress2(), in combination with ZSTD_CCtx_setParameter() and other parameter setters.
 *  This prototype will generate compilation warnings. */
ZSTD_DEPRECATED("use ZSTD_compress2")
ZSTDLIB_STATIC_API
size_t ZSTD_compress_advanced(ZSTD_CCtx* cctx,
                              void* dst, size_t dstCapacity,
                        const void* src, size_t srcSize,
                        const void* dict,size_t dictSize,
                              ZSTD_parameters params);

/*! ZSTD_compress_usingCDict_advanced() :
 *  Note : this function is now DEPRECATED.
 *         It can be replaced by ZSTD_compress2(), in combination with ZSTD_CCtx_loadDictionary() and other parameter setters.
 *  This prototype will generate compilation warnings. */
ZSTD_DEPRECATED("use ZSTD_compress2 with ZSTD_CCtx_loadDictionary")
ZSTDLIB_STATIC_API
size_t ZSTD_compress_usingCDict_advanced(ZSTD_CCtx* cctx,
                                              void* dst, size_t dstCapacity,
                                        const void* src, size_t srcSize,
                                        const ZSTD_CDict* cdict,
                                              ZSTD_frameParameters fParams);


/*! ZSTD_CCtx_loadDictionary_byReference() :
 *  Same as ZSTD_CCtx_loadDictionary(), but dictionary content is referenced, instead of being copied into CCtx.
 *  It saves some memory, but also requires that `dict` outlives its usage within `cctx` */
ZSTDLIB_STATIC_API size_t ZSTD_CCtx_loadDictionary_byReference(ZSTD_CCtx* cctx, const void* dict, size_t dictSize);

/*! ZSTD_CCtx_loadDictionary_advanced() :
 *  Same as ZSTD_CCtx_loadDictionary(), but gives finer control over
 *  how to load the dictionary (by copy ? by reference ?)
 *  and how to interpret it (automatic ? force raw mode ? full mode only ?) */
ZSTDLIB_STATIC_API size_t ZSTD_CCtx_loadDictionary_advanced(ZSTD_CCtx* cctx, const void* dict, size_t dictSize, ZSTD_dictLoadMethod_e dictLoadMethod, ZSTD_dictContentType_e dictContentType);

/*! ZSTD_CCtx_refPrefix_advanced() :
 *  Same as ZSTD_CCtx_refPrefix(), but gives finer control over
 *  how to interpret prefix content (automatic ? force raw mode (default) ? full mode only ?) */
ZSTDLIB_STATIC_API size_t ZSTD_CCtx_refPrefix_advanced(ZSTD_CCtx* cctx, const void* prefix, size_t prefixSize, ZSTD_dictContentType_e dictContentType);

/* ===   experimental parameters   === */
/* these parameters can be used with ZSTD_setParameter()
 * they are not guaranteed to remain supported in the future */

 /* Enables rsyncable mode,
  * which makes compressed files more rsync friendly
  * by adding periodic synchronization points to the compressed data.
  * The target average block size is ZSTD_c_jobSize / 2.
  * It's possible to modify the job size to increase or decrease
  * the granularity of the synchronization point.
  * Once the jobSize is smaller than the window size,
  * it will result in compression ratio degradation.
  * NOTE 1: rsyncable mode only works when multithreading is enabled.
  * NOTE 2: rsyncable performs poorly in combination with long range mode,
  * since it will decrease the effectiveness of synchronization points,
  * though mileage may vary.
  * NOTE 3: Rsyncable mode limits maximum compression speed to ~400 MB/s.
  * If the selected compression level is already running significantly slower,
  * the overall speed won't be significantly impacted.
  */
 #define ZSTD_c_rsyncable ZSTD_c_experimentalParam1

/* Select a compression format.
 * The value must be of type ZSTD_format_e.
 * See ZSTD_format_e enum definition for details */
#define ZSTD_c_format ZSTD_c_experimentalParam2

/* Force back-reference distances to remain < windowSize,
 * even when referencing into Dictionary content (default:0) */
#define ZSTD_c_forceMaxWindow ZSTD_c_experimentalParam3

/* Controls whether the contents of a CDict
 * are used in place, or copied into the working context.
 * Accepts values from the ZSTD_dictAttachPref_e enum.
 * See the comments on that enum for an explanation of the feature. */
#define ZSTD_c_forceAttachDict ZSTD_c_experimentalParam4

/* Controlled with ZSTD_ParamSwitch_e enum.
 * Default is ZSTD_ps_auto.
 * Set to ZSTD_ps_disable to never compress literals.
 * Set to ZSTD_ps_enable to always compress literals. (Note: uncompressed literals
 * may still be emitted if huffman is not beneficial to use.)
 *
 * By default, in ZSTD_ps_auto, the library will decide at runtime whether to use
 * literals compression based on the compression parameters - specifically,
 * negative compression levels do not use literal compression.
 */
#define ZSTD_c_literalCompressionMode ZSTD_c_experimentalParam5

/* User's best guess of source size.
 * Hint is not valid when srcSizeHint == 0.
 * There is no guarantee that hint is close to actual source size,
 * but compression ratio may regress significantly if guess considerably underestimates */
#define ZSTD_c_srcSizeHint ZSTD_c_experimentalParam7

/* Controls whether the new and experimental "dedicated dictionary search
 * structure" can be used. This feature is still rough around the edges, be
 * prepared for surprising behavior!
 *
 * How to use it:
 *
 * When using a CDict, whether to use this feature or not is controlled at
 * CDict creation, and it must be set in a CCtxParams set passed into that
 * construction (via ZSTD_createCDict_advanced2()). A compression will then
 * use the feature or not based on how the CDict was constructed; the value of
 * this param, set in the CCtx, will have no effect.
 *
 * However, when a dictionary buffer is passed into a CCtx, such as via
 * ZSTD_CCtx_loadDictionary(), this param can be set on the CCtx to control
 * whether the CDict that is created internally can use the feature or not.
 *
 * What it does:
 *
 * Normally, the internal data structures of the CDict are analogous to what
 * would be stored in a CCtx after compressing the contents of a dictionary.
 * To an approximation, a compression using a dictionary can then use those
 * data structures to simply continue what is effectively a streaming
 * compression where the simulated compression of the dictionary left off.
 * Which is to say, the search structures in the CDict are normally the same
 * format as in the CCtx.
 *
 * It is possible to do better, since the CDict is not like a CCtx: the search
 * structures are written once during CDict creation, and then are only read
 * after that, while the search structures in the CCtx are both read and
 * written as the compression goes along. This means we can choose a search
 * structure for the dictionary that is read-optimized.
 *
 * This feature enables the use of that different structure.
 *
 * Note that some of the members of the ZSTD_compressionParameters struct have
 * different semantics and constraints in the dedicated search structure. It is
 * highly recommended that you simply set a compression level in the CCtxParams
 * you pass into the CDict creation call, and avoid messing with the cParams
 * directly.
 *
 * Effects:
 *
 * This will only have any effect when the selected ZSTD_strategy
 * implementation supports this feature. Currently, that's limited to
 * ZSTD_greedy, ZSTD_lazy, and ZSTD_lazy2.
 *
 * Note that this means that the CDict tables can no longer be copied into the
 * CCtx, so the dict attachment mode ZSTD_dictForceCopy will no longer be
 * usable. The dictionary can only be attached or reloaded.
 *
 * In general, you should expect compression to be faster--sometimes very much
 * so--and CDict creation to be slightly slower. Eventually, we will probably
 * make this mode the default.
 */
#define ZSTD_c_enableDedicatedDictSearch ZSTD_c_experimentalParam8

/* ZSTD_c_stableInBuffer
 * Experimental parameter.
 * Default is 0 == disabled. Set to 1 to enable.
 *
 * Tells the compressor that input data presented with ZSTD_inBuffer
 * will ALWAYS be the same between calls.
 * Technically, the @src pointer must never be changed,
 * and the @pos field can only be updated by zstd.
 * However, it's possible to increase the @size field,
 * allowing scenarios where more data can be appended after compressions starts.
 * These conditions are checked by the compressor,
 * and compression will fail if they are not respected.
 * Also, data in the ZSTD_inBuffer within the range [src, src + pos)
 * MUST not be modified during compression or it will result in data corruption.
 *
 * When this flag is enabled zstd won't allocate an input window buffer,
 * because the user guarantees it can reference the ZSTD_inBuffer until
 * the frame is complete. But, it will still allocate an output buffer
 * large enough to fit a block (see ZSTD_c_stableOutBuffer). This will also
 * avoid the memcpy() from the input buffer to the input window buffer.
 *
 * NOTE: So long as the ZSTD_inBuffer always points to valid memory, using
 * this flag is ALWAYS memory safe, and will never access out-of-bounds
 * memory. However, compression WILL fail if conditions are not respected.
 *
 * WARNING: The data in the ZSTD_inBuffer in the range [src, src + pos) MUST
 * not be modified during compression or it will result in data corruption.
 * This is because zstd needs to reference data in the ZSTD_inBuffer to find
 * matches. Normally zstd maintains its own window buffer for this purpose,
 * but passing this flag tells zstd to rely on user provided buffer instead.
 */
#define ZSTD_c_stableInBuffer ZSTD_c_experimentalParam9

/* ZSTD_c_stableOutBuffer
 * Experimental parameter.
 * Default is 0 == disabled. Set to 1 to enable.
 *
 * Tells he compressor that the ZSTD_outBuffer will not be resized between
 * calls. Specifically: (out.size - out.pos) will never grow. This gives the
 * compressor the freedom to say: If the compressed data doesn't fit in the
 * output buffer then return ZSTD_error_dstSizeTooSmall. This allows us to
 * always decompress directly into the output buffer, instead of decompressing
 * into an internal buffer and copying to the output buffer.
 *
 * When this flag is enabled zstd won't allocate an output buffer, because
 * it can write directly to the ZSTD_outBuffer. It will still allocate the
 * input window buffer (see ZSTD_c_stableInBuffer).
 *
 * Zstd will check that (out.size - out.pos) never grows and return an error
 * if it does. While not strictly necessary, this should prevent surprises.
 */
#define ZSTD_c_stableOutBuffer ZSTD_c_experimentalParam10

/* ZSTD_c_blockDelimiters
 * Default is 0 == ZSTD_sf_noBlockDelimiters.
 *
 * For use with sequence compression API: ZSTD_compressSequences().
 *
 * Designates whether or not the given array of ZSTD_Sequence contains block delimiters
 * and last literals, which are defined as sequences with offset == 0 and matchLength == 0.
 * See the definition of ZSTD_Sequence for more specifics.
 */
#define ZSTD_c_blockDelimiters ZSTD_c_experimentalParam11

/* ZSTD_c_validateSequences
 * Default is 0 == disabled. Set to 1 to enable sequence validation.
 *
 * For use with sequence compression API: ZSTD_compressSequences*().
 * Designates whether or not provided sequences are validated within ZSTD_compressSequences*()
 * during function execution.
 *
 * When Sequence validation is disabled (default), Sequences are compressed as-is,
 * so they must correct, otherwise it would result in a corruption error.
 *
 * Sequence validation adds some protection, by ensuring that all values respect boundary conditions.
 * If a Sequence is detected invalid (see doc/zstd_compression_format.md for
 * specifics regarding offset/matchlength requirements) then the function will bail out and
 * return an error.
 */
#define ZSTD_c_validateSequences ZSTD_c_experimentalParam12

/* ZSTD_c_blockSplitterLevel
 * note: this parameter only influences the first splitter stage,
 *       which is active before producing the sequences.
 *       ZSTD_c_splitAfterSequences controls the next splitter stage,
 *       which is active after sequence production.
 *       Note that both can be combined.
 * Allowed values are between 0 and ZSTD_BLOCKSPLITTER_LEVEL_MAX included.
 * 0 means "auto", which will select a value depending on current ZSTD_c_strategy.
 * 1 means no splitting.
 * Then, values from 2 to 6 are sorted in increasing cpu load order.
 *
 * Note that currently the first block is never split,
 * to ensure expansion guarantees in presence of incompressible data.
 */
#define ZSTD_BLOCKSPLITTER_LEVEL_MAX 6
#define ZSTD_c_blockSplitterLevel ZSTD_c_experimentalParam20

/* ZSTD_c_splitAfterSequences
 * This is a stronger splitter algorithm,
 * based on actual sequences previously produced by the selected parser.
 * It's also slower, and as a consequence, mostly used for high compression levels.
 * While the post-splitter does overlap with the pre-splitter,
 * both can nonetheless be combined,
 * notably with ZSTD_c_blockSplitterLevel at ZSTD_BLOCKSPLITTER_LEVEL_MAX,
 * resulting in higher compression ratio than just one of them.
 *
 * Default is ZSTD_ps_auto.
 * Set to ZSTD_ps_disable to never use block splitter.
 * Set to ZSTD_ps_enable to always use block splitter.
 *
 * By default, in ZSTD_ps_auto, the library will decide at runtime whether to use
 * block splitting based on the compression parameters.
 */
#define ZSTD_c_splitAfterSequences ZSTD_c_experimentalParam13

/* ZSTD_c_useRowMatchFinder
 * Controlled with ZSTD_ParamSwitch_e enum.
 * Default is ZSTD_ps_auto.
 * Set to ZSTD_ps_disable to never use row-based matchfinder.
 * Set to ZSTD_ps_enable to force usage of row-based matchfinder.
 *
 * By default, in ZSTD_ps_auto, the library will decide at runtime whether to use
 * the row-based matchfinder based on support for SIMD instructions and the window log.
 * Note that this only pertains to compression strategies: greedy, lazy, and lazy2
 */
#define ZSTD_c_useRowMatchFinder ZSTD_c_experimentalParam14

/* ZSTD_c_deterministicRefPrefix
 * Default is 0 == disabled. Set to 1 to enable.
 *
 * Zstd produces different results for prefix compression when the prefix is
 * directly adjacent to the data about to be compressed vs. when it isn't.
 * This is because zstd detects that the two buffers are contiguous and it can
 * use a more efficient match finding algorithm. However, this produces different
 * results than when the two buffers are non-contiguous. This flag forces zstd
 * to always load the prefix in non-contiguous mode, even if it happens to be
 * adjacent to the data, to guarantee determinism.
 *
 * If you really care about determinism when using a dictionary or prefix,
 * like when doing delta compression, you should select this option. It comes
 * at a speed penalty of about ~2.5% if the dictionary and data happened to be
 * contiguous, and is free if they weren't contiguous. We don't expect that
 * intentionally making the dictionary and data contiguous will be worth the
 * cost to memcpy() the data.
 */
#define ZSTD_c_deterministicRefPrefix ZSTD_c_experimentalParam15

/* ZSTD_c_prefetchCDictTables
 * Controlled with ZSTD_ParamSwitch_e enum. Default is ZSTD_ps_auto.
 *
 * In some situations, zstd uses CDict tables in-place rather than copying them
 * into the working context. (See docs on ZSTD_dictAttachPref_e above for details).
 * In such situations, compression speed is seriously impacted when CDict tables are
 * "cold" (outside CPU cache). This parameter instructs zstd to prefetch CDict tables
 * when they are used in-place.
 *
 * For sufficiently small inputs, the cost of the prefetch will outweigh the benefit.
 * For sufficiently large inputs, zstd will by default memcpy() CDict tables
 * into the working context, so there is no need to prefetch. This parameter is
 * targeted at a middle range of input sizes, where a prefetch is cheap enough to be
 * useful but memcpy() is too expensive. The exact range of input sizes where this
 * makes sense is best determined by careful experimentation.
 *
 * Note: for this parameter, ZSTD_ps_auto is currently equivalent to ZSTD_ps_disable,
 * but in the future zstd may conditionally enable this feature via an auto-detection
 * heuristic for cold CDicts.
 * Use ZSTD_ps_disable to opt out of prefetching under any circumstances.
 */
#define ZSTD_c_prefetchCDictTables ZSTD_c_experimentalParam16

/* ZSTD_c_enableSeqProducerFallback
 * Allowed values are 0 (disable) and 1 (enable). The default setting is 0.
 *
 * Controls whether zstd will fall back to an internal sequence producer if an
 * external sequence producer is registered and returns an error code. This fallback
 * is block-by-block: the internal sequence producer will only be called for blocks
 * where the external sequence producer returns an error code. Fallback parsing will
 * follow any other cParam settings, such as compression level, the same as in a
 * normal (fully-internal) compression operation.
 *
 * The user is strongly encouraged to read the full Block-Level Sequence Producer API
 * documentation (below) before setting this parameter. */
#define ZSTD_c_enableSeqProducerFallback ZSTD_c_experimentalParam17

/* ZSTD_c_maxBlockSize
 * Allowed values are between 1KB and ZSTD_BLOCKSIZE_MAX (128KB).
 * The default is ZSTD_BLOCKSIZE_MAX, and setting to 0 will set to the default.
 *
 * This parameter can be used to set an upper bound on the blocksize
 * that overrides the default ZSTD_BLOCKSIZE_MAX. It cannot be used to set upper
 * bounds greater than ZSTD_BLOCKSIZE_MAX or bounds lower than 1KB (will make
 * compressBound() inaccurate). Only currently meant to be used for testing.
 */
#define ZSTD_c_maxBlockSize ZSTD_c_experimentalParam18

/* ZSTD_c_repcodeResolution
 * This parameter only has an effect if ZSTD_c_blockDelimiters is
 * set to ZSTD_sf_explicitBlockDelimiters (may change in the future).
 *
 * This parameter affects how zstd parses external sequences,
 * provided via the ZSTD_compressSequences*() API
 * or from an external block-level sequence producer.
 *
 * If set to ZSTD_ps_enable, the library will check for repeated offsets within
 * external sequences, even if those repcodes are not explicitly indicated in
 * the "rep" field. Note that this is the only way to exploit repcode matches
 * while using compressSequences*() or an external sequence producer, since zstd
 * currently ignores the "rep" field of external sequences.
 *
 * If set to ZSTD_ps_disable, the library will not exploit repeated offsets in
 * external sequences, regardless of whether the "rep" field has been set. This
 * reduces sequence compression overhead by about 25% while sacrificing some
 * compression ratio.
 *
 * The default value is ZSTD_ps_auto, for which the library will enable/disable
 * based on compression level (currently: level<10 disables, level>=10 enables).
 */
#define ZSTD_c_repcodeResolution ZSTD_c_experimentalParam19
#define ZSTD_c_searchForExternalRepcodes ZSTD_c_experimentalParam19 /* older name */


/*! ZSTD_CCtx_getParameter() :
 *  Get the requested compression parameter value, selected by enum ZSTD_cParameter,
 *  and store it into int* value.
 * @return : 0, or an error code (which can be tested with ZSTD_isError()).
 */
ZSTDLIB_STATIC_API size_t ZSTD_CCtx_getParameter(const ZSTD_CCtx* cctx, ZSTD_cParameter param, int* value);


/*! ZSTD_CCtx_params :
 *  Quick howto :
 *  - ZSTD_createCCtxParams() : Create a ZSTD_CCtx_params structure
 *  - ZSTD_CCtxParams_setParameter() : Push parameters one by one into
 *                                     an existing ZSTD_CCtx_params structure.
 *                                     This is similar to
 *                                     ZSTD_CCtx_setParameter().
 *  - ZSTD_CCtx_setParametersUsingCCtxParams() : Apply parameters to
 *                                    an existing CCtx.
 *                                    These parameters will be applied to
 *                                    all subsequent frames.
 *  - ZSTD_compressStream2() : Do compression using the CCtx.
 *  - ZSTD_freeCCtxParams() : Free the memory, accept NULL pointer.
 *
 *  This can be used with ZSTD_estimateCCtxSize_advanced_usingCCtxParams()
 *  for static allocation of CCtx for single-threaded compression.
 */
ZSTDLIB_STATIC_API ZSTD_CCtx_params* ZSTD_createCCtxParams(void);
ZSTDLIB_STATIC_API size_t ZSTD_freeCCtxParams(ZSTD_CCtx_params* params);  /* accept NULL pointer */

/*! ZSTD_CCtxParams_reset() :
 *  Reset params to default values.
 */
ZSTDLIB_STATIC_API size_t ZSTD_CCtxParams_reset(ZSTD_CCtx_params* params);

/*! ZSTD_CCtxParams_init() :
 *  Initializes the compression parameters of cctxParams according to
 *  compression level. All other parameters are reset to their default values.
 */
ZSTDLIB_STATIC_API size_t ZSTD_CCtxParams_init(ZSTD_CCtx_params* cctxParams, int compressionLevel);

/*! ZSTD_CCtxParams_init_advanced() :
 *  Initializes the compression and frame parameters of cctxParams according to
 *  params. All other parameters are reset to their default values.
 */
ZSTDLIB_STATIC_API size_t ZSTD_CCtxParams_init_advanced(ZSTD_CCtx_params* cctxParams, ZSTD_parameters params);

/*! ZSTD_CCtxParams_setParameter() : Requires v1.4.0+
 *  Similar to ZSTD_CCtx_setParameter.
 *  Set one compression parameter, selected by enum ZSTD_cParameter.
 *  Parameters must be applied to a ZSTD_CCtx using
 *  ZSTD_CCtx_setParametersUsingCCtxParams().
 * @result : a code representing success or failure (which can be tested with
 *           ZSTD_isError()).
 */
ZSTDLIB_STATIC_API size_t ZSTD_CCtxParams_setParameter(ZSTD_CCtx_params* params, ZSTD_cParameter param, int value);

/*! ZSTD_CCtxParams_getParameter() :
 * Similar to ZSTD_CCtx_getParameter.
 * Get the requested value of one compression parameter, selected by enum ZSTD_cParameter.
 * @result : 0, or an error code (which can be tested with ZSTD_isError()).
 */
ZSTDLIB_STATIC_API size_t ZSTD_CCtxParams_getParameter(const ZSTD_CCtx_params* params, ZSTD_cParameter param, int* value);

/*! ZSTD_CCtx_setParametersUsingCCtxParams() :
 *  Apply a set of ZSTD_CCtx_params to the compression context.
 *  This can be done even after compression is started,
 *    if nbWorkers==0, this will have no impact until a new compression is started.
 *    if nbWorkers>=1, new parameters will be picked up at next job,
 *       with a few restrictions (windowLog, pledgedSrcSize, nbWorkers, jobSize, and overlapLog are not updated).
 */
ZSTDLIB_STATIC_API size_t ZSTD_CCtx_setParametersUsingCCtxParams(
        ZSTD_CCtx* cctx, const ZSTD_CCtx_params* params);

/*! ZSTD_compressStream2_simpleArgs() :
 *  Same as ZSTD_compressStream2(),
 *  but using only integral types as arguments.
 *  This variant might be helpful for binders from dynamic languages
 *  which have troubles handling structures containing memory pointers.
 */
ZSTDLIB_STATIC_API size_t ZSTD_compressStream2_simpleArgs (
                            ZSTD_CCtx* cctx,
                            void* dst, size_t dstCapacity, size_t* dstPos,
                      const void* src, size_t srcSize, size_t* srcPos,
                            ZSTD_EndDirective endOp);


/***************************************
*  Advanced decompression functions
***************************************/

/*! ZSTD_isFrame() :
 *  Tells if the content of `buffer` starts with a valid Frame Identifier.
 *  Note : Frame Identifier is 4 bytes. If `size < 4`, @return will always be 0.
 *  Note 2 : Legacy Frame Identifiers are considered valid only if Legacy Support is enabled.
 *  Note 3 : Skippable Frame Identifiers are considered valid. */
ZSTDLIB_STATIC_API unsigned ZSTD_isFrame(const void* buffer, size_t size);

/*! ZSTD_createDDict_byReference() :
 *  Create a digested dictionary, ready to start decompression operation without startup delay.
 *  Dictionary content is referenced, and therefore stays in dictBuffer.
 *  It is important that dictBuffer outlives DDict,
 *  it must remain read accessible throughout the lifetime of DDict */
ZSTDLIB_STATIC_API ZSTD_DDict* ZSTD_createDDict_byReference(const void* dictBuffer, size_t dictSize);

/*! ZSTD_DCtx_loadDictionary_byReference() :
 *  Same as ZSTD_DCtx_loadDictionary(),
 *  but references `dict` content instead of copying it into `dctx`.
 *  This saves memory if `dict` remains around.,
 *  However, it's imperative that `dict` remains accessible (and unmodified) while being used, so it must outlive decompression. */
ZSTDLIB_STATIC_API size_t ZSTD_DCtx_loadDictionary_byReference(ZSTD_DCtx* dctx, const void* dict, size_t dictSize);

/*! ZSTD_DCtx_loadDictionary_advanced() :
 *  Same as ZSTD_DCtx_loadDictionary(),
 *  but gives direct control over
 *  how to load the dictionary (by copy ? by reference ?)
 *  and how to interpret it (automatic ? force raw mode ? full mode only ?). */
ZSTDLIB_STATIC_API size_t ZSTD_DCtx_loadDictionary_advanced(ZSTD_DCtx* dctx, const void* dict, size_t dictSize, ZSTD_dictLoadMethod_e dictLoadMethod, ZSTD_dictContentType_e dictContentType);

/*! ZSTD_DCtx_refPrefix_advanced() :
 *  Same as ZSTD_DCtx_refPrefix(), but gives finer control over
 *  how to interpret prefix content (automatic ? force raw mode (default) ? full mode only ?) */
ZSTDLIB_STATIC_API size_t ZSTD_DCtx_refPrefix_advanced(ZSTD_DCtx* dctx, const void* prefix, size_t prefixSize, ZSTD_dictContentType_e dictContentType);

/*! ZSTD_DCtx_setMaxWindowSize() :
 *  Refuses allocating internal buffers for frames requiring a window size larger than provided limit.
 *  This protects a decoder context from reserving too much memory for itself (potential attack scenario).
 *  This parameter is only useful in streaming mode, since no internal buffer is allocated in single-pass mode.
 *  By default, a decompression context accepts all window sizes <= (1 << ZSTD_WINDOWLOG_LIMIT_DEFAULT)
 * @return : 0, or an error code (which can be tested using ZSTD_isError()).
 */
ZSTDLIB_STATIC_API size_t ZSTD_DCtx_setMaxWindowSize(ZSTD_DCtx* dctx, size_t maxWindowSize);

/*! ZSTD_DCtx_getParameter() :
 *  Get the requested decompression parameter value, selected by enum ZSTD_dParameter,
 *  and store it into int* value.
 * @return : 0, or an error code (which can be tested with ZSTD_isError()).
 */
ZSTDLIB_STATIC_API size_t ZSTD_DCtx_getParameter(ZSTD_DCtx* dctx, ZSTD_dParameter param, int* value);

/* ZSTD_d_format
 * experimental parameter,
 * allowing selection between ZSTD_format_e input compression formats
 */
#define ZSTD_d_format ZSTD_d_experimentalParam1
/* ZSTD_d_stableOutBuffer
 * Experimental parameter.
 * Default is 0 == disabled. Set to 1 to enable.
 *
 * Tells the decompressor that the ZSTD_outBuffer will ALWAYS be the same
 * between calls, except for the modifications that zstd makes to pos (the
 * caller must not modify pos). This is checked by the decompressor, and
 * decompression will fail if it ever changes. Therefore the ZSTD_outBuffer
 * MUST be large enough to fit the entire decompressed frame. This will be
 * checked when the frame content size is known. The data in the ZSTD_outBuffer
 * in the range [dst, dst + pos) MUST not be modified during decompression
 * or you will get data corruption.
 *
 * When this flag is enabled zstd won't allocate an output buffer, because
 * it can write directly to the ZSTD_outBuffer, but it will still allocate
 * an input buffer large enough to fit any compressed block. This will also
 * avoid the memcpy() from the internal output buffer to the ZSTD_outBuffer.
 * If you need to avoid the input buffer allocation use the buffer-less
 * streaming API.
 *
 * NOTE: So long as the ZSTD_outBuffer always points to valid memory, using
 * this flag is ALWAYS memory safe, and will never access out-of-bounds
 * memory. However, decompression WILL fail if you violate the preconditions.
 *
 * WARNING: The data in the ZSTD_outBuffer in the range [dst, dst + pos) MUST
 * not be modified during decompression or you will get data corruption. This
 * is because zstd needs to reference data in the ZSTD_outBuffer to regenerate
 * matches. Normally zstd maintains its own buffer for this purpose, but passing
 * this flag tells zstd to use the user provided buffer.
 */
#define ZSTD_d_stableOutBuffer ZSTD_d_experimentalParam2

/* ZSTD_d_forceIgnoreChecksum
 * Experimental parameter.
 * Default is 0 == disabled. Set to 1 to enable
 *
 * Tells the decompressor to skip checksum validation during decompression, regardless
 * of whether checksumming was specified during compression. This offers some
 * slight performance benefits, and may be useful for debugging.
 * Param has values of type ZSTD_forceIgnoreChecksum_e
 */
#define ZSTD_d_forceIgnoreChecksum ZSTD_d_experimentalParam3

/* ZSTD_d_refMultipleDDicts
 * Experimental parameter.
 * Default is 0 == disabled. Set to 1 to enable
 *
 * If enabled and dctx is allocated on the heap, then additional memory will be allocated
 * to store references to multiple ZSTD_DDict. That is, multiple calls of ZSTD_refDDict()
 * using a given ZSTD_DCtx, rather than overwriting the previous DDict reference, will instead
 * store all references. At decompression time, the appropriate dictID is selected
 * from the set of DDicts based on the dictID in the frame.
 *
 * Usage is simply calling ZSTD_refDDict() on multiple dict buffers.
 *
 * Param has values of byte ZSTD_refMultipleDDicts_e
 *
 * WARNING: Enabling this parameter and calling ZSTD_DCtx_refDDict(), will trigger memory
 * allocation for the hash table. ZSTD_freeDCtx() also frees this memory.
 * Memory is allocated as per ZSTD_DCtx::customMem.
 *
 * Although this function allocates memory for the table, the user is still responsible for
 * memory management of the underlying ZSTD_DDict* themselves.
 */
#define ZSTD_d_refMultipleDDicts ZSTD_d_experimentalParam4

/* ZSTD_d_disableHuffmanAssembly
 * Set to 1 to disable the Huffman assembly implementation.
 * The default value is 0, which allows zstd to use the Huffman assembly
 * implementation if available.
 *
 * This parameter can be used to disable Huffman assembly at runtime.
 * If you want to disable it at compile time you can define the macro
 * ZSTD_DISABLE_ASM.
 */
#define ZSTD_d_disableHuffmanAssembly ZSTD_d_experimentalParam5

/* ZSTD_d_maxBlockSize
 * Allowed values are between 1KB and ZSTD_BLOCKSIZE_MAX (128KB).
 * The default is ZSTD_BLOCKSIZE_MAX, and setting to 0 will set to the default.
 *
 * Forces the decompressor to reject blocks whose content size is
 * larger than the configured maxBlockSize. When maxBlockSize is
 * larger than the windowSize, the windowSize is used instead.
 * This saves memory on the decoder when you know all blocks are small.
 *
 * This option is typically used in conjunction with ZSTD_c_maxBlockSize.
 *
 * WARNING: This causes the decoder to reject otherwise valid frames
 * that have block sizes larger than the configured maxBlockSize.
 */
#define ZSTD_d_maxBlockSize ZSTD_d_experimentalParam6


/*! ZSTD_DCtx_setFormat() :
 *  This function is REDUNDANT. Prefer ZSTD_DCtx_setParameter().
 *  Instruct the decoder context about what kind of data to decode next.
 *  This instruction is mandatory to decode data without a fully-formed header,
 *  such ZSTD_f_zstd1_magicless for example.
 * @return : 0, or an error code (which can be tested using ZSTD_isError()). */
ZSTD_DEPRECATED("use ZSTD_DCtx_setParameter() instead")
ZSTDLIB_STATIC_API
size_t ZSTD_DCtx_setFormat(ZSTD_DCtx* dctx, ZSTD_format_e format);

/*! ZSTD_decompressStream_simpleArgs() :
 *  Same as ZSTD_decompressStream(),
 *  but using only integral types as arguments.
 *  This can be helpful for binders from dynamic languages
 *  which have troubles handling structures containing memory pointers.
 */
ZSTDLIB_STATIC_API size_t ZSTD_decompressStream_simpleArgs (
                            ZSTD_DCtx* dctx,
                            void* dst, size_t dstCapacity, size_t* dstPos,
                      const void* src, size_t srcSize, size_t* srcPos);


/********************************************************************
*  Advanced streaming functions
*  Warning : most of these functions are now redundant with the Advanced API.
*  Once Advanced API reaches "stable" status,
*  redundant functions will be deprecated, and then at some point removed.
********************************************************************/

/*=====   Advanced Streaming compression functions  =====*/

/*! ZSTD_initCStream_srcSize() :
 * This function is DEPRECATED, and equivalent to:
 *     ZSTD_CCtx_reset(zcs, ZSTD_reset_session_only);
 *     ZSTD_CCtx_refCDict(zcs, NULL); // clear the dictionary (if any)
 *     ZSTD_CCtx_setParameter(zcs, ZSTD_c_compressionLevel, compressionLevel);
 *     ZSTD_CCtx_setPledgedSrcSize(zcs, pledgedSrcSize);
 *
 * pledgedSrcSize must be correct. If it is not known at init time, use
 * ZSTD_CONTENTSIZE_UNKNOWN. Note that, for compatibility with older programs,
 * "0" also disables frame content size field. It may be enabled in the future.
 * This prototype will generate compilation warnings.
 */
ZSTD_DEPRECATED("use ZSTD_CCtx_reset, see zstd.h for detailed instructions")
ZSTDLIB_STATIC_API
size_t ZSTD_initCStream_srcSize(ZSTD_CStream* zcs,
                         int compressionLevel,
                         unsigned long long pledgedSrcSize);

/*! ZSTD_initCStream_usingDict() :
 * This function is DEPRECATED, and is equivalent to:
 *     ZSTD_CCtx_reset(zcs, ZSTD_reset_session_only);
 *     ZSTD_CCtx_setParameter(zcs, ZSTD_c_compressionLevel, compressionLevel);
 *     ZSTD_CCtx_loadDictionary(zcs, dict, dictSize);
 *
 * Creates of an internal CDict (incompatible with static CCtx), except if
 * dict == NULL or dictSize < 8, in which case no dict is used.
 * Note: dict is loaded with ZSTD_dct_auto (treated as a full zstd dictionary if
 * it begins with ZSTD_MAGIC_DICTIONARY, else as raw content) and ZSTD_dlm_byCopy.
 * This prototype will generate compilation warnings.
 */
ZSTD_DEPRECATED("use ZSTD_CCtx_reset, see zstd.h for detailed instructions")
ZSTDLIB_STATIC_API
size_t ZSTD_initCStream_usingDict(ZSTD_CStream* zcs,
                     const void* dict, size_t dictSize,
                           int compressionLevel);

/*! ZSTD_initCStream_advanced() :
 * This function is DEPRECATED, and is equivalent to:
 *     ZSTD_CCtx_reset(zcs, ZSTD_reset_session_only);
 *     ZSTD_CCtx_setParams(zcs, params);
 *     ZSTD_CCtx_setPledgedSrcSize(zcs, pledgedSrcSize);
 *     ZSTD_CCtx_loadDictionary(zcs, dict, dictSize);
 *
 * dict is loaded with ZSTD_dct_auto and ZSTD_dlm_byCopy.
 * pledgedSrcSize must be correct.
 * If srcSize is not known at init time, use value ZSTD_CONTENTSIZE_UNKNOWN.
 * This prototype will generate compilation warnings.
 */
ZSTD_DEPRECATED("use ZSTD_CCtx_reset, see zstd.h for detailed instructions")
ZSTDLIB_STATIC_API
size_t ZSTD_initCStream_advanced(ZSTD_CStream* zcs,
                    const void* dict, size_t dictSize,
                          ZSTD_parameters params,
                          unsigned long long pledgedSrcSize);

/*! ZSTD_initCStream_usingCDict() :
 * This function is DEPRECATED, and equivalent to:
 *     ZSTD_CCtx_reset(zcs, ZSTD_reset_session_only);
 *     ZSTD_CCtx_refCDict(zcs, cdict);
 *
 * note : cdict will just be referenced, and must outlive compression session
 * This prototype will generate compilation warnings.
 */
ZSTD_DEPRECATED("use ZSTD_CCtx_reset and ZSTD_CCtx_refCDict, see zstd.h for detailed instructions")
ZSTDLIB_STATIC_API
size_t ZSTD_initCStream_usingCDict(ZSTD_CStream* zcs, const ZSTD_CDict* cdict);

/*! ZSTD_initCStream_usingCDict_advanced() :
 *   This function is DEPRECATED, and is equivalent to:
 *     ZSTD_CCtx_reset(zcs, ZSTD_reset_session_only);
 *     ZSTD_CCtx_setFParams(zcs, fParams);
 *     ZSTD_CCtx_setPledgedSrcSize(zcs, pledgedSrcSize);
 *     ZSTD_CCtx_refCDict(zcs, cdict);
 *
 * same as ZSTD_initCStream_usingCDict(), with control over frame parameters.
 * pledgedSrcSize must be correct. If srcSize is not known at init time, use
 * value ZSTD_CONTENTSIZE_UNKNOWN.
 * This prototype will generate compilation warnings.
 */
ZSTD_DEPRECATED("use ZSTD_CCtx_reset and ZSTD_CCtx_refCDict, see zstd.h for detailed instructions")
ZSTDLIB_STATIC_API
size_t ZSTD_initCStream_usingCDict_advanced(ZSTD_CStream* zcs,
                               const ZSTD_CDict* cdict,
                                     ZSTD_frameParameters fParams,
                                     unsigned long long pledgedSrcSize);

/*! ZSTD_resetCStream() :
 * This function is DEPRECATED, and is equivalent to:
 *     ZSTD_CCtx_reset(zcs, ZSTD_reset_session_only);
 *     ZSTD_CCtx_setPledgedSrcSize(zcs, pledgedSrcSize);
 * Note: ZSTD_resetCStream() interprets pledgedSrcSize == 0 as ZSTD_CONTENTSIZE_UNKNOWN, but
 *       ZSTD_CCtx_setPledgedSrcSize() does not do the same, so ZSTD_CONTENTSIZE_UNKNOWN must be
 *       explicitly specified.
 *
 *  start a new frame, using same parameters from previous frame.
 *  This is typically useful to skip dictionary loading stage, since it will reuse it in-place.
 *  Note that zcs must be init at least once before using ZSTD_resetCStream().
 *  If pledgedSrcSize is not known at reset time, use macro ZSTD_CONTENTSIZE_UNKNOWN.
 *  If pledgedSrcSize > 0, its value must be correct, as it will be written in header, and controlled at the end.
 *  For the time being, pledgedSrcSize==0 is interpreted as "srcSize unknown" for compatibility with older programs,
 *  but it will change to mean "empty" in future version, so use macro ZSTD_CONTENTSIZE_UNKNOWN instead.
 * @return : 0, or an error code (which can be tested using ZSTD_isError())
 *  This prototype will generate compilation warnings.
 */
ZSTD_DEPRECATED("use ZSTD_CCtx_reset, see zstd.h for detailed instructions")
ZSTDLIB_STATIC_API
size_t ZSTD_resetCStream(ZSTD_CStream* zcs, unsigned long long pledgedSrcSize);


typedef struct {
    unsigned long long ingested;   /* nb input bytes read and buffered */
    unsigned long long consumed;   /* nb input bytes actually compressed */
    unsigned long long produced;   /* nb of compressed bytes generated and buffered */
    unsigned long long flushed;    /* nb of compressed bytes flushed : not provided; can be tracked from caller side */
    unsigned currentJobID;         /* MT only : latest started job nb */
    unsigned nbActiveWorkers;      /* MT only : nb of workers actively compressing at probe time */
} ZSTD_frameProgression;

/* ZSTD_getFrameProgression() :
 * tells how much data has been ingested (read from input)
 * consumed (input actually compressed) and produced (output) for current frame.
 * Note : (ingested - consumed) is amount of input data buffered internally, not yet compressed.
 * Aggregates progression inside active worker threads.
 */
ZSTDLIB_STATIC_API ZSTD_frameProgression ZSTD_getFrameProgression(const ZSTD_CCtx* cctx);

/*! ZSTD_toFlushNow() :
 *  Tell how many bytes are ready to be flushed immediately.
 *  Useful for multithreading scenarios (nbWorkers >= 1).
 *  Probe the oldest active job, defined as oldest job not yet entirely flushed,
 *  and check its output buffer.
 * @return : amount of data stored in oldest job and ready to be flushed immediately.
 *  if @return == 0, it means either :
 *  + there is no active job (could be checked with ZSTD_frameProgression()), or
 *  + oldest job is still actively compressing data,
 *    but everything it has produced has also been flushed so far,
 *    therefore flush speed is limited by production speed of oldest job
 *    irrespective of the speed of concurrent (and newer) jobs.
 */
ZSTDLIB_STATIC_API size_t ZSTD_toFlushNow(ZSTD_CCtx* cctx);


/*=====   Advanced Streaming decompression functions  =====*/

/*!
 * This function is deprecated, and is equivalent to:
 *
 *     ZSTD_DCtx_reset(zds, ZSTD_reset_session_only);
 *     ZSTD_DCtx_loadDictionary(zds, dict, dictSize);
 *
 * note: no dictionary will be used if dict == NULL or dictSize < 8
 */
ZSTD_DEPRECATED("use ZSTD_DCtx_reset + ZSTD_DCtx_loadDictionary, see zstd.h for detailed instructions")
ZSTDLIB_STATIC_API size_t ZSTD_initDStream_usingDict(ZSTD_DStream* zds, const void* dict, size_t dictSize);

/*!
 * This function is deprecated, and is equivalent to:
 *
 *     ZSTD_DCtx_reset(zds, ZSTD_reset_session_only);
 *     ZSTD_DCtx_refDDict(zds, ddict);
 *
 * note : ddict is referenced, it must outlive decompression session
 */
ZSTD_DEPRECATED("use ZSTD_DCtx_reset + ZSTD_DCtx_refDDict, see zstd.h for detailed instructions")
ZSTDLIB_STATIC_API size_t ZSTD_initDStream_usingDDict(ZSTD_DStream* zds, const ZSTD_DDict* ddict);

/*!
 * This function is deprecated, and is equivalent to:
 *
 *     ZSTD_DCtx_reset(zds, ZSTD_reset_session_only);
 *
 * reuse decompression parameters from previous init; saves dictionary loading
 */
ZSTD_DEPRECATED("use ZSTD_DCtx_reset, see zstd.h for detailed instructions")
ZSTDLIB_STATIC_API size_t ZSTD_resetDStream(ZSTD_DStream* zds);


/* ********************* BLOCK-LEVEL SEQUENCE PRODUCER API *********************
 *
 * *** OVERVIEW ***
 * The Block-Level Sequence Producer API allows users to provide their own custom
 * sequence producer which libzstd invokes to process each block. The produced list
 * of sequences (literals and matches) is then post-processed by libzstd to produce
 * valid compressed blocks.
 *
 * This block-level offload API is a more granular complement of the existing
 * frame-level offload API compressSequences() (introduced in v1.5.1). It offers
 * an easier migration story for applications already integrated with libzstd: the
 * user application continues to invoke the same compression functions
 * ZSTD_compress2() or ZSTD_compressStream2() as usual, and transparently benefits
 * from the specific advantages of the external sequence producer. For example,
 * the sequence producer could be tuned to take advantage of known characteristics
 * of the input, to offer better speed / ratio, or could leverage hardware
 * acceleration not available within libzstd itself.
 *
 * See contrib/externalSequenceProducer for an example program employing the
 * Block-Level Sequence Producer API.
 *
 * *** USAGE ***
 * The user is responsible for implementing a function of type
 * ZSTD_sequenceProducer_F. For each block, zstd will pass the following
 * arguments to the user-provided function:
 *
 *   - sequenceProducerState: a pointer to a user-managed state for the sequence
 *     producer.
 *
 *   - outSeqs, outSeqsCapacity: an output buffer for the sequence producer.
 *     outSeqsCapacity is guaranteed >= ZSTD_sequenceBound(srcSize). The memory
 *     backing outSeqs is managed by the CCtx.
 *
 *   - src, srcSize: an input buffer for the sequence producer to parse.
 *     srcSize is guaranteed to be <= ZSTD_BLOCKSIZE_MAX.
 *
 *   - dict, dictSize: a history buffer, which may be empty, which the sequence
 *     producer may reference as it parses the src buffer. Currently, zstd will
 *     always pass dictSize == 0 into external sequence producers, but this will
 *     change in the future.
 *
 *   - compressionLevel: a signed integer representing the zstd compression level
 *     set by the user for the current operation. The sequence producer may choose
 *     to use this information to change its compression strategy and speed/ratio
 *     tradeoff. Note: the compression level does not reflect zstd parameters set
 *     through the advanced API.
 *
 *   - windowSize: a size_t representing the maximum allowed offset for external
 *     sequences. Note that sequence offsets are sometimes allowed to exceed the
 *     windowSize if a dictionary is present, see doc/zstd_compression_format.md
 *     for details.
 *
 * The user-provided function shall return a size_t representing the number of
 * sequences written to outSeqs. This return value will be treated as an error
 * code if it is greater than outSeqsCapacity. The return value must be non-zero
 * if srcSize is non-zero. The ZSTD_SEQUENCE_PRODUCER_ERROR macro is provided
 * for convenience, but any value greater than outSeqsCapacity will be treated as
 * an error code.
 *
 * If the user-provided function does not return an error code, the sequences
 * written to outSeqs must be a valid parse of the src buffer. Data corruption may
 * occur if the parse is not valid. A parse is defined to be valid if the
 * following conditions hold:
 *   - The sum of matchLengths and literalLengths must equal srcSize.
 *   - All sequences in the parse, except for the final sequence, must have
 *     matchLength >= ZSTD_MINMATCH_MIN. The final sequence must have
 *     matchLength >= ZSTD_MINMATCH_MIN or matchLength == 0.
 *   - All offsets must respect the windowSize parameter as specified in
 *     doc/zstd_compression_format.md.
 *   - If the final sequence has matchLength == 0, it must also have offset == 0.
 *
 * zstd will only validate these conditions (and fail compression if they do not
 * hold) if the ZSTD_c_validateSequences cParam is enabled. Note that sequence
 * validation has a performance cost.
 *
 * If the user-provided function returns an error, zstd will either fall back
 * to an internal sequence producer or fail the compression operation. The user can
 * choose between the two behaviors by setting the ZSTD_c_enableSeqProducerFallback
 * cParam. Fallback compression will follow any other cParam settings, such as
 * compression level, the same as in a normal compression operation.
 *
 * The user shall instruct zstd to use a particular ZSTD_sequenceProducer_F
 * function by calling
 *         ZSTD_registerSequenceProducer(cctx,
 *                                       sequenceProducerState,
 *                                       sequenceProducer)
 * This setting will persist until the next parameter reset of the CCtx.
 *
 * The sequenceProducerState must be initialized by the user before calling
 * ZSTD_registerSequenceProducer(). The user is responsible for destroying the
 * sequenceProducerState.
 *
 * *** LIMITATIONS ***
 * This API is compatible with all zstd compression APIs which respect advanced parameters.
 * However, there are three limitations:
 *
 * First, the ZSTD_c_enableLongDistanceMatching cParam is not currently supported.
 * COMPRESSION WILL FAIL if it is enabled and the user tries to compress with a block-level
 * external sequence producer.
 *   - Note that ZSTD_c_enableLongDistanceMatching is auto-enabled by default in some
 *     cases (see its documentation for details). Users must explicitly set
 *     ZSTD_c_enableLongDistanceMatching to ZSTD_ps_disable in such cases if an external
 *     sequence producer is registered.
 *   - As of this writing, ZSTD_c_enableLongDistanceMatching is disabled by default
 *     whenever ZSTD_c_windowLog < 128MB, but that's subject to change. Users should
 *     check the docs on ZSTD_c_enableLongDistanceMatching whenever the Block-Level Sequence
 *     Producer API is used in conjunction with advanced settings (like ZSTD_c_windowLog).
 *
 * Second, history buffers are not currently supported. Concretely, zstd will always pass
 * dictSize == 0 to the external sequence producer (for now). This has two implications:
 *   - Dictionaries are not currently supported. Compression will *not* fail if the user
 *     references a dictionary, but the dictionary won't have any effect.
 *   - Stream history is not currently supported. All advanced compression APIs, including
 *     streaming APIs, work with external sequence producers, but each block is treated as
 *     an independent chunk without history from previous blocks.
 *
 * Third, multi-threading within a single compression is not currently supported. In other words,
 * COMPRESSION WILL FAIL if ZSTD_c_nbWorkers > 0 and an external sequence producer is registered.
 * Multi-threading across compressions is fine: simply create one CCtx per thread.
 *
 * Long-term, we plan to overcome all three limitations. There is no technical blocker to
 * overcoming them. It is purely a question of engineering effort.
 */

#define ZSTD_SEQUENCE_PRODUCER_ERROR ((size_t)(-1))

typedef size_t (*ZSTD_sequenceProducer_F) (
  void* sequenceProducerState,
  ZSTD_Sequence* outSeqs, size_t outSeqsCapacity,
  const void* src, size_t srcSize,
  const void* dict, size_t dictSize,
  int compressionLevel,
  size_t windowSize
);

/*! ZSTD_registerSequenceProducer() :
 * Instruct zstd to use a block-level external sequence producer function.
 *
 * The sequenceProducerState must be initialized by the caller, and the caller is
 * responsible for managing its lifetime. This parameter is sticky across
 * compressions. It will remain set until the user explicitly resets compression
 * parameters.
 *
 * Sequence producer registration is considered to be an "advanced parameter",
 * part of the "advanced API". This means it will only have an effect on compression
 * APIs which respect advanced parameters, such as compress2() and compressStream2().
 * Older compression APIs such as compressCCtx(), which predate the introduction of
 * "advanced parameters", will ignore any external sequence producer setting.
 *
 * The sequence producer can be "cleared" by registering a NULL function pointer. This
 * removes all limitations described above in the "LIMITATIONS" section of the API docs.
 *
 * The user is strongly encouraged to read the full API documentation (above) before
 * calling this function. */
ZSTDLIB_STATIC_API void
ZSTD_registerSequenceProducer(
  ZSTD_CCtx* cctx,
  void* sequenceProducerState,
  ZSTD_sequenceProducer_F sequenceProducer
);

/*! ZSTD_CCtxParams_registerSequenceProducer() :
 * Same as ZSTD_registerSequenceProducer(), but operates on ZSTD_CCtx_params.
 * This is used for accurate size estimation with ZSTD_estimateCCtxSize_usingCCtxParams(),
 * which is needed when creating a ZSTD_CCtx with ZSTD_initStaticCCtx().
 *
 * If you are using the external sequence producer API in a scenario where ZSTD_initStaticCCtx()
 * is required, then this function is for you. Otherwise, you probably don't need it.
 *
 * See tests/zstreamtest.c for example usage. */
ZSTDLIB_STATIC_API void
ZSTD_CCtxParams_registerSequenceProducer(
  ZSTD_CCtx_params* params,
  void* sequenceProducerState,
  ZSTD_sequenceProducer_F sequenceProducer
);


/*********************************************************************
*  Buffer-less and synchronous inner streaming functions (DEPRECATED)
*
*  This API is deprecated, and will be removed in a future version.
*  It allows streaming (de)compression with user allocated buffers.
*  However, it is hard to use, and not as well tested as the rest of
*  our API.
*
*  Please use the normal streaming API instead: ZSTD_compressStream2,
*  and ZSTD_decompressStream.
*  If there is functionality that you need, but it doesn't provide,
*  please open an issue on our GitHub.
********************************************************************* */

/**
  Buffer-less streaming compression (synchronous mode)

  A ZSTD_CCtx object is required to track streaming operations.
  Use ZSTD_createCCtx() / ZSTD_freeCCtx() to manage resource.
  ZSTD_CCtx object can be reused multiple times within successive compression operations.

  Start by initializing a context.
  Use ZSTD_compressBegin(), or ZSTD_compressBegin_usingDict() for dictionary compression.

  Then, consume your input using ZSTD_compressContinue().
  There are some important considerations to keep in mind when using this advanced function :
  - ZSTD_compressContinue() has no internal buffer. It uses externally provided buffers only.
  - Interface is synchronous : input is consumed entirely and produces 1+ compressed blocks.
  - Caller must ensure there is enough space in `dst` to store compressed data under worst case scenario.
    Worst case evaluation is provided by ZSTD_compressBound().
    ZSTD_compressContinue() doesn't guarantee recover after a failed compression.
  - ZSTD_compressContinue() presumes prior input ***is still accessible and unmodified*** (up to maximum distance size, see WindowLog).
    It remembers all previous contiguous blocks, plus one separated memory segment (which can itself consists of multiple contiguous blocks)
  - ZSTD_compressContinue() detects that prior input has been overwritten when `src` buffer overlaps.
    In which case, it will "discard" the relevant memory section from its history.

  Finish a frame with ZSTD_compressEnd(), which will write the last block(s) and optional checksum.
  It's possible to use srcSize==0, in which case, it will write a final empty block to end the frame.
  Without last block mark, frames are considered unfinished (hence corrupted) by compliant decoders.

  `ZSTD_CCtx` object can be reused (ZSTD_compressBegin()) to compress again.
*/

/*=====   Buffer-less streaming compression functions  =====*/
ZSTD_DEPRECATED("The buffer-less API is deprecated in favor of the normal streaming API. See docs.")
ZSTDLIB_STATIC_API size_t ZSTD_compressBegin(ZSTD_CCtx* cctx, int compressionLevel);
ZSTD_DEPRECATED("The buffer-less API is deprecated in favor of the normal streaming API. See docs.")
ZSTDLIB_STATIC_API size_t ZSTD_compressBegin_usingDict(ZSTD_CCtx* cctx, const void* dict, size_t dictSize, int compressionLevel);
ZSTD_DEPRECATED("The buffer-less API is deprecated in favor of the normal streaming API. See docs.")
ZSTDLIB_STATIC_API size_t ZSTD_compressBegin_usingCDict(ZSTD_CCtx* cctx, const ZSTD_CDict* cdict); /**< note: fails if cdict==NULL */

ZSTD_DEPRECATED("This function will likely be removed in a future release. It is misleading and has very limited utility.")
ZSTDLIB_STATIC_API
size_t ZSTD_copyCCtx(ZSTD_CCtx* cctx, const ZSTD_CCtx* preparedCCtx, unsigned long long pledgedSrcSize); /**<  note: if pledgedSrcSize is not known, use ZSTD_CONTENTSIZE_UNKNOWN */

ZSTD_DEPRECATED("The buffer-less API is deprecated in favor of the normal streaming API. See docs.")
ZSTDLIB_STATIC_API size_t ZSTD_compressContinue(ZSTD_CCtx* cctx, void* dst, size_t dstCapacity, const void* src, size_t srcSize);
ZSTD_DEPRECATED("The buffer-less API is deprecated in favor of the normal streaming API. See docs.")
ZSTDLIB_STATIC_API size_t ZSTD_compressEnd(ZSTD_CCtx* cctx, void* dst, size_t dstCapacity, const void* src, size_t srcSize);

/* The ZSTD_compressBegin_advanced() and ZSTD_compressBegin_usingCDict_advanced() are now DEPRECATED and will generate a compiler warning */
ZSTD_DEPRECATED("use advanced API to access custom parameters")
ZSTDLIB_STATIC_API
size_t ZSTD_compressBegin_advanced(ZSTD_CCtx* cctx, const void* dict, size_t dictSize, ZSTD_parameters params, unsigned long long pledgedSrcSize); /**< pledgedSrcSize : If srcSize is not known at init time, use ZSTD_CONTENTSIZE_UNKNOWN */
ZSTD_DEPRECATED("use advanced API to access custom parameters")
ZSTDLIB_STATIC_API
size_t ZSTD_compressBegin_usingCDict_advanced(ZSTD_CCtx* const cctx, const ZSTD_CDict* const cdict, ZSTD_frameParameters const fParams, unsigned long long const pledgedSrcSize);   /* compression parameters are already set within cdict. pledgedSrcSize must be correct. If srcSize is not known, use macro ZSTD_CONTENTSIZE_UNKNOWN */
/**
  Buffer-less streaming decompression (synchronous mode)

  A ZSTD_DCtx object is required to track streaming operations.
  Use ZSTD_createDCtx() / ZSTD_freeDCtx() to manage it.
  A ZSTD_DCtx object can be reused multiple times.

  First typical operation is to retrieve frame parameters, using ZSTD_getFrameHeader().
  Frame header is extracted from the beginning of compressed frame, so providing only the frame's beginning is enough.
  Data fragment must be large enough to ensure successful decoding.
 `ZSTD_frameHeaderSize_max` bytes is guaranteed to always be large enough.
  result  : 0 : successful decoding, the `ZSTD_frameHeader` structure is correctly filled.
           >0 : `srcSize` is too small, please provide at least result bytes on next attempt.
           errorCode, which can be tested using ZSTD_isError().

  It fills a ZSTD_FrameHeader structure with important information to correctly decode the frame,
  such as the dictionary ID, content size, or maximum back-reference distance (`windowSize`).
  Note that these values could be wrong, either because of data corruption, or because a 3rd party deliberately spoofs false information.
  As a consequence, check that values remain within valid application range.
  For example, do not allocate memory blindly, check that `windowSize` is within expectation.
  Each application can set its own limits, depending on local restrictions.
  For extended interoperability, it is recommended to support `windowSize` of at least 8 MB.

  ZSTD_decompressContinue() needs previous data blocks during decompression, up to `windowSize` bytes.
  ZSTD_decompressContinue() is very sensitive to contiguity,
  if 2 blocks don't follow each other, make sure that either the compressor breaks contiguity at the same place,
  or that previous contiguous segment is large enough to properly handle maximum back-reference distance.
  There are multiple ways to guarantee this condition.

  The most memory efficient way is to use a round buffer of sufficient size.
  Sufficient size is determined by invoking ZSTD_decodingBufferSize_min(),
  which can return an error code if required value is too large for current system (in 32-bits mode).
  In a round buffer methodology, ZSTD_decompressContinue() decompresses each block next to previous one,
  up to the moment there is not enough room left in the buffer to guarantee decoding another full block,
  which maximum size is provided in `ZSTD_frameHeader` structure, field `blockSizeMax`.
  At which point, decoding can resume from the beginning of the buffer.
  Note that already decoded data stored in the buffer should be flushed before being overwritten.

  There are alternatives possible, for example using two or more buffers of size `windowSize` each, though they consume more memory.

  Finally, if you control the compression process, you can also ignore all buffer size rules,
  as long as the encoder and decoder progress in "lock-step",
  aka use exactly the same buffer sizes, break contiguity at the same place, etc.

  Once buffers are setup, start decompression, with ZSTD_decompressBegin().
  If decompression requires a dictionary, use ZSTD_decompressBegin_usingDict() or ZSTD_decompressBegin_usingDDict().

  Then use ZSTD_nextSrcSizeToDecompress() and ZSTD_decompressContinue() alternatively.
  ZSTD_nextSrcSizeToDecompress() tells how many bytes to provide as 'srcSize' to ZSTD_decompressContinue().
  ZSTD_decompressContinue() requires this _exact_ amount of bytes, or it will fail.

  result of ZSTD_decompressContinue() is the number of bytes regenerated within 'dst' (necessarily <= dstCapacity).
  It can be zero : it just means ZSTD_decompressContinue() has decoded some metadata item.
  It can also be an error code, which can be tested with ZSTD_isError().

  A frame is fully decoded when ZSTD_nextSrcSizeToDecompress() returns zero.
  Context can then be reset to start a new decompression.

  Note : it's possible to know if next input to present is a header or a block, using ZSTD_nextInputType().
  This information is not required to properly decode a frame.

  == Special case : skippable frames ==

  Skippable frames allow integration of user-defined data into a flow of concatenated frames.
  Skippable frames will be ignored (skipped) by decompressor.
  The format of skippable frames is as follows :
  a) Skippable frame ID - 4 Bytes, Little endian format, any value from 0x184D2A50 to 0x184D2A5F
  b) Frame Size - 4 Bytes, Little endian format, unsigned 32-bits
  c) Frame Content - any content (User Data) of length equal to Frame Size
  For skippable frames ZSTD_getFrameHeader() returns zfhPtr->frameType==ZSTD_skippableFrame.
  For skippable frames ZSTD_decompressContinue() always returns 0 : it only skips the content.
*/

/*=====   Buffer-less streaming decompression functions  =====*/

ZSTDLIB_STATIC_API size_t ZSTD_decodingBufferSize_min(unsigned long long windowSize, unsigned long long frameContentSize);  /**< when frame content size is not known, pass in frameContentSize == ZSTD_CONTENTSIZE_UNKNOWN */

ZSTDLIB_STATIC_API size_t ZSTD_decompressBegin(ZSTD_DCtx* dctx);
ZSTDLIB_STATIC_API size_t ZSTD_decompressBegin_usingDict(ZSTD_DCtx* dctx, const void* dict, size_t dictSize);
ZSTDLIB_STATIC_API size_t ZSTD_decompressBegin_usingDDict(ZSTD_DCtx* dctx, const ZSTD_DDict* ddict);

ZSTDLIB_STATIC_API size_t ZSTD_nextSrcSizeToDecompress(ZSTD_DCtx* dctx);
ZSTDLIB_STATIC_API size_t ZSTD_decompressContinue(ZSTD_DCtx* dctx, void* dst, size_t dstCapacity, const void* src, size_t srcSize);

/* misc */
ZSTD_DEPRECATED("This function will likely be removed in the next minor release. It is misleading and has very limited utility.")
ZSTDLIB_STATIC_API void   ZSTD_copyDCtx(ZSTD_DCtx* dctx, const ZSTD_DCtx* preparedDCtx);
typedef enum { ZSTDnit_frameHeader, ZSTDnit_blockHeader, ZSTDnit_block, ZSTDnit_lastBlock, ZSTDnit_checksum, ZSTDnit_skippableFrame } ZSTD_nextInputType_e;
ZSTDLIB_STATIC_API ZSTD_nextInputType_e ZSTD_nextInputType(ZSTD_DCtx* dctx);




/* ========================================= */
/**       Block level API (DEPRECATED)       */
/* ========================================= */

/*!

    This API is deprecated in favor of the regular compression API.
    You can get the frame header down to 2 bytes by setting:
      - ZSTD_c_format = ZSTD_f_zstd1_magicless
      - ZSTD_c_contentSizeFlag = 0
      - ZSTD_c_checksumFlag = 0
      - ZSTD_c_dictIDFlag = 0

    This API is not as well tested as our normal API, so we recommend not using it.
    We will be removing it in a future version. If the normal API doesn't provide
    the functionality you need, please open a GitHub issue.

    Block functions produce and decode raw zstd blocks, without frame metadata.
    Frame metadata cost is typically ~12 bytes, which can be non-negligible for very small blocks (< 100 bytes).
    But users will have to take in charge needed metadata to regenerate data, such as compressed and content sizes.

    A few rules to respect :
    - Compressing and decompressing require a context structure
      + Use ZSTD_createCCtx() and ZSTD_createDCtx()
    - It is necessary to init context before starting
      + compression : any ZSTD_compressBegin*() variant, including with dictionary
      + decompression : any ZSTD_decompressBegin*() variant, including with dictionary
    - Block size is limited, it must be <= ZSTD_getBlockSize() <= ZSTD_BLOCKSIZE_MAX == 128 KB
      + If input is larger than a block size, it's necessary to split input data into multiple blocks
      + For inputs larger than a single block, consider using regular ZSTD_compress() instead.
        Frame metadata is not that costly, and quickly becomes negligible as source size grows larger than a block.
    - When a block is considered not compressible enough, ZSTD_compressBlock() result will be 0 (zero) !
      ===> In which case, nothing is produced into `dst` !
      + User __must__ test for such outcome and deal directly with uncompressed data
      + A block cannot be declared incompressible if ZSTD_compressBlock() return value was != 0.
        Doing so would mess up with statistics history, leading to potential data corruption.
      + ZSTD_decompressBlock() _doesn't accept uncompressed data as input_ !!
      + In case of multiple successive blocks, should some of them be uncompressed,
        decoder must be informed of their existence in order to follow proper history.
        Use ZSTD_insertBlock() for such a case.
*/

/*=====   Raw zstd block functions  =====*/
ZSTD_DEPRECATED("The block API is deprecated in favor of the normal compression API. See docs.")
ZSTDLIB_STATIC_API size_t ZSTD_getBlockSize   (const ZSTD_CCtx* cctx);
ZSTD_DEPRECATED("The block API is deprecated in favor of the normal compression API. See docs.")
ZSTDLIB_STATIC_API size_t ZSTD_compressBlock  (ZSTD_CCtx* cctx, void* dst, size_t dstCapacity, const void* src, size_t srcSize);
ZSTD_DEPRECATED("The block API is deprecated in favor of the normal compression API. See docs.")
ZSTDLIB_STATIC_API size_t ZSTD_decompressBlock(ZSTD_DCtx* dctx, void* dst, size_t dstCapacity, const void* src, size_t srcSize);
ZSTD_DEPRECATED("The block API is deprecated in favor of the normal compression API. See docs.")
ZSTDLIB_STATIC_API size_t ZSTD_insertBlock    (ZSTD_DCtx* dctx, const void* blockStart, size_t blockSize);  /**< insert uncompressed block into `dctx` history. Useful for multi-blocks decompression. */

#if defined (__cplusplus)
}
#endif

#endif   /* ZSTD_H_ZSTD_STATIC_LINKING_ONLY */
```

--- file: target/debug/build/zstd-sys-6db71bc350d87f54/out/include/zstd_errors.h ---
```h
/*
 * Copyright (c) Meta Platforms, Inc. and affiliates.
 * All rights reserved.
 *
 * This source code is licensed under both the BSD-style license (found in the
 * LICENSE file in the root directory of this source tree) and the GPLv2 (found
 * in the COPYING file in the root directory of this source tree).
 * You may select, at your option, one of the above-listed licenses.
 */

#ifndef ZSTD_ERRORS_H_398273423
#define ZSTD_ERRORS_H_398273423

#if defined (__cplusplus)
extern "C" {
#endif

/* =====   ZSTDERRORLIB_API : control library symbols visibility   ===== */
#ifndef ZSTDERRORLIB_VISIBLE
   /* Backwards compatibility with old macro name */
#  ifdef ZSTDERRORLIB_VISIBILITY
#    define ZSTDERRORLIB_VISIBLE ZSTDERRORLIB_VISIBILITY
#  elif defined(__GNUC__) && (__GNUC__ >= 4) && !defined(__MINGW32__)
#    define ZSTDERRORLIB_VISIBLE __attribute__ ((visibility ("default")))
#  else
#    define ZSTDERRORLIB_VISIBLE
#  endif
#endif

#ifndef ZSTDERRORLIB_HIDDEN
#  if defined(__GNUC__) && (__GNUC__ >= 4) && !defined(__MINGW32__)
#    define ZSTDERRORLIB_HIDDEN __attribute__ ((visibility ("hidden")))
#  else
#    define ZSTDERRORLIB_HIDDEN
#  endif
#endif

#if defined(ZSTD_DLL_EXPORT) && (ZSTD_DLL_EXPORT==1)
#  define ZSTDERRORLIB_API __declspec(dllexport) ZSTDERRORLIB_VISIBLE
#elif defined(ZSTD_DLL_IMPORT) && (ZSTD_DLL_IMPORT==1)
#  define ZSTDERRORLIB_API __declspec(dllimport) ZSTDERRORLIB_VISIBLE /* It isn't required but allows to generate better code, saving a function pointer load from the IAT and an indirect jump.*/
#else
#  define ZSTDERRORLIB_API ZSTDERRORLIB_VISIBLE
#endif

/*-*********************************************
 *  Error codes list
 *-*********************************************
 *  Error codes _values_ are pinned down since v1.3.1 only.
 *  Therefore, don't rely on values if you may link to any version < v1.3.1.
 *
 *  Only values < 100 are considered stable.
 *
 *  note 1 : this API shall be used with static linking only.
 *           dynamic linking is not yet officially supported.
 *  note 2 : Prefer relying on the enum than on its value whenever possible
 *           This is the only supported way to use the error list < v1.3.1
 *  note 3 : ZSTD_isError() is always correct, whatever the library version.
 **********************************************/
typedef enum {
  ZSTD_error_no_error = 0,
  ZSTD_error_GENERIC  = 1,
  ZSTD_error_prefix_unknown                = 10,
  ZSTD_error_version_unsupported           = 12,
  ZSTD_error_frameParameter_unsupported    = 14,
  ZSTD_error_frameParameter_windowTooLarge = 16,
  ZSTD_error_corruption_detected = 20,
  ZSTD_error_checksum_wrong      = 22,
  ZSTD_error_literals_headerWrong = 24,
  ZSTD_error_dictionary_corrupted      = 30,
  ZSTD_error_dictionary_wrong          = 32,
  ZSTD_error_dictionaryCreation_failed = 34,
  ZSTD_error_parameter_unsupported   = 40,
  ZSTD_error_parameter_combination_unsupported = 41,
  ZSTD_error_parameter_outOfBound    = 42,
  ZSTD_error_tableLog_tooLarge       = 44,
  ZSTD_error_maxSymbolValue_tooLarge = 46,
  ZSTD_error_maxSymbolValue_tooSmall = 48,
  ZSTD_error_cannotProduce_uncompressedBlock = 49,
  ZSTD_error_stabilityCondition_notRespected = 50,
  ZSTD_error_stage_wrong       = 60,
  ZSTD_error_init_missing      = 62,
  ZSTD_error_memory_allocation = 64,
  ZSTD_error_workSpace_tooSmall= 66,
  ZSTD_error_dstSize_tooSmall = 70,
  ZSTD_error_srcSize_wrong    = 72,
  ZSTD_error_dstBuffer_null   = 74,
  ZSTD_error_noForwardProgress_destFull = 80,
  ZSTD_error_noForwardProgress_inputEmpty = 82,
  /* following error codes are __NOT STABLE__, they can be removed or changed in future versions */
  ZSTD_error_frameIndex_tooLarge = 100,
  ZSTD_error_seekableIO          = 102,
  ZSTD_error_dstBuffer_wrong     = 104,
  ZSTD_error_srcBuffer_wrong     = 105,
  ZSTD_error_sequenceProducer_failed = 106,
  ZSTD_error_externalSequences_invalid = 107,
  ZSTD_error_maxCode = 120  /* never EVER use this value directly, it can change in future versions! Use ZSTD_isError() instead */
} ZSTD_ErrorCode;

ZSTDERRORLIB_API const char* ZSTD_getErrorString(ZSTD_ErrorCode code);   /**< Same as ZSTD_getErrorName, but using a `ZSTD_ErrorCode` enum argument */


#if defined (__cplusplus)
}
#endif

#endif /* ZSTD_ERRORS_H_398273423 */
```

--- file: target/debug/build/zstd-sys-e95a61b68c71fb17/out/flag_check.c ---
```c
int main(void) { return 0; }
```

--- file: target/debug/build/zstd-sys-e95a61b68c71fb17/out/include/zdict.h ---
```h
/*
 * Copyright (c) Meta Platforms, Inc. and affiliates.
 * All rights reserved.
 *
 * This source code is licensed under both the BSD-style license (found in the
 * LICENSE file in the root directory of this source tree) and the GPLv2 (found
 * in the COPYING file in the root directory of this source tree).
 * You may select, at your option, one of the above-listed licenses.
 */

#ifndef ZSTD_ZDICT_H
#define ZSTD_ZDICT_H


/*======  Dependencies  ======*/
#include <stddef.h>  /* size_t */

#if defined (__cplusplus)
extern "C" {
#endif

/* =====   ZDICTLIB_API : control library symbols visibility   ===== */
#ifndef ZDICTLIB_VISIBLE
   /* Backwards compatibility with old macro name */
#  ifdef ZDICTLIB_VISIBILITY
#    define ZDICTLIB_VISIBLE ZDICTLIB_VISIBILITY
#  elif defined(__GNUC__) && (__GNUC__ >= 4) && !defined(__MINGW32__)
#    define ZDICTLIB_VISIBLE __attribute__ ((visibility ("default")))
#  else
#    define ZDICTLIB_VISIBLE
#  endif
#endif

#ifndef ZDICTLIB_HIDDEN
#  if defined(__GNUC__) && (__GNUC__ >= 4) && !defined(__MINGW32__)
#    define ZDICTLIB_HIDDEN __attribute__ ((visibility ("hidden")))
#  else
#    define ZDICTLIB_HIDDEN
#  endif
#endif

#if defined(ZSTD_DLL_EXPORT) && (ZSTD_DLL_EXPORT==1)
#  define ZDICTLIB_API __declspec(dllexport) ZDICTLIB_VISIBLE
#elif defined(ZSTD_DLL_IMPORT) && (ZSTD_DLL_IMPORT==1)
#  define ZDICTLIB_API __declspec(dllimport) ZDICTLIB_VISIBLE /* It isn't required but allows to generate better code, saving a function pointer load from the IAT and an indirect jump.*/
#else
#  define ZDICTLIB_API ZDICTLIB_VISIBLE
#endif

/*******************************************************************************
 * Zstd dictionary builder
 *
 * FAQ
 * ===
 * Why should I use a dictionary?
 * ------------------------------
 *
 * Zstd can use dictionaries to improve compression ratio of small data.
 * Traditionally small files don't compress well because there is very little
 * repetition in a single sample, since it is small. But, if you are compressing
 * many similar files, like a bunch of JSON records that share the same
 * structure, you can train a dictionary on ahead of time on some samples of
 * these files. Then, zstd can use the dictionary to find repetitions that are
 * present across samples. This can vastly improve compression ratio.
 *
 * When is a dictionary useful?
 * ----------------------------
 *
 * Dictionaries are useful when compressing many small files that are similar.
 * The larger a file is, the less benefit a dictionary will have. Generally,
 * we don't expect dictionary compression to be effective past 100KB. And the
 * smaller a file is, the more we would expect the dictionary to help.
 *
 * How do I use a dictionary?
 * --------------------------
 *
 * Simply pass the dictionary to the zstd compressor with
 * `ZSTD_CCtx_loadDictionary()`. The same dictionary must then be passed to
 * the decompressor, using `ZSTD_DCtx_loadDictionary()`. There are other
 * more advanced functions that allow selecting some options, see zstd.h for
 * complete documentation.
 *
 * What is a zstd dictionary?
 * --------------------------
 *
 * A zstd dictionary has two pieces: Its header, and its content. The header
 * contains a magic number, the dictionary ID, and entropy tables. These
 * entropy tables allow zstd to save on header costs in the compressed file,
 * which really matters for small data. The content is just bytes, which are
 * repeated content that is common across many samples.
 *
 * What is a raw content dictionary?
 * ---------------------------------
 *
 * A raw content dictionary is just bytes. It doesn't have a zstd dictionary
 * header, a dictionary ID, or entropy tables. Any buffer is a valid raw
 * content dictionary.
 *
 * How do I train a dictionary?
 * ----------------------------
 *
 * Gather samples from your use case. These samples should be similar to each
 * other. If you have several use cases, you could try to train one dictionary
 * per use case.
 *
 * Pass those samples to `ZDICT_trainFromBuffer()` and that will train your
 * dictionary. There are a few advanced versions of this function, but this
 * is a great starting point. If you want to further tune your dictionary
 * you could try `ZDICT_optimizeTrainFromBuffer_cover()`. If that is too slow
 * you can try `ZDICT_optimizeTrainFromBuffer_fastCover()`.
 *
 * If the dictionary training function fails, that is likely because you
 * either passed too few samples, or a dictionary would not be effective
 * for your data. Look at the messages that the dictionary trainer printed,
 * if it doesn't say too few samples, then a dictionary would not be effective.
 *
 * How large should my dictionary be?
 * ----------------------------------
 *
 * A reasonable dictionary size, the `dictBufferCapacity`, is about 100KB.
 * The zstd CLI defaults to a 110KB dictionary. You likely don't need a
 * dictionary larger than that. But, most use cases can get away with a
 * smaller dictionary. The advanced dictionary builders can automatically
 * shrink the dictionary for you, and select the smallest size that doesn't
 * hurt compression ratio too much. See the `shrinkDict` parameter.
 * A smaller dictionary can save memory, and potentially speed up
 * compression.
 *
 * How many samples should I provide to the dictionary builder?
 * ------------------------------------------------------------
 *
 * We generally recommend passing ~100x the size of the dictionary
 * in samples. A few thousand should suffice. Having too few samples
 * can hurt the dictionaries effectiveness. Having more samples will
 * only improve the dictionaries effectiveness. But having too many
 * samples can slow down the dictionary builder.
 *
 * How do I determine if a dictionary will be effective?
 * -----------------------------------------------------
 *
 * Simply train a dictionary and try it out. You can use zstd's built in
 * benchmarking tool to test the dictionary effectiveness.
 *
 *   # Benchmark levels 1-3 without a dictionary
 *   zstd -b1e3 -r /path/to/my/files
 *   # Benchmark levels 1-3 with a dictionary
 *   zstd -b1e3 -r /path/to/my/files -D /path/to/my/dictionary
 *
 * When should I retrain a dictionary?
 * -----------------------------------
 *
 * You should retrain a dictionary when its effectiveness drops. Dictionary
 * effectiveness drops as the data you are compressing changes. Generally, we do
 * expect dictionaries to "decay" over time, as your data changes, but the rate
 * at which they decay depends on your use case. Internally, we regularly
 * retrain dictionaries, and if the new dictionary performs significantly
 * better than the old dictionary, we will ship the new dictionary.
 *
 * I have a raw content dictionary, how do I turn it into a zstd dictionary?
 * -------------------------------------------------------------------------
 *
 * If you have a raw content dictionary, e.g. by manually constructing it, or
 * using a third-party dictionary builder, you can turn it into a zstd
 * dictionary by using `ZDICT_finalizeDictionary()`. You'll also have to
 * provide some samples of the data. It will add the zstd header to the
 * raw content, which contains a dictionary ID and entropy tables, which
 * will improve compression ratio, and allow zstd to write the dictionary ID
 * into the frame, if you so choose.
 *
 * Do I have to use zstd's dictionary builder?
 * -------------------------------------------
 *
 * No! You can construct dictionary content however you please, it is just
 * bytes. It will always be valid as a raw content dictionary. If you want
 * a zstd dictionary, which can improve compression ratio, use
 * `ZDICT_finalizeDictionary()`.
 *
 * What is the attack surface of a zstd dictionary?
 * ------------------------------------------------
 *
 * Zstd is heavily fuzz tested, including loading fuzzed dictionaries, so
 * zstd should never crash, or access out-of-bounds memory no matter what
 * the dictionary is. However, if an attacker can control the dictionary
 * during decompression, they can cause zstd to generate arbitrary bytes,
 * just like if they controlled the compressed data.
 *
 ******************************************************************************/


/*! ZDICT_trainFromBuffer():
 *  Train a dictionary from an array of samples.
 *  Redirect towards ZDICT_optimizeTrainFromBuffer_fastCover() single-threaded, with d=8, steps=4,
 *  f=20, and accel=1.
 *  Samples must be stored concatenated in a single flat buffer `samplesBuffer`,
 *  supplied with an array of sizes `samplesSizes`, providing the size of each sample, in order.
 *  The resulting dictionary will be saved into `dictBuffer`.
 * @return: size of dictionary stored into `dictBuffer` (<= `dictBufferCapacity`)
 *          or an error code, which can be tested with ZDICT_isError().
 *  Note:  Dictionary training will fail if there are not enough samples to construct a
 *         dictionary, or if most of the samples are too small (< 8 bytes being the lower limit).
 *         If dictionary training fails, you should use zstd without a dictionary, as the dictionary
 *         would've been ineffective anyways. If you believe your samples would benefit from a dictionary
 *         please open an issue with details, and we can look into it.
 *  Note: ZDICT_trainFromBuffer()'s memory usage is about 6 MB.
 *  Tips: In general, a reasonable dictionary has a size of ~ 100 KB.
 *        It's possible to select smaller or larger size, just by specifying `dictBufferCapacity`.
 *        In general, it's recommended to provide a few thousands samples, though this can vary a lot.
 *        It's recommended that total size of all samples be about ~x100 times the target size of dictionary.
 */
ZDICTLIB_API size_t ZDICT_trainFromBuffer(void* dictBuffer, size_t dictBufferCapacity,
                                    const void* samplesBuffer,
                                    const size_t* samplesSizes, unsigned nbSamples);

typedef struct {
    int      compressionLevel;   /**< optimize for a specific zstd compression level; 0 means default */
    unsigned notificationLevel;  /**< Write log to stderr; 0 = none (default); 1 = errors; 2 = progression; 3 = details; 4 = debug; */
    unsigned dictID;             /**< force dictID value; 0 means auto mode (32-bits random value)
                                  *   NOTE: The zstd format reserves some dictionary IDs for future use.
                                  *         You may use them in private settings, but be warned that they
                                  *         may be used by zstd in a public dictionary registry in the future.
                                  *         These dictionary IDs are:
                                  *           - low range  : <= 32767
                                  *           - high range : >= (2^31)
                                  */
} ZDICT_params_t;

/*! ZDICT_finalizeDictionary():
 * Given a custom content as a basis for dictionary, and a set of samples,
 * finalize dictionary by adding headers and statistics according to the zstd
 * dictionary format.
 *
 * Samples must be stored concatenated in a flat buffer `samplesBuffer`,
 * supplied with an array of sizes `samplesSizes`, providing the size of each
 * sample in order. The samples are used to construct the statistics, so they
 * should be representative of what you will compress with this dictionary.
 *
 * The compression level can be set in `parameters`. You should pass the
 * compression level you expect to use in production. The statistics for each
 * compression level differ, so tuning the dictionary for the compression level
 * can help quite a bit.
 *
 * You can set an explicit dictionary ID in `parameters`, or allow us to pick
 * a random dictionary ID for you, but we can't guarantee no collisions.
 *
 * The dstDictBuffer and the dictContent may overlap, and the content will be
 * appended to the end of the header. If the header + the content doesn't fit in
 * maxDictSize the beginning of the content is truncated to make room, since it
 * is presumed that the most profitable content is at the end of the dictionary,
 * since that is the cheapest to reference.
 *
 * `maxDictSize` must be >= max(dictContentSize, ZDICT_DICTSIZE_MIN).
 *
 * @return: size of dictionary stored into `dstDictBuffer` (<= `maxDictSize`),
 *          or an error code, which can be tested by ZDICT_isError().
 * Note: ZDICT_finalizeDictionary() will push notifications into stderr if
 *       instructed to, using notificationLevel>0.
 * NOTE: This function currently may fail in several edge cases including:
 *         * Not enough samples
 *         * Samples are uncompressible
 *         * Samples are all exactly the same
 */
ZDICTLIB_API size_t ZDICT_finalizeDictionary(void* dstDictBuffer, size_t maxDictSize,
                                const void* dictContent, size_t dictContentSize,
                                const void* samplesBuffer, const size_t* samplesSizes, unsigned nbSamples,
                                ZDICT_params_t parameters);


/*======   Helper functions   ======*/
ZDICTLIB_API unsigned ZDICT_getDictID(const void* dictBuffer, size_t dictSize);  /**< extracts dictID; @return zero if error (not a valid dictionary) */
ZDICTLIB_API size_t ZDICT_getDictHeaderSize(const void* dictBuffer, size_t dictSize);  /* returns dict header size; returns a ZSTD error code on failure */
ZDICTLIB_API unsigned ZDICT_isError(size_t errorCode);
ZDICTLIB_API const char* ZDICT_getErrorName(size_t errorCode);

#if defined (__cplusplus)
}
#endif

#endif   /* ZSTD_ZDICT_H */

#if defined(ZDICT_STATIC_LINKING_ONLY) && !defined(ZSTD_ZDICT_H_STATIC)
#define ZSTD_ZDICT_H_STATIC

#if defined (__cplusplus)
extern "C" {
#endif

/* This can be overridden externally to hide static symbols. */
#ifndef ZDICTLIB_STATIC_API
#  if defined(ZSTD_DLL_EXPORT) && (ZSTD_DLL_EXPORT==1)
#    define ZDICTLIB_STATIC_API __declspec(dllexport) ZDICTLIB_VISIBLE
#  elif defined(ZSTD_DLL_IMPORT) && (ZSTD_DLL_IMPORT==1)
#    define ZDICTLIB_STATIC_API __declspec(dllimport) ZDICTLIB_VISIBLE
#  else
#    define ZDICTLIB_STATIC_API ZDICTLIB_VISIBLE
#  endif
#endif

/* ====================================================================================
 * The definitions in this section are considered experimental.
 * They should never be used with a dynamic library, as they may change in the future.
 * They are provided for advanced usages.
 * Use them only in association with static linking.
 * ==================================================================================== */

#define ZDICT_DICTSIZE_MIN    256
/* Deprecated: Remove in v1.6.0 */
#define ZDICT_CONTENTSIZE_MIN 128

/*! ZDICT_cover_params_t:
 *  k and d are the only required parameters.
 *  For others, value 0 means default.
 */
typedef struct {
    unsigned k;                  /* Segment size : constraint: 0 < k : Reasonable range [16, 2048+] */
    unsigned d;                  /* dmer size : constraint: 0 < d <= k : Reasonable range [6, 16] */
    unsigned steps;              /* Number of steps : Only used for optimization : 0 means default (40) : Higher means more parameters checked */
    unsigned nbThreads;          /* Number of threads : constraint: 0 < nbThreads : 1 means single-threaded : Only used for optimization : Ignored if ZSTD_MULTITHREAD is not defined */
    double splitPoint;           /* Percentage of samples used for training: Only used for optimization : the first nbSamples * splitPoint samples will be used to training, the last nbSamples * (1 - splitPoint) samples will be used for testing, 0 means default (1.0), 1.0 when all samples are used for both training and testing */
    unsigned shrinkDict;         /* Train dictionaries to shrink in size starting from the minimum size and selects the smallest dictionary that is shrinkDictMaxRegression% worse than the largest dictionary. 0 means no shrinking and 1 means shrinking  */
    unsigned shrinkDictMaxRegression; /* Sets shrinkDictMaxRegression so that a smaller dictionary can be at worse shrinkDictMaxRegression% worse than the max dict size dictionary. */
    ZDICT_params_t zParams;
} ZDICT_cover_params_t;

typedef struct {
    unsigned k;                  /* Segment size : constraint: 0 < k : Reasonable range [16, 2048+] */
    unsigned d;                  /* dmer size : constraint: 0 < d <= k : Reasonable range [6, 16] */
    unsigned f;                  /* log of size of frequency array : constraint: 0 < f <= 31 : 1 means default(20)*/
    unsigned steps;              /* Number of steps : Only used for optimization : 0 means default (40) : Higher means more parameters checked */
    unsigned nbThreads;          /* Number of threads : constraint: 0 < nbThreads : 1 means single-threaded : Only used for optimization : Ignored if ZSTD_MULTITHREAD is not defined */
    double splitPoint;           /* Percentage of samples used for training: Only used for optimization : the first nbSamples * splitPoint samples will be used to training, the last nbSamples * (1 - splitPoint) samples will be used for testing, 0 means default (0.75), 1.0 when all samples are used for both training and testing */
    unsigned accel;              /* Acceleration level: constraint: 0 < accel <= 10, higher means faster and less accurate, 0 means default(1) */
    unsigned shrinkDict;         /* Train dictionaries to shrink in size starting from the minimum size and selects the smallest dictionary that is shrinkDictMaxRegression% worse than the largest dictionary. 0 means no shrinking and 1 means shrinking  */
    unsigned shrinkDictMaxRegression; /* Sets shrinkDictMaxRegression so that a smaller dictionary can be at worse shrinkDictMaxRegression% worse than the max dict size dictionary. */

    ZDICT_params_t zParams;
} ZDICT_fastCover_params_t;

/*! ZDICT_trainFromBuffer_cover():
 *  Train a dictionary from an array of samples using the COVER algorithm.
 *  Samples must be stored concatenated in a single flat buffer `samplesBuffer`,
 *  supplied with an array of sizes `samplesSizes`, providing the size of each sample, in order.
 *  The resulting dictionary will be saved into `dictBuffer`.
 * @return: size of dictionary stored into `dictBuffer` (<= `dictBufferCapacity`)
 *          or an error code, which can be tested with ZDICT_isError().
 *          See ZDICT_trainFromBuffer() for details on failure modes.
 *  Note: ZDICT_trainFromBuffer_cover() requires about 9 bytes of memory for each input byte.
 *  Tips: In general, a reasonable dictionary has a size of ~ 100 KB.
 *        It's possible to select smaller or larger size, just by specifying `dictBufferCapacity`.
 *        In general, it's recommended to provide a few thousands samples, though this can vary a lot.
 *        It's recommended that total size of all samples be about ~x100 times the target size of dictionary.
 */
ZDICTLIB_STATIC_API size_t ZDICT_trainFromBuffer_cover(
          void *dictBuffer, size_t dictBufferCapacity,
    const void *samplesBuffer, const size_t *samplesSizes, unsigned nbSamples,
          ZDICT_cover_params_t parameters);

/*! ZDICT_optimizeTrainFromBuffer_cover():
 * The same requirements as above hold for all the parameters except `parameters`.
 * This function tries many parameter combinations and picks the best parameters.
 * `*parameters` is filled with the best parameters found,
 * dictionary constructed with those parameters is stored in `dictBuffer`.
 *
 * All of the parameters d, k, steps are optional.
 * If d is non-zero then we don't check multiple values of d, otherwise we check d = {6, 8}.
 * if steps is zero it defaults to its default value.
 * If k is non-zero then we don't check multiple values of k, otherwise we check steps values in [50, 2000].
 *
 * @return: size of dictionary stored into `dictBuffer` (<= `dictBufferCapacity`)
 *          or an error code, which can be tested with ZDICT_isError().
 *          On success `*parameters` contains the parameters selected.
 *          See ZDICT_trainFromBuffer() for details on failure modes.
 * Note: ZDICT_optimizeTrainFromBuffer_cover() requires about 8 bytes of memory for each input byte and additionally another 5 bytes of memory for each byte of memory for each thread.
 */
ZDICTLIB_STATIC_API size_t ZDICT_optimizeTrainFromBuffer_cover(
          void* dictBuffer, size_t dictBufferCapacity,
    const void* samplesBuffer, const size_t* samplesSizes, unsigned nbSamples,
          ZDICT_cover_params_t* parameters);

/*! ZDICT_trainFromBuffer_fastCover():
 *  Train a dictionary from an array of samples using a modified version of COVER algorithm.
 *  Samples must be stored concatenated in a single flat buffer `samplesBuffer`,
 *  supplied with an array of sizes `samplesSizes`, providing the size of each sample, in order.
 *  d and k are required.
 *  All other parameters are optional, will use default values if not provided
 *  The resulting dictionary will be saved into `dictBuffer`.
 * @return: size of dictionary stored into `dictBuffer` (<= `dictBufferCapacity`)
 *          or an error code, which can be tested with ZDICT_isError().
 *          See ZDICT_trainFromBuffer() for details on failure modes.
 *  Note: ZDICT_trainFromBuffer_fastCover() requires 6 * 2^f bytes of memory.
 *  Tips: In general, a reasonable dictionary has a size of ~ 100 KB.
 *        It's possible to select smaller or larger size, just by specifying `dictBufferCapacity`.
 *        In general, it's recommended to provide a few thousands samples, though this can vary a lot.
 *        It's recommended that total size of all samples be about ~x100 times the target size of dictionary.
 */
ZDICTLIB_STATIC_API size_t ZDICT_trainFromBuffer_fastCover(void *dictBuffer,
                    size_t dictBufferCapacity, const void *samplesBuffer,
                    const size_t *samplesSizes, unsigned nbSamples,
                    ZDICT_fastCover_params_t parameters);

/*! ZDICT_optimizeTrainFromBuffer_fastCover():
 * The same requirements as above hold for all the parameters except `parameters`.
 * This function tries many parameter combinations (specifically, k and d combinations)
 * and picks the best parameters. `*parameters` is filled with the best parameters found,
 * dictionary constructed with those parameters is stored in `dictBuffer`.
 * All of the parameters d, k, steps, f, and accel are optional.
 * If d is non-zero then we don't check multiple values of d, otherwise we check d = {6, 8}.
 * if steps is zero it defaults to its default value.
 * If k is non-zero then we don't check multiple values of k, otherwise we check steps values in [50, 2000].
 * If f is zero, default value of 20 is used.
 * If accel is zero, default value of 1 is used.
 *
 * @return: size of dictionary stored into `dictBuffer` (<= `dictBufferCapacity`)
 *          or an error code, which can be tested with ZDICT_isError().
 *          On success `*parameters` contains the parameters selected.
 *          See ZDICT_trainFromBuffer() for details on failure modes.
 * Note: ZDICT_optimizeTrainFromBuffer_fastCover() requires about 6 * 2^f bytes of memory for each thread.
 */
ZDICTLIB_STATIC_API size_t ZDICT_optimizeTrainFromBuffer_fastCover(void* dictBuffer,
                    size_t dictBufferCapacity, const void* samplesBuffer,
                    const size_t* samplesSizes, unsigned nbSamples,
                    ZDICT_fastCover_params_t* parameters);

typedef struct {
    unsigned selectivityLevel;   /* 0 means default; larger => select more => larger dictionary */
    ZDICT_params_t zParams;
} ZDICT_legacy_params_t;

/*! ZDICT_trainFromBuffer_legacy():
 *  Train a dictionary from an array of samples.
 *  Samples must be stored concatenated in a single flat buffer `samplesBuffer`,
 *  supplied with an array of sizes `samplesSizes`, providing the size of each sample, in order.
 *  The resulting dictionary will be saved into `dictBuffer`.
 * `parameters` is optional and can be provided with values set to 0 to mean "default".
 * @return: size of dictionary stored into `dictBuffer` (<= `dictBufferCapacity`)
 *          or an error code, which can be tested with ZDICT_isError().
 *          See ZDICT_trainFromBuffer() for details on failure modes.
 *  Tips: In general, a reasonable dictionary has a size of ~ 100 KB.
 *        It's possible to select smaller or larger size, just by specifying `dictBufferCapacity`.
 *        In general, it's recommended to provide a few thousands samples, though this can vary a lot.
 *        It's recommended that total size of all samples be about ~x100 times the target size of dictionary.
 *  Note: ZDICT_trainFromBuffer_legacy() will send notifications into stderr if instructed to, using notificationLevel>0.
 */
ZDICTLIB_STATIC_API size_t ZDICT_trainFromBuffer_legacy(
    void* dictBuffer, size_t dictBufferCapacity,
    const void* samplesBuffer, const size_t* samplesSizes, unsigned nbSamples,
    ZDICT_legacy_params_t parameters);


/* Deprecation warnings */
/* It is generally possible to disable deprecation warnings from compiler,
   for example with -Wno-deprecated-declarations for gcc
   or _CRT_SECURE_NO_WARNINGS in Visual.
   Otherwise, it's also possible to manually define ZDICT_DISABLE_DEPRECATE_WARNINGS */
#ifdef ZDICT_DISABLE_DEPRECATE_WARNINGS
#  define ZDICT_DEPRECATED(message) /* disable deprecation warnings */
#else
#  define ZDICT_GCC_VERSION (__GNUC__ * 100 + __GNUC_MINOR__)
#  if defined (__cplusplus) && (__cplusplus >= 201402) /* C++14 or greater */
#    define ZDICT_DEPRECATED(message) [[deprecated(message)]]
#  elif defined(__clang__) || (ZDICT_GCC_VERSION >= 405)
#    define ZDICT_DEPRECATED(message) __attribute__((deprecated(message)))
#  elif (ZDICT_GCC_VERSION >= 301)
#    define ZDICT_DEPRECATED(message) __attribute__((deprecated))
#  elif defined(_MSC_VER)
#    define ZDICT_DEPRECATED(message) __declspec(deprecated(message))
#  else
#    pragma message("WARNING: You need to implement ZDICT_DEPRECATED for this compiler")
#    define ZDICT_DEPRECATED(message)
#  endif
#endif /* ZDICT_DISABLE_DEPRECATE_WARNINGS */

ZDICT_DEPRECATED("use ZDICT_finalizeDictionary() instead")
ZDICTLIB_STATIC_API
size_t ZDICT_addEntropyTablesFromBuffer(void* dictBuffer, size_t dictContentSize, size_t dictBufferCapacity,
                                  const void* samplesBuffer, const size_t* samplesSizes, unsigned nbSamples);

#if defined (__cplusplus)
}
#endif

#endif   /* ZSTD_ZDICT_H_STATIC */
```

--- file: target/debug/build/zstd-sys-e95a61b68c71fb17/out/include/zstd.h ---
```h
/*
 * Copyright (c) Meta Platforms, Inc. and affiliates.
 * All rights reserved.
 *
 * This source code is licensed under both the BSD-style license (found in the
 * LICENSE file in the root directory of this source tree) and the GPLv2 (found
 * in the COPYING file in the root directory of this source tree).
 * You may select, at your option, one of the above-listed licenses.
 */

#ifndef ZSTD_H_235446
#define ZSTD_H_235446


/* ======   Dependencies   ======*/
#include <stddef.h>   /* size_t */

#include "zstd_errors.h" /* list of errors */
#if defined(ZSTD_STATIC_LINKING_ONLY) && !defined(ZSTD_H_ZSTD_STATIC_LINKING_ONLY)
#include <limits.h>   /* INT_MAX */
#endif /* ZSTD_STATIC_LINKING_ONLY */

#if defined (__cplusplus)
extern "C" {
#endif

/* =====   ZSTDLIB_API : control library symbols visibility   ===== */
#ifndef ZSTDLIB_VISIBLE
   /* Backwards compatibility with old macro name */
#  ifdef ZSTDLIB_VISIBILITY
#    define ZSTDLIB_VISIBLE ZSTDLIB_VISIBILITY
#  elif defined(__GNUC__) && (__GNUC__ >= 4) && !defined(__MINGW32__)
#    define ZSTDLIB_VISIBLE __attribute__ ((visibility ("default")))
#  else
#    define ZSTDLIB_VISIBLE
#  endif
#endif

#ifndef ZSTDLIB_HIDDEN
#  if defined(__GNUC__) && (__GNUC__ >= 4) && !defined(__MINGW32__)
#    define ZSTDLIB_HIDDEN __attribute__ ((visibility ("hidden")))
#  else
#    define ZSTDLIB_HIDDEN
#  endif
#endif

#if defined(ZSTD_DLL_EXPORT) && (ZSTD_DLL_EXPORT==1)
#  define ZSTDLIB_API __declspec(dllexport) ZSTDLIB_VISIBLE
#elif defined(ZSTD_DLL_IMPORT) && (ZSTD_DLL_IMPORT==1)
#  define ZSTDLIB_API __declspec(dllimport) ZSTDLIB_VISIBLE /* It isn't required but allows to generate better code, saving a function pointer load from the IAT and an indirect jump.*/
#else
#  define ZSTDLIB_API ZSTDLIB_VISIBLE
#endif

/* Deprecation warnings :
 * Should these warnings be a problem, it is generally possible to disable them,
 * typically with -Wno-deprecated-declarations for gcc or _CRT_SECURE_NO_WARNINGS in Visual.
 * Otherwise, it's also possible to define ZSTD_DISABLE_DEPRECATE_WARNINGS.
 */
#ifdef ZSTD_DISABLE_DEPRECATE_WARNINGS
#  define ZSTD_DEPRECATED(message) /* disable deprecation warnings */
#else
#  if defined (__cplusplus) && (__cplusplus >= 201402) /* C++14 or greater */
#    define ZSTD_DEPRECATED(message) [[deprecated(message)]]
#  elif (defined(GNUC) && (GNUC > 4 || (GNUC == 4 && GNUC_MINOR >= 5))) || defined(__clang__) || defined(__IAR_SYSTEMS_ICC__)
#    define ZSTD_DEPRECATED(message) __attribute__((deprecated(message)))
#  elif defined(__GNUC__) && (__GNUC__ >= 3)
#    define ZSTD_DEPRECATED(message) __attribute__((deprecated))
#  elif defined(_MSC_VER)
#    define ZSTD_DEPRECATED(message) __declspec(deprecated(message))
#  else
#    pragma message("WARNING: You need to implement ZSTD_DEPRECATED for this compiler")
#    define ZSTD_DEPRECATED(message)
#  endif
#endif /* ZSTD_DISABLE_DEPRECATE_WARNINGS */


/*******************************************************************************
  Introduction

  zstd, short for Zstandard, is a fast lossless compression algorithm, targeting
  real-time compression scenarios at zlib-level and better compression ratios.
  The zstd compression library provides in-memory compression and decompression
  functions.

  The library supports regular compression levels from 1 up to ZSTD_maxCLevel(),
  which is currently 22. Levels >= 20, labeled `--ultra`, should be used with
  caution, as they require more memory. The library also offers negative
  compression levels, which extend the range of speed vs. ratio preferences.
  The lower the level, the faster the speed (at the cost of compression).

  Compression can be done in:
    - a single step (described as Simple API)
    - a single step, reusing a context (described as Explicit context)
    - unbounded multiple steps (described as Streaming compression)

  The compression ratio achievable on small data can be highly improved using
  a dictionary. Dictionary compression can be performed in:
    - a single step (described as Simple dictionary API)
    - a single step, reusing a dictionary (described as Bulk-processing
      dictionary API)

  Advanced experimental functions can be accessed using
  `#define ZSTD_STATIC_LINKING_ONLY` before including zstd.h.

  Advanced experimental APIs should never be used with a dynamically-linked
  library. They are not "stable"; their definitions or signatures may change in
  the future. Only static linking is allowed.
*******************************************************************************/

/*------   Version   ------*/
#define ZSTD_VERSION_MAJOR    1
#define ZSTD_VERSION_MINOR    5
#define ZSTD_VERSION_RELEASE  7
#define ZSTD_VERSION_NUMBER  (ZSTD_VERSION_MAJOR *100*100 + ZSTD_VERSION_MINOR *100 + ZSTD_VERSION_RELEASE)

/*! ZSTD_versionNumber() :
 *  Return runtime library version, the value is (MAJOR*100*100 + MINOR*100 + RELEASE). */
ZSTDLIB_API unsigned ZSTD_versionNumber(void);

#define ZSTD_LIB_VERSION ZSTD_VERSION_MAJOR.ZSTD_VERSION_MINOR.ZSTD_VERSION_RELEASE
#define ZSTD_QUOTE(str) #str
#define ZSTD_EXPAND_AND_QUOTE(str) ZSTD_QUOTE(str)
#define ZSTD_VERSION_STRING ZSTD_EXPAND_AND_QUOTE(ZSTD_LIB_VERSION)

/*! ZSTD_versionString() :
 *  Return runtime library version, like "1.4.5". Requires v1.3.0+. */
ZSTDLIB_API const char* ZSTD_versionString(void);

/* *************************************
 *  Default constant
 ***************************************/
#ifndef ZSTD_CLEVEL_DEFAULT
#  define ZSTD_CLEVEL_DEFAULT 3
#endif

/* *************************************
 *  Constants
 ***************************************/

/* All magic numbers are supposed read/written to/from files/memory using little-endian convention */
#define ZSTD_MAGICNUMBER            0xFD2FB528    /* valid since v0.8.0 */
#define ZSTD_MAGIC_DICTIONARY       0xEC30A437    /* valid since v0.7.0 */
#define ZSTD_MAGIC_SKIPPABLE_START  0x184D2A50    /* all 16 values, from 0x184D2A50 to 0x184D2A5F, signal the beginning of a skippable frame */
#define ZSTD_MAGIC_SKIPPABLE_MASK   0xFFFFFFF0

#define ZSTD_BLOCKSIZELOG_MAX  17
#define ZSTD_BLOCKSIZE_MAX     (1<<ZSTD_BLOCKSIZELOG_MAX)


/***************************************
*  Simple Core API
***************************************/
/*! ZSTD_compress() :
 *  Compresses `src` content as a single zstd compressed frame into already allocated `dst`.
 *  NOTE: Providing `dstCapacity >= ZSTD_compressBound(srcSize)` guarantees that zstd will have
 *        enough space to successfully compress the data.
 *  @return : compressed size written into `dst` (<= `dstCapacity),
 *            or an error code if it fails (which can be tested using ZSTD_isError()). */
ZSTDLIB_API size_t ZSTD_compress( void* dst, size_t dstCapacity,
                            const void* src, size_t srcSize,
                                  int compressionLevel);

/*! ZSTD_decompress() :
 * `compressedSize` : must be the _exact_ size of some number of compressed and/or skippable frames.
 *  Multiple compressed frames can be decompressed at once with this method.
 *  The result will be the concatenation of all decompressed frames, back to back.
 * `dstCapacity` is an upper bound of originalSize to regenerate.
 *  First frame's decompressed size can be extracted using ZSTD_getFrameContentSize().
 *  If maximum upper bound isn't known, prefer using streaming mode to decompress data.
 * @return : the number of bytes decompressed into `dst` (<= `dstCapacity`),
 *           or an errorCode if it fails (which can be tested using ZSTD_isError()). */
ZSTDLIB_API size_t ZSTD_decompress( void* dst, size_t dstCapacity,
                              const void* src, size_t compressedSize);


/*======  Decompression helper functions  ======*/

/*! ZSTD_getFrameContentSize() : requires v1.3.0+
 * `src` should point to the start of a ZSTD encoded frame.
 * `srcSize` must be at least as large as the frame header.
 *           hint : any size >= `ZSTD_frameHeaderSize_max` is large enough.
 * @return : - decompressed size of `src` frame content, if known
 *           - ZSTD_CONTENTSIZE_UNKNOWN if the size cannot be determined
 *           - ZSTD_CONTENTSIZE_ERROR if an error occurred (e.g. invalid magic number, srcSize too small)
 *  note 1 : a 0 return value means the frame is valid but "empty".
 *           When invoking this method on a skippable frame, it will return 0.
 *  note 2 : decompressed size is an optional field, it may not be present (typically in streaming mode).
 *           When `return==ZSTD_CONTENTSIZE_UNKNOWN`, data to decompress could be any size.
 *           In which case, it's necessary to use streaming mode to decompress data.
 *           Optionally, application can rely on some implicit limit,
 *           as ZSTD_decompress() only needs an upper bound of decompressed size.
 *           (For example, data could be necessarily cut into blocks <= 16 KB).
 *  note 3 : decompressed size is always present when compression is completed using single-pass functions,
 *           such as ZSTD_compress(), ZSTD_compressCCtx() ZSTD_compress_usingDict() or ZSTD_compress_usingCDict().
 *  note 4 : decompressed size can be very large (64-bits value),
 *           potentially larger than what local system can handle as a single memory segment.
 *           In which case, it's necessary to use streaming mode to decompress data.
 *  note 5 : If source is untrusted, decompressed size could be wrong or intentionally modified.
 *           Always ensure return value fits within application's authorized limits.
 *           Each application can set its own limits.
 *  note 6 : This function replaces ZSTD_getDecompressedSize() */
#define ZSTD_CONTENTSIZE_UNKNOWN (0ULL - 1)
#define ZSTD_CONTENTSIZE_ERROR   (0ULL - 2)
ZSTDLIB_API unsigned long long ZSTD_getFrameContentSize(const void *src, size_t srcSize);

/*! ZSTD_getDecompressedSize() (obsolete):
 *  This function is now obsolete, in favor of ZSTD_getFrameContentSize().
 *  Both functions work the same way, but ZSTD_getDecompressedSize() blends
 *  "empty", "unknown" and "error" results to the same return value (0),
 *  while ZSTD_getFrameContentSize() gives them separate return values.
 * @return : decompressed size of `src` frame content _if known and not empty_, 0 otherwise. */
ZSTD_DEPRECATED("Replaced by ZSTD_getFrameContentSize")
ZSTDLIB_API unsigned long long ZSTD_getDecompressedSize(const void* src, size_t srcSize);

/*! ZSTD_findFrameCompressedSize() : Requires v1.4.0+
 * `src` should point to the start of a ZSTD frame or skippable frame.
 * `srcSize` must be >= first frame size
 * @return : the compressed size of the first frame starting at `src`,
 *           suitable to pass as `srcSize` to `ZSTD_decompress` or similar,
 *           or an error code if input is invalid
 *  Note 1: this method is called _find*() because it's not enough to read the header,
 *          it may have to scan through the frame's content, to reach its end.
 *  Note 2: this method also works with Skippable Frames. In which case,
 *          it returns the size of the complete skippable frame,
 *          which is always equal to its content size + 8 bytes for headers. */
ZSTDLIB_API size_t ZSTD_findFrameCompressedSize(const void* src, size_t srcSize);


/*======  Compression helper functions  ======*/

/*! ZSTD_compressBound() :
 * maximum compressed size in worst case single-pass scenario.
 * When invoking `ZSTD_compress()`, or any other one-pass compression function,
 * it's recommended to provide @dstCapacity >= ZSTD_compressBound(srcSize)
 * as it eliminates one potential failure scenario,
 * aka not enough room in dst buffer to write the compressed frame.
 * Note : ZSTD_compressBound() itself can fail, if @srcSize >= ZSTD_MAX_INPUT_SIZE .
 *        In which case, ZSTD_compressBound() will return an error code
 *        which can be tested using ZSTD_isError().
 *
 * ZSTD_COMPRESSBOUND() :
 * same as ZSTD_compressBound(), but as a macro.
 * It can be used to produce constants, which can be useful for static allocation,
 * for example to size a static array on stack.
 * Will produce constant value 0 if srcSize is too large.
 */
#define ZSTD_MAX_INPUT_SIZE ((sizeof(size_t)==8) ? 0xFF00FF00FF00FF00ULL : 0xFF00FF00U)
#define ZSTD_COMPRESSBOUND(srcSize)   (((size_t)(srcSize) >= ZSTD_MAX_INPUT_SIZE) ? 0 : (srcSize) + ((srcSize)>>8) + (((srcSize) < (128<<10)) ? (((128<<10) - (srcSize)) >> 11) /* margin, from 64 to 0 */ : 0))  /* this formula ensures that bound(A) + bound(B) <= bound(A+B) as long as A and B >= 128 KB */
ZSTDLIB_API size_t ZSTD_compressBound(size_t srcSize); /*!< maximum compressed size in worst case single-pass scenario */


/*======  Error helper functions  ======*/
/* ZSTD_isError() :
 * Most ZSTD_* functions returning a size_t value can be tested for error,
 * using ZSTD_isError().
 * @return 1 if error, 0 otherwise
 */
ZSTDLIB_API unsigned     ZSTD_isError(size_t result);      /*!< tells if a `size_t` function result is an error code */
ZSTDLIB_API ZSTD_ErrorCode ZSTD_getErrorCode(size_t functionResult); /* convert a result into an error code, which can be compared to error enum list */
ZSTDLIB_API const char*  ZSTD_getErrorName(size_t result); /*!< provides readable string from a function result */
ZSTDLIB_API int          ZSTD_minCLevel(void);             /*!< minimum negative compression level allowed, requires v1.4.0+ */
ZSTDLIB_API int          ZSTD_maxCLevel(void);             /*!< maximum compression level available */
ZSTDLIB_API int          ZSTD_defaultCLevel(void);         /*!< default compression level, specified by ZSTD_CLEVEL_DEFAULT, requires v1.5.0+ */


/***************************************
*  Explicit context
***************************************/
/*= Compression context
 *  When compressing many times,
 *  it is recommended to allocate a compression context just once,
 *  and reuse it for each successive compression operation.
 *  This will make the workload easier for system's memory.
 *  Note : re-using context is just a speed / resource optimization.
 *         It doesn't change the compression ratio, which remains identical.
 *  Note 2: For parallel execution in multi-threaded environments,
 *         use one different context per thread .
 */
typedef struct ZSTD_CCtx_s ZSTD_CCtx;
ZSTDLIB_API ZSTD_CCtx* ZSTD_createCCtx(void);
ZSTDLIB_API size_t     ZSTD_freeCCtx(ZSTD_CCtx* cctx);  /* compatible with NULL pointer */

/*! ZSTD_compressCCtx() :
 *  Same as ZSTD_compress(), using an explicit ZSTD_CCtx.
 *  Important : in order to mirror `ZSTD_compress()` behavior,
 *  this function compresses at the requested compression level,
 *  __ignoring any other advanced parameter__ .
 *  If any advanced parameter was set using the advanced API,
 *  they will all be reset. Only @compressionLevel remains.
 */
ZSTDLIB_API size_t ZSTD_compressCCtx(ZSTD_CCtx* cctx,
                                     void* dst, size_t dstCapacity,
                               const void* src, size_t srcSize,
                                     int compressionLevel);

/*= Decompression context
 *  When decompressing many times,
 *  it is recommended to allocate a context only once,
 *  and reuse it for each successive compression operation.
 *  This will make workload friendlier for system's memory.
 *  Use one context per thread for parallel execution. */
typedef struct ZSTD_DCtx_s ZSTD_DCtx;
ZSTDLIB_API ZSTD_DCtx* ZSTD_createDCtx(void);
ZSTDLIB_API size_t     ZSTD_freeDCtx(ZSTD_DCtx* dctx);  /* accept NULL pointer */

/*! ZSTD_decompressDCtx() :
 *  Same as ZSTD_decompress(),
 *  requires an allocated ZSTD_DCtx.
 *  Compatible with sticky parameters (see below).
 */
ZSTDLIB_API size_t ZSTD_decompressDCtx(ZSTD_DCtx* dctx,
                                       void* dst, size_t dstCapacity,
                                 const void* src, size_t srcSize);


/*********************************************
*  Advanced compression API (Requires v1.4.0+)
**********************************************/

/* API design :
 *   Parameters are pushed one by one into an existing context,
 *   using ZSTD_CCtx_set*() functions.
 *   Pushed parameters are sticky : they are valid for next compressed frame, and any subsequent frame.
 *   "sticky" parameters are applicable to `ZSTD_compress2()` and `ZSTD_compressStream*()` !
 *   __They do not apply to one-shot variants such as ZSTD_compressCCtx()__ .
 *
 *   It's possible to reset all parameters to "default" using ZSTD_CCtx_reset().
 *
 *   This API supersedes all other "advanced" API entry points in the experimental section.
 *   In the future, we expect to remove API entry points from experimental which are redundant with this API.
 */


/* Compression strategies, listed from fastest to strongest */
typedef enum { ZSTD_fast=1,
               ZSTD_dfast=2,
               ZSTD_greedy=3,
               ZSTD_lazy=4,
               ZSTD_lazy2=5,
               ZSTD_btlazy2=6,
               ZSTD_btopt=7,
               ZSTD_btultra=8,
               ZSTD_btultra2=9
               /* note : new strategies _might_ be added in the future.
                         Only the order (from fast to strong) is guaranteed */
} ZSTD_strategy;

typedef enum {

    /* compression parameters
     * Note: When compressing with a ZSTD_CDict these parameters are superseded
     * by the parameters used to construct the ZSTD_CDict.
     * See ZSTD_CCtx_refCDict() for more info (superseded-by-cdict). */
    ZSTD_c_compressionLevel=100, /* Set compression parameters according to pre-defined cLevel table.
                              * Note that exact compression parameters are dynamically determined,
                              * depending on both compression level and srcSize (when known).
                              * Default level is ZSTD_CLEVEL_DEFAULT==3.
                              * Special: value 0 means default, which is controlled by ZSTD_CLEVEL_DEFAULT.
                              * Note 1 : it's possible to pass a negative compression level.
                              * Note 2 : setting a level does not automatically set all other compression parameters
                              *   to default. Setting this will however eventually dynamically impact the compression
                              *   parameters which have not been manually set. The manually set
                              *   ones will 'stick'. */
    /* Advanced compression parameters :
     * It's possible to pin down compression parameters to some specific values.
     * In which case, these values are no longer dynamically selected by the compressor */
    ZSTD_c_windowLog=101,    /* Maximum allowed back-reference distance, expressed as power of 2.
                              * This will set a memory budget for streaming decompression,
                              * with larger values requiring more memory
                              * and typically compressing more.
                              * Must be clamped between ZSTD_WINDOWLOG_MIN and ZSTD_WINDOWLOG_MAX.
                              * Special: value 0 means "use default windowLog".
                              * Note: Using a windowLog greater than ZSTD_WINDOWLOG_LIMIT_DEFAULT
                              *       requires explicitly allowing such size at streaming decompression stage. */
    ZSTD_c_hashLog=102,      /* Size of the initial probe table, as a power of 2.
                              * Resulting memory usage is (1 << (hashLog+2)).
                              * Must be clamped between ZSTD_HASHLOG_MIN and ZSTD_HASHLOG_MAX.
                              * Larger tables improve compression ratio of strategies <= dFast,
                              * and improve speed of strategies > dFast.
                              * Special: value 0 means "use default hashLog". */
    ZSTD_c_chainLog=103,     /* Size of the multi-probe search table, as a power of 2.
                              * Resulting memory usage is (1 << (chainLog+2)).
                              * Must be clamped between ZSTD_CHAINLOG_MIN and ZSTD_CHAINLOG_MAX.
                              * Larger tables result in better and slower compression.
                              * This parameter is useless for "fast" strategy.
                              * It's still useful when using "dfast" strategy,
                              * in which case it defines a secondary probe table.
                              * Special: value 0 means "use default chainLog". */
    ZSTD_c_searchLog=104,    /* Number of search attempts, as a power of 2.
                              * More attempts result in better and slower compression.
                              * This parameter is useless for "fast" and "dFast" strategies.
                              * Special: value 0 means "use default searchLog". */
    ZSTD_c_minMatch=105,     /* Minimum size of searched matches.
                              * Note that Zstandard can still find matches of smaller size,
                              * it just tweaks its search algorithm to look for this size and larger.
                              * Larger values increase compression and decompression speed, but decrease ratio.
                              * Must be clamped between ZSTD_MINMATCH_MIN and ZSTD_MINMATCH_MAX.
                              * Note that currently, for all strategies < btopt, effective minimum is 4.
                              *                    , for all strategies > fast, effective maximum is 6.
                              * Special: value 0 means "use default minMatchLength". */
    ZSTD_c_targetLength=106, /* Impact of this field depends on strategy.
                              * For strategies btopt, btultra & btultra2:
                              *     Length of Match considered "good enough" to stop search.
                              *     Larger values make compression stronger, and slower.
                              * For strategy fast:
                              *     Distance between match sampling.
                              *     Larger values make compression faster, and weaker.
                              * Special: value 0 means "use default targetLength". */
    ZSTD_c_strategy=107,     /* See ZSTD_strategy enum definition.
                              * The higher the value of selected strategy, the more complex it is,
                              * resulting in stronger and slower compression.
                              * Special: value 0 means "use default strategy". */

    ZSTD_c_targetCBlockSize=130, /* v1.5.6+
                                  * Attempts to fit compressed block size into approximately targetCBlockSize.
                                  * Bound by ZSTD_TARGETCBLOCKSIZE_MIN and ZSTD_TARGETCBLOCKSIZE_MAX.
                                  * Note that it's not a guarantee, just a convergence target (default:0).
                                  * No target when targetCBlockSize == 0.
                                  * This is helpful in low bandwidth streaming environments to improve end-to-end latency,
                                  * when a client can make use of partial documents (a prominent example being Chrome).
                                  * Note: this parameter is stable since v1.5.6.
                                  * It was present as an experimental parameter in earlier versions,
                                  * but it's not recommended using it with earlier library versions
                                  * due to massive performance regressions.
                                  */
    /* LDM mode parameters */
    ZSTD_c_enableLongDistanceMatching=160, /* Enable long distance matching.
                                     * This parameter is designed to improve compression ratio
                                     * for large inputs, by finding large matches at long distance.
                                     * It increases memory usage and window size.
                                     * Note: enabling this parameter increases default ZSTD_c_windowLog to 128 MB
                                     * except when expressly set to a different value.
                                     * Note: will be enabled by default if ZSTD_c_windowLog >= 128 MB and
                                     * compression strategy >= ZSTD_btopt (== compression level 16+) */
    ZSTD_c_ldmHashLog=161,   /* Size of the table for long distance matching, as a power of 2.
                              * Larger values increase memory usage and compression ratio,
                              * but decrease compression speed.
                              * Must be clamped between ZSTD_HASHLOG_MIN and ZSTD_HASHLOG_MAX
                              * default: windowlog - 7.
                              * Special: value 0 means "automatically determine hashlog". */
    ZSTD_c_ldmMinMatch=162,  /* Minimum match size for long distance matcher.
                              * Larger/too small values usually decrease compression ratio.
                              * Must be clamped between ZSTD_LDM_MINMATCH_MIN and ZSTD_LDM_MINMATCH_MAX.
                              * Special: value 0 means "use default value" (default: 64). */
    ZSTD_c_ldmBucketSizeLog=163, /* Log size of each bucket in the LDM hash table for collision resolution.
                              * Larger values improve collision resolution but decrease compression speed.
                              * The maximum value is ZSTD_LDM_BUCKETSIZELOG_MAX.
                              * Special: value 0 means "use default value" (default: 3). */
    ZSTD_c_ldmHashRateLog=164, /* Frequency of inserting/looking up entries into the LDM hash table.
                              * Must be clamped between 0 and (ZSTD_WINDOWLOG_MAX - ZSTD_HASHLOG_MIN).
                              * Default is MAX(0, (windowLog - ldmHashLog)), optimizing hash table usage.
                              * Larger values improve compression speed.
                              * Deviating far from default value will likely result in a compression ratio decrease.
                              * Special: value 0 means "automatically determine hashRateLog". */

    /* frame parameters */
    ZSTD_c_contentSizeFlag=200, /* Content size will be written into frame header _whenever known_ (default:1)
                              * Content size must be known at the beginning of compression.
                              * This is automatically the case when using ZSTD_compress2(),
                              * For streaming scenarios, content size must be provided with ZSTD_CCtx_setPledgedSrcSize() */
    ZSTD_c_checksumFlag=201, /* A 32-bits checksum of content is written at end of frame (default:0) */
    ZSTD_c_dictIDFlag=202,   /* When applicable, dictionary's ID is written into frame header (default:1) */

    /* multi-threading parameters */
    /* These parameters are only active if multi-threading is enabled (compiled with build macro ZSTD_MULTITHREAD).
     * Otherwise, trying to set any other value than default (0) will be a no-op and return an error.
     * In a situation where it's unknown if the linked library supports multi-threading or not,
     * setting ZSTD_c_nbWorkers to any value >= 1 and consulting the return value provides a quick way to check this property.
     */
    ZSTD_c_nbWorkers=400,    /* Select how many threads will be spawned to compress in parallel.
                              * When nbWorkers >= 1, triggers asynchronous mode when invoking ZSTD_compressStream*() :
                              * ZSTD_compressStream*() consumes input and flush output if possible, but immediately gives back control to caller,
                              * while compression is performed in parallel, within worker thread(s).
                              * (note : a strong exception to this rule is when first invocation of ZSTD_compressStream2() sets ZSTD_e_end :
                              *  in which case, ZSTD_compressStream2() delegates to ZSTD_compress2(), which is always a blocking call).
                              * More workers improve speed, but also increase memory usage.
                              * Default value is `0`, aka "single-threaded mode" : no worker is spawned,
                              * compression is performed inside Caller's thread, and all invocations are blocking */
    ZSTD_c_jobSize=401,      /* Size of a compression job. This value is enforced only when nbWorkers >= 1.
                              * Each compression job is completed in parallel, so this value can indirectly impact the nb of active threads.
                              * 0 means default, which is dynamically determined based on compression parameters.
                              * Job size must be a minimum of overlap size, or ZSTDMT_JOBSIZE_MIN (= 512 KB), whichever is largest.
                              * The minimum size is automatically and transparently enforced. */
    ZSTD_c_overlapLog=402,   /* Control the overlap size, as a fraction of window size.
                              * The overlap size is an amount of data reloaded from previous job at the beginning of a new job.
                              * It helps preserve compression ratio, while each job is compressed in parallel.
                              * This value is enforced only when nbWorkers >= 1.
                              * Larger values increase compression ratio, but decrease speed.
                              * Possible values range from 0 to 9 :
                              * - 0 means "default" : value will be determined by the library, depending on strategy
                              * - 1 means "no overlap"
                              * - 9 means "full overlap", using a full window size.
                              * Each intermediate rank increases/decreases load size by a factor 2 :
                              * 9: full window;  8: w/2;  7: w/4;  6: w/8;  5:w/16;  4: w/32;  3:w/64;  2:w/128;  1:no overlap;  0:default
                              * default value varies between 6 and 9, depending on strategy */

    /* note : additional experimental parameters are also available
     * within the experimental section of the API.
     * At the time of this writing, they include :
     * ZSTD_c_rsyncable
     * ZSTD_c_format
     * ZSTD_c_forceMaxWindow
     * ZSTD_c_forceAttachDict
     * ZSTD_c_literalCompressionMode
     * ZSTD_c_srcSizeHint
     * ZSTD_c_enableDedicatedDictSearch
     * ZSTD_c_stableInBuffer
     * ZSTD_c_stableOutBuffer
     * ZSTD_c_blockDelimiters
     * ZSTD_c_validateSequences
     * ZSTD_c_blockSplitterLevel
     * ZSTD_c_splitAfterSequences
     * ZSTD_c_useRowMatchFinder
     * ZSTD_c_prefetchCDictTables
     * ZSTD_c_enableSeqProducerFallback
     * ZSTD_c_maxBlockSize
     * Because they are not stable, it's necessary to define ZSTD_STATIC_LINKING_ONLY to access them.
     * note : never ever use experimentalParam? names directly;
     *        also, the enums values themselves are unstable and can still change.
     */
     ZSTD_c_experimentalParam1=500,
     ZSTD_c_experimentalParam2=10,
     ZSTD_c_experimentalParam3=1000,
     ZSTD_c_experimentalParam4=1001,
     ZSTD_c_experimentalParam5=1002,
     /* was ZSTD_c_experimentalParam6=1003; is now ZSTD_c_targetCBlockSize */
     ZSTD_c_experimentalParam7=1004,
     ZSTD_c_experimentalParam8=1005,
     ZSTD_c_experimentalParam9=1006,
     ZSTD_c_experimentalParam10=1007,
     ZSTD_c_experimentalParam11=1008,
     ZSTD_c_experimentalParam12=1009,
     ZSTD_c_experimentalParam13=1010,
     ZSTD_c_experimentalParam14=1011,
     ZSTD_c_experimentalParam15=1012,
     ZSTD_c_experimentalParam16=1013,
     ZSTD_c_experimentalParam17=1014,
     ZSTD_c_experimentalParam18=1015,
     ZSTD_c_experimentalParam19=1016,
     ZSTD_c_experimentalParam20=1017
} ZSTD_cParameter;

typedef struct {
    size_t error;
    int lowerBound;
    int upperBound;
} ZSTD_bounds;

/*! ZSTD_cParam_getBounds() :
 *  All parameters must belong to an interval with lower and upper bounds,
 *  otherwise they will either trigger an error or be automatically clamped.
 * @return : a structure, ZSTD_bounds, which contains
 *         - an error status field, which must be tested using ZSTD_isError()
 *         - lower and upper bounds, both inclusive
 */
ZSTDLIB_API ZSTD_bounds ZSTD_cParam_getBounds(ZSTD_cParameter cParam);

/*! ZSTD_CCtx_setParameter() :
 *  Set one compression parameter, selected by enum ZSTD_cParameter.
 *  All parameters have valid bounds. Bounds can be queried using ZSTD_cParam_getBounds().
 *  Providing a value beyond bound will either clamp it, or trigger an error (depending on parameter).
 *  Setting a parameter is generally only possible during frame initialization (before starting compression).
 *  Exception : when using multi-threading mode (nbWorkers >= 1),
 *              the following parameters can be updated _during_ compression (within same frame):
 *              => compressionLevel, hashLog, chainLog, searchLog, minMatch, targetLength and strategy.
 *              new parameters will be active for next job only (after a flush()).
 * @return : an error code (which can be tested using ZSTD_isError()).
 */
ZSTDLIB_API size_t ZSTD_CCtx_setParameter(ZSTD_CCtx* cctx, ZSTD_cParameter param, int value);

/*! ZSTD_CCtx_setPledgedSrcSize() :
 *  Total input data size to be compressed as a single frame.
 *  Value will be written in frame header, unless if explicitly forbidden using ZSTD_c_contentSizeFlag.
 *  This value will also be controlled at end of frame, and trigger an error if not respected.
 * @result : 0, or an error code (which can be tested with ZSTD_isError()).
 *  Note 1 : pledgedSrcSize==0 actually means zero, aka an empty frame.
 *           In order to mean "unknown content size", pass constant ZSTD_CONTENTSIZE_UNKNOWN.
 *           ZSTD_CONTENTSIZE_UNKNOWN is default value for any new frame.
 *  Note 2 : pledgedSrcSize is only valid once, for the next frame.
 *           It's discarded at the end of the frame, and replaced by ZSTD_CONTENTSIZE_UNKNOWN.
 *  Note 3 : Whenever all input data is provided and consumed in a single round,
 *           for example with ZSTD_compress2(),
 *           or invoking immediately ZSTD_compressStream2(,,,ZSTD_e_end),
 *           this value is automatically overridden by srcSize instead.
 */
ZSTDLIB_API size_t ZSTD_CCtx_setPledgedSrcSize(ZSTD_CCtx* cctx, unsigned long long pledgedSrcSize);

typedef enum {
    ZSTD_reset_session_only = 1,
    ZSTD_reset_parameters = 2,
    ZSTD_reset_session_and_parameters = 3
} ZSTD_ResetDirective;

/*! ZSTD_CCtx_reset() :
 *  There are 2 different things that can be reset, independently or jointly :
 *  - The session : will stop compressing current frame, and make CCtx ready to start a new one.
 *                  Useful after an error, or to interrupt any ongoing compression.
 *                  Any internal data not yet flushed is cancelled.
 *                  Compression parameters and dictionary remain unchanged.
 *                  They will be used to compress next frame.
 *                  Resetting session never fails.
 *  - The parameters : changes all parameters back to "default".
 *                  This also removes any reference to any dictionary or external sequence producer.
 *                  Parameters can only be changed between 2 sessions (i.e. no compression is currently ongoing)
 *                  otherwise the reset fails, and function returns an error value (which can be tested using ZSTD_isError())
 *  - Both : similar to resetting the session, followed by resetting parameters.
 */
ZSTDLIB_API size_t ZSTD_CCtx_reset(ZSTD_CCtx* cctx, ZSTD_ResetDirective reset);

/*! ZSTD_compress2() :
 *  Behave the same as ZSTD_compressCCtx(), but compression parameters are set using the advanced API.
 *  (note that this entry point doesn't even expose a compression level parameter).
 *  ZSTD_compress2() always starts a new frame.
 *  Should cctx hold data from a previously unfinished frame, everything about it is forgotten.
 *  - Compression parameters are pushed into CCtx before starting compression, using ZSTD_CCtx_set*()
 *  - The function is always blocking, returns when compression is completed.
 *  NOTE: Providing `dstCapacity >= ZSTD_compressBound(srcSize)` guarantees that zstd will have
 *        enough space to successfully compress the data, though it is possible it fails for other reasons.
 * @return : compressed size written into `dst` (<= `dstCapacity),
 *           or an error code if it fails (which can be tested using ZSTD_isError()).
 */
ZSTDLIB_API size_t ZSTD_compress2( ZSTD_CCtx* cctx,
                                   void* dst, size_t dstCapacity,
                             const void* src, size_t srcSize);


/***********************************************
*  Advanced decompression API (Requires v1.4.0+)
************************************************/

/* The advanced API pushes parameters one by one into an existing DCtx context.
 * Parameters are sticky, and remain valid for all following frames
 * using the same DCtx context.
 * It's possible to reset parameters to default values using ZSTD_DCtx_reset().
 * Note : This API is compatible with existing ZSTD_decompressDCtx() and ZSTD_decompressStream().
 *        Therefore, no new decompression function is necessary.
 */

typedef enum {

    ZSTD_d_windowLogMax=100, /* Select a size limit (in power of 2) beyond which
                              * the streaming API will refuse to allocate memory buffer
                              * in order to protect the host from unreasonable memory requirements.
                              * This parameter is only useful in streaming mode, since no internal buffer is allocated in single-pass mode.
                              * By default, a decompression context accepts window sizes <= (1 << ZSTD_WINDOWLOG_LIMIT_DEFAULT).
                              * Special: value 0 means "use default maximum windowLog". */

    /* note : additional experimental parameters are also available
     * within the experimental section of the API.
     * At the time of this writing, they include :
     * ZSTD_d_format
     * ZSTD_d_stableOutBuffer
     * ZSTD_d_forceIgnoreChecksum
     * ZSTD_d_refMultipleDDicts
     * ZSTD_d_disableHuffmanAssembly
     * ZSTD_d_maxBlockSize
     * Because they are not stable, it's necessary to define ZSTD_STATIC_LINKING_ONLY to access them.
     * note : never ever use experimentalParam? names directly
     */
     ZSTD_d_experimentalParam1=1000,
     ZSTD_d_experimentalParam2=1001,
     ZSTD_d_experimentalParam3=1002,
     ZSTD_d_experimentalParam4=1003,
     ZSTD_d_experimentalParam5=1004,
     ZSTD_d_experimentalParam6=1005

} ZSTD_dParameter;

/*! ZSTD_dParam_getBounds() :
 *  All parameters must belong to an interval with lower and upper bounds,
 *  otherwise they will either trigger an error or be automatically clamped.
 * @return : a structure, ZSTD_bounds, which contains
 *         - an error status field, which must be tested using ZSTD_isError()
 *         - both lower and upper bounds, inclusive
 */
ZSTDLIB_API ZSTD_bounds ZSTD_dParam_getBounds(ZSTD_dParameter dParam);

/*! ZSTD_DCtx_setParameter() :
 *  Set one compression parameter, selected by enum ZSTD_dParameter.
 *  All parameters have valid bounds. Bounds can be queried using ZSTD_dParam_getBounds().
 *  Providing a value beyond bound will either clamp it, or trigger an error (depending on parameter).
 *  Setting a parameter is only possible during frame initialization (before starting decompression).
 * @return : 0, or an error code (which can be tested using ZSTD_isError()).
 */
ZSTDLIB_API size_t ZSTD_DCtx_setParameter(ZSTD_DCtx* dctx, ZSTD_dParameter param, int value);

/*! ZSTD_DCtx_reset() :
 *  Return a DCtx to clean state.
 *  Session and parameters can be reset jointly or separately.
 *  Parameters can only be reset when no active frame is being decompressed.
 * @return : 0, or an error code, which can be tested with ZSTD_isError()
 */
ZSTDLIB_API size_t ZSTD_DCtx_reset(ZSTD_DCtx* dctx, ZSTD_ResetDirective reset);


/****************************
*  Streaming
****************************/

typedef struct ZSTD_inBuffer_s {
  const void* src;    /**< start of input buffer */
  size_t size;        /**< size of input buffer */
  size_t pos;         /**< position where reading stopped. Will be updated. Necessarily 0 <= pos <= size */
} ZSTD_inBuffer;

typedef struct ZSTD_outBuffer_s {
  void*  dst;         /**< start of output buffer */
  size_t size;        /**< size of output buffer */
  size_t pos;         /**< position where writing stopped. Will be updated. Necessarily 0 <= pos <= size */
} ZSTD_outBuffer;



/*-***********************************************************************
*  Streaming compression - HowTo
*
*  A ZSTD_CStream object is required to track streaming operation.
*  Use ZSTD_createCStream() and ZSTD_freeCStream() to create/release resources.
*  ZSTD_CStream objects can be reused multiple times on consecutive compression operations.
*  It is recommended to reuse ZSTD_CStream since it will play nicer with system's memory, by re-using already allocated memory.
*
*  For parallel execution, use one separate ZSTD_CStream per thread.
*
*  note : since v1.3.0, ZSTD_CStream and ZSTD_CCtx are the same thing.
*
*  Parameters are sticky : when starting a new compression on the same context,
*  it will reuse the same sticky parameters as previous compression session.
*  When in doubt, it's recommended to fully initialize the context before usage.
*  Use ZSTD_CCtx_reset() to reset the context and ZSTD_CCtx_setParameter(),
*  ZSTD_CCtx_setPledgedSrcSize(), or ZSTD_CCtx_loadDictionary() and friends to
*  set more specific parameters, the pledged source size, or load a dictionary.
*
*  Use ZSTD_compressStream2() with ZSTD_e_continue as many times as necessary to
*  consume input stream. The function will automatically update both `pos`
*  fields within `input` and `output`.
*  Note that the function may not consume the entire input, for example, because
*  the output buffer is already full, in which case `input.pos < input.size`.
*  The caller must check if input has been entirely consumed.
*  If not, the caller must make some room to receive more compressed data,
*  and then present again remaining input data.
*  note: ZSTD_e_continue is guaranteed to make some forward progress when called,
*        but doesn't guarantee maximal forward progress. This is especially relevant
*        when compressing with multiple threads. The call won't block if it can
*        consume some input, but if it can't it will wait for some, but not all,
*        output to be flushed.
* @return : provides a minimum amount of data remaining to be flushed from internal buffers
*           or an error code, which can be tested using ZSTD_isError().
*
*  At any moment, it's possible to flush whatever data might remain stuck within internal buffer,
*  using ZSTD_compressStream2() with ZSTD_e_flush. `output->pos` will be updated.
*  Note that, if `output->size` is too small, a single invocation with ZSTD_e_flush might not be enough (return code > 0).
*  In which case, make some room to receive more compressed data, and call again ZSTD_compressStream2() with ZSTD_e_flush.
*  You must continue calling ZSTD_compressStream2() with ZSTD_e_flush until it returns 0, at which point you can change the
*  operation.
*  note: ZSTD_e_flush will flush as much output as possible, meaning when compressing with multiple threads, it will
*        block until the flush is complete or the output buffer is full.
*  @return : 0 if internal buffers are entirely flushed,
*            >0 if some data still present within internal buffer (the value is minimal estimation of remaining size),
*            or an error code, which can be tested using ZSTD_isError().
*
*  Calling ZSTD_compressStream2() with ZSTD_e_end instructs to finish a frame.
*  It will perform a flush and write frame epilogue.
*  The epilogue is required for decoders to consider a frame completed.
*  flush operation is the same, and follows same rules as calling ZSTD_compressStream2() with ZSTD_e_flush.
*  You must continue calling ZSTD_compressStream2() with ZSTD_e_end until it returns 0, at which point you are free to
*  start a new frame.
*  note: ZSTD_e_end will flush as much output as possible, meaning when compressing with multiple threads, it will
*        block until the flush is complete or the output buffer is full.
*  @return : 0 if frame fully completed and fully flushed,
*            >0 if some data still present within internal buffer (the value is minimal estimation of remaining size),
*            or an error code, which can be tested using ZSTD_isError().
*
* *******************************************************************/

typedef ZSTD_CCtx ZSTD_CStream;  /**< CCtx and CStream are now effectively same object (>= v1.3.0) */
                                 /* Continue to distinguish them for compatibility with older versions <= v1.2.0 */
/*===== ZSTD_CStream management functions =====*/
ZSTDLIB_API ZSTD_CStream* ZSTD_createCStream(void);
ZSTDLIB_API size_t ZSTD_freeCStream(ZSTD_CStream* zcs);  /* accept NULL pointer */

/*===== Streaming compression functions =====*/
typedef enum {
    ZSTD_e_continue=0, /* collect more data, encoder decides when to output compressed result, for optimal compression ratio */
    ZSTD_e_flush=1,    /* flush any data provided so far,
                        * it creates (at least) one new block, that can be decoded immediately on reception;
                        * frame will continue: any future data can still reference previously compressed data, improving compression.
                        * note : multithreaded compression will block to flush as much output as possible. */
    ZSTD_e_end=2       /* flush any remaining data _and_ close current frame.
                        * note that frame is only closed after compressed data is fully flushed (return value == 0).
                        * After that point, any additional data starts a new frame.
                        * note : each frame is independent (does not reference any content from previous frame).
                        : note : multithreaded compression will block to flush as much output as possible. */
} ZSTD_EndDirective;

/*! ZSTD_compressStream2() : Requires v1.4.0+
 *  Behaves about the same as ZSTD_compressStream, with additional control on end directive.
 *  - Compression parameters are pushed into CCtx before starting compression, using ZSTD_CCtx_set*()
 *  - Compression parameters cannot be changed once compression is started (save a list of exceptions in multi-threading mode)
 *  - output->pos must be <= dstCapacity, input->pos must be <= srcSize
 *  - output->pos and input->pos will be updated. They are guaranteed to remain below their respective limit.
 *  - endOp must be a valid directive
 *  - When nbWorkers==0 (default), function is blocking : it completes its job before returning to caller.
 *  - When nbWorkers>=1, function is non-blocking : it copies a portion of input, distributes jobs to internal worker threads, flush to output whatever is available,
 *                                                  and then immediately returns, just indicating that there is some data remaining to be flushed.
 *                                                  The function nonetheless guarantees forward progress : it will return only after it reads or write at least 1+ byte.
 *  - Exception : if the first call requests a ZSTD_e_end directive and provides enough dstCapacity, the function delegates to ZSTD_compress2() which is always blocking.
 *  - @return provides a minimum amount of data remaining to be flushed from internal buffers
 *            or an error code, which can be tested using ZSTD_isError().
 *            if @return != 0, flush is not fully completed, there is still some data left within internal buffers.
 *            This is useful for ZSTD_e_flush, since in this case more flushes are necessary to empty all buffers.
 *            For ZSTD_e_end, @return == 0 when internal buffers are fully flushed and frame is completed.
 *  - after a ZSTD_e_end directive, if internal buffer is not fully flushed (@return != 0),
 *            only ZSTD_e_end or ZSTD_e_flush operations are allowed.
 *            Before starting a new compression job, or changing compression parameters,
 *            it is required to fully flush internal buffers.
 *  - note: if an operation ends with an error, it may leave @cctx in an undefined state.
 *          Therefore, it's UB to invoke ZSTD_compressStream2() of ZSTD_compressStream() on such a state.
 *          In order to be re-employed after an error, a state must be reset,
 *          which can be done explicitly (ZSTD_CCtx_reset()),
 *          or is sometimes implied by methods starting a new compression job (ZSTD_initCStream(), ZSTD_compressCCtx())
 */
ZSTDLIB_API size_t ZSTD_compressStream2( ZSTD_CCtx* cctx,
                                         ZSTD_outBuffer* output,
                                         ZSTD_inBuffer* input,
                                         ZSTD_EndDirective endOp);


/* These buffer sizes are softly recommended.
 * They are not required : ZSTD_compressStream*() happily accepts any buffer size, for both input and output.
 * Respecting the recommended size just makes it a bit easier for ZSTD_compressStream*(),
 * reducing the amount of memory shuffling and buffering, resulting in minor performance savings.
 *
 * However, note that these recommendations are from the perspective of a C caller program.
 * If the streaming interface is invoked from some other language,
 * especially managed ones such as Java or Go, through a foreign function interface such as jni or cgo,
 * a major performance rule is to reduce crossing such interface to an absolute minimum.
 * It's not rare that performance ends being spent more into the interface, rather than compression itself.
 * In which cases, prefer using large buffers, as large as practical,
 * for both input and output, to reduce the nb of roundtrips.
 */
ZSTDLIB_API size_t ZSTD_CStreamInSize(void);    /**< recommended size for input buffer */
ZSTDLIB_API size_t ZSTD_CStreamOutSize(void);   /**< recommended size for output buffer. Guarantee to successfully flush at least one complete compressed block. */


/* *****************************************************************************
 * This following is a legacy streaming API, available since v1.0+ .
 * It can be replaced by ZSTD_CCtx_reset() and ZSTD_compressStream2().
 * It is redundant, but remains fully supported.
 ******************************************************************************/

/*!
 * Equivalent to:
 *
 *     ZSTD_CCtx_reset(zcs, ZSTD_reset_session_only);
 *     ZSTD_CCtx_refCDict(zcs, NULL); // clear the dictionary (if any)
 *     ZSTD_CCtx_setParameter(zcs, ZSTD_c_compressionLevel, compressionLevel);
 *
 * Note that ZSTD_initCStream() clears any previously set dictionary. Use the new API
 * to compress with a dictionary.
 */
ZSTDLIB_API size_t ZSTD_initCStream(ZSTD_CStream* zcs, int compressionLevel);
/*!
 * Alternative for ZSTD_compressStream2(zcs, output, input, ZSTD_e_continue).
 * NOTE: The return value is different. ZSTD_compressStream() returns a hint for
 * the next read size (if non-zero and not an error). ZSTD_compressStream2()
 * returns the minimum nb of bytes left to flush (if non-zero and not an error).
 */
ZSTDLIB_API size_t ZSTD_compressStream(ZSTD_CStream* zcs, ZSTD_outBuffer* output, ZSTD_inBuffer* input);
/*! Equivalent to ZSTD_compressStream2(zcs, output, &emptyInput, ZSTD_e_flush). */
ZSTDLIB_API size_t ZSTD_flushStream(ZSTD_CStream* zcs, ZSTD_outBuffer* output);
/*! Equivalent to ZSTD_compressStream2(zcs, output, &emptyInput, ZSTD_e_end). */
ZSTDLIB_API size_t ZSTD_endStream(ZSTD_CStream* zcs, ZSTD_outBuffer* output);


/*-***************************************************************************
*  Streaming decompression - HowTo
*
*  A ZSTD_DStream object is required to track streaming operations.
*  Use ZSTD_createDStream() and ZSTD_freeDStream() to create/release resources.
*  ZSTD_DStream objects can be re-employed multiple times.
*
*  Use ZSTD_initDStream() to start a new decompression operation.
* @return : recommended first input size
*  Alternatively, use advanced API to set specific properties.
*
*  Use ZSTD_decompressStream() repetitively to consume your input.
*  The function will update both `pos` fields.
*  If `input.pos < input.size`, some input has not been consumed.
*  It's up to the caller to present again remaining data.
*
*  The function tries to flush all data decoded immediately, respecting output buffer size.
*  If `output.pos < output.size`, decoder has flushed everything it could.
*
*  However, when `output.pos == output.size`, it's more difficult to know.
*  If @return > 0, the frame is not complete, meaning
*  either there is still some data left to flush within internal buffers,
*  or there is more input to read to complete the frame (or both).
*  In which case, call ZSTD_decompressStream() again to flush whatever remains in the buffer.
*  Note : with no additional input provided, amount of data flushed is necessarily <= ZSTD_BLOCKSIZE_MAX.
* @return : 0 when a frame is completely decoded and fully flushed,
*        or an error code, which can be tested using ZSTD_isError(),
*        or any other value > 0, which means there is still some decoding or flushing to do to complete current frame :
*                                the return value is a suggested next input size (just a hint for better latency)
*                                that will never request more than the remaining content of the compressed frame.
* *******************************************************************************/

typedef ZSTD_DCtx ZSTD_DStream;  /**< DCtx and DStream are now effectively same object (>= v1.3.0) */
                                 /* For compatibility with versions <= v1.2.0, prefer differentiating them. */
/*===== ZSTD_DStream management functions =====*/
ZSTDLIB_API ZSTD_DStream* ZSTD_createDStream(void);
ZSTDLIB_API size_t ZSTD_freeDStream(ZSTD_DStream* zds);  /* accept NULL pointer */

/*===== Streaming decompression functions =====*/

/*! ZSTD_initDStream() :
 * Initialize/reset DStream state for new decompression operation.
 * Call before new decompression operation using same DStream.
 *
 * Note : This function is redundant with the advanced API and equivalent to:
 *     ZSTD_DCtx_reset(zds, ZSTD_reset_session_only);
 *     ZSTD_DCtx_refDDict(zds, NULL);
 */
ZSTDLIB_API size_t ZSTD_initDStream(ZSTD_DStream* zds);

/*! ZSTD_decompressStream() :
 * Streaming decompression function.
 * Call repetitively to consume full input updating it as necessary.
 * Function will update both input and output `pos` fields exposing current state via these fields:
 * - `input.pos < input.size`, some input remaining and caller should provide remaining input
 *   on the next call.
 * - `output.pos < output.size`, decoder flushed internal output buffer.
 * - `output.pos == output.size`, unflushed data potentially present in the internal buffers,
 *   check ZSTD_decompressStream() @return value,
 *   if > 0, invoke it again to flush remaining data to output.
 * Note : with no additional input, amount of data flushed <= ZSTD_BLOCKSIZE_MAX.
 *
 * @return : 0 when a frame is completely decoded and fully flushed,
 *           or an error code, which can be tested using ZSTD_isError(),
 *           or any other value > 0, which means there is some decoding or flushing to do to complete current frame.
 *
 * Note: when an operation returns with an error code, the @zds state may be left in undefined state.
 *       It's UB to invoke `ZSTD_decompressStream()` on such a state.
 *       In order to re-use such a state, it must be first reset,
 *       which can be done explicitly (`ZSTD_DCtx_reset()`),
 *       or is implied for operations starting some new decompression job (`ZSTD_initDStream`, `ZSTD_decompressDCtx()`, `ZSTD_decompress_usingDict()`)
 */
ZSTDLIB_API size_t ZSTD_decompressStream(ZSTD_DStream* zds, ZSTD_outBuffer* output, ZSTD_inBuffer* input);

ZSTDLIB_API size_t ZSTD_DStreamInSize(void);    /*!< recommended size for input buffer */
ZSTDLIB_API size_t ZSTD_DStreamOutSize(void);   /*!< recommended size for output buffer. Guarantee to successfully flush at least one complete block in all circumstances. */


/**************************
*  Simple dictionary API
***************************/
/*! ZSTD_compress_usingDict() :
 *  Compression at an explicit compression level using a Dictionary.
 *  A dictionary can be any arbitrary data segment (also called a prefix),
 *  or a buffer with specified information (see zdict.h).
 *  Note : This function loads the dictionary, resulting in significant startup delay.
 *         It's intended for a dictionary used only once.
 *  Note 2 : When `dict == NULL || dictSize < 8` no dictionary is used. */
ZSTDLIB_API size_t ZSTD_compress_usingDict(ZSTD_CCtx* ctx,
                                           void* dst, size_t dstCapacity,
                                     const void* src, size_t srcSize,
                                     const void* dict,size_t dictSize,
                                           int compressionLevel);

/*! ZSTD_decompress_usingDict() :
 *  Decompression using a known Dictionary.
 *  Dictionary must be identical to the one used during compression.
 *  Note : This function loads the dictionary, resulting in significant startup delay.
 *         It's intended for a dictionary used only once.
 *  Note : When `dict == NULL || dictSize < 8` no dictionary is used. */
ZSTDLIB_API size_t ZSTD_decompress_usingDict(ZSTD_DCtx* dctx,
                                             void* dst, size_t dstCapacity,
                                       const void* src, size_t srcSize,
                                       const void* dict,size_t dictSize);


/***********************************
 *  Bulk processing dictionary API
 **********************************/
typedef struct ZSTD_CDict_s ZSTD_CDict;

/*! ZSTD_createCDict() :
 *  When compressing multiple messages or blocks using the same dictionary,
 *  it's recommended to digest the dictionary only once, since it's a costly operation.
 *  ZSTD_createCDict() will create a state from digesting a dictionary.
 *  The resulting state can be used for future compression operations with very limited startup cost.
 *  ZSTD_CDict can be created once and shared by multiple threads concurrently, since its usage is read-only.
 * @dictBuffer can be released after ZSTD_CDict creation, because its content is copied within CDict.
 *  Note 1 : Consider experimental function `ZSTD_createCDict_byReference()` if you prefer to not duplicate @dictBuffer content.
 *  Note 2 : A ZSTD_CDict can be created from an empty @dictBuffer,
 *      in which case the only thing that it transports is the @compressionLevel.
 *      This can be useful in a pipeline featuring ZSTD_compress_usingCDict() exclusively,
 *      expecting a ZSTD_CDict parameter with any data, including those without a known dictionary. */
ZSTDLIB_API ZSTD_CDict* ZSTD_createCDict(const void* dictBuffer, size_t dictSize,
                                         int compressionLevel);

/*! ZSTD_freeCDict() :
 *  Function frees memory allocated by ZSTD_createCDict().
 *  If a NULL pointer is passed, no operation is performed. */
ZSTDLIB_API size_t      ZSTD_freeCDict(ZSTD_CDict* CDict);

/*! ZSTD_compress_usingCDict() :
 *  Compression using a digested Dictionary.
 *  Recommended when same dictionary is used multiple times.
 *  Note : compression level is _decided at dictionary creation time_,
 *     and frame parameters are hardcoded (dictID=yes, contentSize=yes, checksum=no) */
ZSTDLIB_API size_t ZSTD_compress_usingCDict(ZSTD_CCtx* cctx,
                                            void* dst, size_t dstCapacity,
                                      const void* src, size_t srcSize,
                                      const ZSTD_CDict* cdict);


typedef struct ZSTD_DDict_s ZSTD_DDict;

/*! ZSTD_createDDict() :
 *  Create a digested dictionary, ready to start decompression operation without startup delay.
 *  dictBuffer can be released after DDict creation, as its content is copied inside DDict. */
ZSTDLIB_API ZSTD_DDict* ZSTD_createDDict(const void* dictBuffer, size_t dictSize);

/*! ZSTD_freeDDict() :
 *  Function frees memory allocated with ZSTD_createDDict()
 *  If a NULL pointer is passed, no operation is performed. */
ZSTDLIB_API size_t      ZSTD_freeDDict(ZSTD_DDict* ddict);

/*! ZSTD_decompress_usingDDict() :
 *  Decompression using a digested Dictionary.
 *  Recommended when same dictionary is used multiple times. */
ZSTDLIB_API size_t ZSTD_decompress_usingDDict(ZSTD_DCtx* dctx,
                                              void* dst, size_t dstCapacity,
                                        const void* src, size_t srcSize,
                                        const ZSTD_DDict* ddict);


/********************************
 *  Dictionary helper functions
 *******************************/

/*! ZSTD_getDictID_fromDict() : Requires v1.4.0+
 *  Provides the dictID stored within dictionary.
 *  if @return == 0, the dictionary is not conformant with Zstandard specification.
 *  It can still be loaded, but as a content-only dictionary. */
ZSTDLIB_API unsigned ZSTD_getDictID_fromDict(const void* dict, size_t dictSize);

/*! ZSTD_getDictID_fromCDict() : Requires v1.5.0+
 *  Provides the dictID of the dictionary loaded into `cdict`.
 *  If @return == 0, the dictionary is not conformant to Zstandard specification, or empty.
 *  Non-conformant dictionaries can still be loaded, but as content-only dictionaries. */
ZSTDLIB_API unsigned ZSTD_getDictID_fromCDict(const ZSTD_CDict* cdict);

/*! ZSTD_getDictID_fromDDict() : Requires v1.4.0+
 *  Provides the dictID of the dictionary loaded into `ddict`.
 *  If @return == 0, the dictionary is not conformant to Zstandard specification, or empty.
 *  Non-conformant dictionaries can still be loaded, but as content-only dictionaries. */
ZSTDLIB_API unsigned ZSTD_getDictID_fromDDict(const ZSTD_DDict* ddict);

/*! ZSTD_getDictID_fromFrame() : Requires v1.4.0+
 *  Provides the dictID required to decompressed the frame stored within `src`.
 *  If @return == 0, the dictID could not be decoded.
 *  This could for one of the following reasons :
 *  - The frame does not require a dictionary to be decoded (most common case).
 *  - The frame was built with dictID intentionally removed. Whatever dictionary is necessary is a hidden piece of information.
 *    Note : this use case also happens when using a non-conformant dictionary.
 *  - `srcSize` is too small, and as a result, the frame header could not be decoded (only possible if `srcSize < ZSTD_FRAMEHEADERSIZE_MAX`).
 *  - This is not a Zstandard frame.
 *  When identifying the exact failure cause, it's possible to use ZSTD_getFrameHeader(), which will provide a more precise error code. */
ZSTDLIB_API unsigned ZSTD_getDictID_fromFrame(const void* src, size_t srcSize);


/*******************************************************************************
 * Advanced dictionary and prefix API (Requires v1.4.0+)
 *
 * This API allows dictionaries to be used with ZSTD_compress2(),
 * ZSTD_compressStream2(), and ZSTD_decompressDCtx().
 * Dictionaries are sticky, they remain valid when same context is reused,
 * they only reset when the context is reset
 * with ZSTD_reset_parameters or ZSTD_reset_session_and_parameters.
 * In contrast, Prefixes are single-use.
 ******************************************************************************/


/*! ZSTD_CCtx_loadDictionary() : Requires v1.4.0+
 *  Create an internal CDict from `dict` buffer.
 *  Decompression will have to use same dictionary.
 * @result : 0, or an error code (which can be tested with ZSTD_isError()).
 *  Special: Loading a NULL (or 0-size) dictionary invalidates previous dictionary,
 *           meaning "return to no-dictionary mode".
 *  Note 1 : Dictionary is sticky, it will be used for all future compressed frames,
 *           until parameters are reset, a new dictionary is loaded, or the dictionary
 *           is explicitly invalidated by loading a NULL dictionary.
 *  Note 2 : Loading a dictionary involves building tables.
 *           It's also a CPU consuming operation, with non-negligible impact on latency.
 *           Tables are dependent on compression parameters, and for this reason,
 *           compression parameters can no longer be changed after loading a dictionary.
 *  Note 3 :`dict` content will be copied internally.
 *           Use experimental ZSTD_CCtx_loadDictionary_byReference() to reference content instead.
 *           In such a case, dictionary buffer must outlive its users.
 *  Note 4 : Use ZSTD_CCtx_loadDictionary_advanced()
 *           to precisely select how dictionary content must be interpreted.
 *  Note 5 : This method does not benefit from LDM (long distance mode).
 *           If you want to employ LDM on some large dictionary content,
 *           prefer employing ZSTD_CCtx_refPrefix() described below.
 */
ZSTDLIB_API size_t ZSTD_CCtx_loadDictionary(ZSTD_CCtx* cctx, const void* dict, size_t dictSize);

/*! ZSTD_CCtx_refCDict() : Requires v1.4.0+
 *  Reference a prepared dictionary, to be used for all future compressed frames.
 *  Note that compression parameters are enforced from within CDict,
 *  and supersede any compression parameter previously set within CCtx.
 *  The parameters ignored are labelled as "superseded-by-cdict" in the ZSTD_cParameter enum docs.
 *  The ignored parameters will be used again if the CCtx is returned to no-dictionary mode.
 *  The dictionary will remain valid for future compressed frames using same CCtx.
 * @result : 0, or an error code (which can be tested with ZSTD_isError()).
 *  Special : Referencing a NULL CDict means "return to no-dictionary mode".
 *  Note 1 : Currently, only one dictionary can be managed.
 *           Referencing a new dictionary effectively "discards" any previous one.
 *  Note 2 : CDict is just referenced, its lifetime must outlive its usage within CCtx. */
ZSTDLIB_API size_t ZSTD_CCtx_refCDict(ZSTD_CCtx* cctx, const ZSTD_CDict* cdict);

/*! ZSTD_CCtx_refPrefix() : Requires v1.4.0+
 *  Reference a prefix (single-usage dictionary) for next compressed frame.
 *  A prefix is **only used once**. Tables are discarded at end of frame (ZSTD_e_end).
 *  Decompression will need same prefix to properly regenerate data.
 *  Compressing with a prefix is similar in outcome as performing a diff and compressing it,
 *  but performs much faster, especially during decompression (compression speed is tunable with compression level).
 *  This method is compatible with LDM (long distance mode).
 * @result : 0, or an error code (which can be tested with ZSTD_isError()).
 *  Special: Adding any prefix (including NULL) invalidates any previous prefix or dictionary
 *  Note 1 : Prefix buffer is referenced. It **must** outlive compression.
 *           Its content must remain unmodified during compression.
 *  Note 2 : If the intention is to diff some large src data blob with some prior version of itself,
 *           ensure that the window size is large enough to contain the entire source.
 *           See ZSTD_c_windowLog.
 *  Note 3 : Referencing a prefix involves building tables, which are dependent on compression parameters.
 *           It's a CPU consuming operation, with non-negligible impact on latency.
 *           If there is a need to use the same prefix multiple times, consider loadDictionary instead.
 *  Note 4 : By default, the prefix is interpreted as raw content (ZSTD_dct_rawContent).
 *           Use experimental ZSTD_CCtx_refPrefix_advanced() to alter dictionary interpretation. */
ZSTDLIB_API size_t ZSTD_CCtx_refPrefix(ZSTD_CCtx* cctx,
                                 const void* prefix, size_t prefixSize);

/*! ZSTD_DCtx_loadDictionary() : Requires v1.4.0+
 *  Create an internal DDict from dict buffer, to be used to decompress all future frames.
 *  The dictionary remains valid for all future frames, until explicitly invalidated, or
 *  a new dictionary is loaded.
 * @result : 0, or an error code (which can be tested with ZSTD_isError()).
 *  Special : Adding a NULL (or 0-size) dictionary invalidates any previous dictionary,
 *            meaning "return to no-dictionary mode".
 *  Note 1 : Loading a dictionary involves building tables,
 *           which has a non-negligible impact on CPU usage and latency.
 *           It's recommended to "load once, use many times", to amortize the cost
 *  Note 2 :`dict` content will be copied internally, so `dict` can be released after loading.
 *           Use ZSTD_DCtx_loadDictionary_byReference() to reference dictionary content instead.
 *  Note 3 : Use ZSTD_DCtx_loadDictionary_advanced() to take control of
 *           how dictionary content is loaded and interpreted.
 */
ZSTDLIB_API size_t ZSTD_DCtx_loadDictionary(ZSTD_DCtx* dctx, const void* dict, size_t dictSize);

/*! ZSTD_DCtx_refDDict() : Requires v1.4.0+
 *  Reference a prepared dictionary, to be used to decompress next frames.
 *  The dictionary remains active for decompression of future frames using same DCtx.
 *
 *  If called with ZSTD_d_refMultipleDDicts enabled, repeated calls of this function
 *  will store the DDict references in a table, and the DDict used for decompression
 *  will be determined at decompression time, as per the dict ID in the frame.
 *  The memory for the table is allocated on the first call to refDDict, and can be
 *  freed with ZSTD_freeDCtx().
 *
 *  If called with ZSTD_d_refMultipleDDicts disabled (the default), only one dictionary
 *  will be managed, and referencing a dictionary effectively "discards" any previous one.
 *
 * @result : 0, or an error code (which can be tested with ZSTD_isError()).
 *  Special: referencing a NULL DDict means "return to no-dictionary mode".
 *  Note 2 : DDict is just referenced, its lifetime must outlive its usage from DCtx.
 */
ZSTDLIB_API size_t ZSTD_DCtx_refDDict(ZSTD_DCtx* dctx, const ZSTD_DDict* ddict);

/*! ZSTD_DCtx_refPrefix() : Requires v1.4.0+
 *  Reference a prefix (single-usage dictionary) to decompress next frame.
 *  This is the reverse operation of ZSTD_CCtx_refPrefix(),
 *  and must use the same prefix as the one used during compression.
 *  Prefix is **only used once**. Reference is discarded at end of frame.
 *  End of frame is reached when ZSTD_decompressStream() returns 0.
 * @result : 0, or an error code (which can be tested with ZSTD_isError()).
 *  Note 1 : Adding any prefix (including NULL) invalidates any previously set prefix or dictionary
 *  Note 2 : Prefix buffer is referenced. It **must** outlive decompression.
 *           Prefix buffer must remain unmodified up to the end of frame,
 *           reached when ZSTD_decompressStream() returns 0.
 *  Note 3 : By default, the prefix is treated as raw content (ZSTD_dct_rawContent).
 *           Use ZSTD_CCtx_refPrefix_advanced() to alter dictMode (Experimental section)
 *  Note 4 : Referencing a raw content prefix has almost no cpu nor memory cost.
 *           A full dictionary is more costly, as it requires building tables.
 */
ZSTDLIB_API size_t ZSTD_DCtx_refPrefix(ZSTD_DCtx* dctx,
                                 const void* prefix, size_t prefixSize);

/* ===   Memory management   === */

/*! ZSTD_sizeof_*() : Requires v1.4.0+
 *  These functions give the _current_ memory usage of selected object.
 *  Note that object memory usage can evolve (increase or decrease) over time. */
ZSTDLIB_API size_t ZSTD_sizeof_CCtx(const ZSTD_CCtx* cctx);
ZSTDLIB_API size_t ZSTD_sizeof_DCtx(const ZSTD_DCtx* dctx);
ZSTDLIB_API size_t ZSTD_sizeof_CStream(const ZSTD_CStream* zcs);
ZSTDLIB_API size_t ZSTD_sizeof_DStream(const ZSTD_DStream* zds);
ZSTDLIB_API size_t ZSTD_sizeof_CDict(const ZSTD_CDict* cdict);
ZSTDLIB_API size_t ZSTD_sizeof_DDict(const ZSTD_DDict* ddict);

#if defined (__cplusplus)
}
#endif

#endif  /* ZSTD_H_235446 */


/* **************************************************************************************
 *   ADVANCED AND EXPERIMENTAL FUNCTIONS
 ****************************************************************************************
 * The definitions in the following section are considered experimental.
 * They are provided for advanced scenarios.
 * They should never be used with a dynamic library, as prototypes may change in the future.
 * Use them only in association with static linking.
 * ***************************************************************************************/

#if defined(ZSTD_STATIC_LINKING_ONLY) && !defined(ZSTD_H_ZSTD_STATIC_LINKING_ONLY)
#define ZSTD_H_ZSTD_STATIC_LINKING_ONLY

#if defined (__cplusplus)
extern "C" {
#endif

/* This can be overridden externally to hide static symbols. */
#ifndef ZSTDLIB_STATIC_API
#  if defined(ZSTD_DLL_EXPORT) && (ZSTD_DLL_EXPORT==1)
#    define ZSTDLIB_STATIC_API __declspec(dllexport) ZSTDLIB_VISIBLE
#  elif defined(ZSTD_DLL_IMPORT) && (ZSTD_DLL_IMPORT==1)
#    define ZSTDLIB_STATIC_API __declspec(dllimport) ZSTDLIB_VISIBLE
#  else
#    define ZSTDLIB_STATIC_API ZSTDLIB_VISIBLE
#  endif
#endif

/****************************************************************************************
 *   experimental API (static linking only)
 ****************************************************************************************
 * The following symbols and constants
 * are not planned to join "stable API" status in the near future.
 * They can still change in future versions.
 * Some of them are planned to remain in the static_only section indefinitely.
 * Some of them might be removed in the future (especially when redundant with existing stable functions)
 * ***************************************************************************************/

#define ZSTD_FRAMEHEADERSIZE_PREFIX(format) ((format) == ZSTD_f_zstd1 ? 5 : 1)   /* minimum input size required to query frame header size */
#define ZSTD_FRAMEHEADERSIZE_MIN(format)    ((format) == ZSTD_f_zstd1 ? 6 : 2)
#define ZSTD_FRAMEHEADERSIZE_MAX   18   /* can be useful for static allocation */
#define ZSTD_SKIPPABLEHEADERSIZE    8

/* compression parameter bounds */
#define ZSTD_WINDOWLOG_MAX_32    30
#define ZSTD_WINDOWLOG_MAX_64    31
#define ZSTD_WINDOWLOG_MAX     ((int)(sizeof(size_t) == 4 ? ZSTD_WINDOWLOG_MAX_32 : ZSTD_WINDOWLOG_MAX_64))
#define ZSTD_WINDOWLOG_MIN       10
#define ZSTD_HASHLOG_MAX       ((ZSTD_WINDOWLOG_MAX < 30) ? ZSTD_WINDOWLOG_MAX : 30)
#define ZSTD_HASHLOG_MIN          6
#define ZSTD_CHAINLOG_MAX_32     29
#define ZSTD_CHAINLOG_MAX_64     30
#define ZSTD_CHAINLOG_MAX      ((int)(sizeof(size_t) == 4 ? ZSTD_CHAINLOG_MAX_32 : ZSTD_CHAINLOG_MAX_64))
#define ZSTD_CHAINLOG_MIN        ZSTD_HASHLOG_MIN
#define ZSTD_SEARCHLOG_MAX      (ZSTD_WINDOWLOG_MAX-1)
#define ZSTD_SEARCHLOG_MIN        1
#define ZSTD_MINMATCH_MAX         7   /* only for ZSTD_fast, other strategies are limited to 6 */
#define ZSTD_MINMATCH_MIN         3   /* only for ZSTD_btopt+, faster strategies are limited to 4 */
#define ZSTD_TARGETLENGTH_MAX    ZSTD_BLOCKSIZE_MAX
#define ZSTD_TARGETLENGTH_MIN     0   /* note : comparing this constant to an unsigned results in a tautological test */
#define ZSTD_STRATEGY_MIN        ZSTD_fast
#define ZSTD_STRATEGY_MAX        ZSTD_btultra2
#define ZSTD_BLOCKSIZE_MAX_MIN (1 << 10) /* The minimum valid max blocksize. Maximum blocksizes smaller than this make compressBound() inaccurate. */


#define ZSTD_OVERLAPLOG_MIN       0
#define ZSTD_OVERLAPLOG_MAX       9

#define ZSTD_WINDOWLOG_LIMIT_DEFAULT 27   /* by default, the streaming decoder will refuse any frame
                                           * requiring larger than (1<<ZSTD_WINDOWLOG_LIMIT_DEFAULT) window size,
                                           * to preserve host's memory from unreasonable requirements.
                                           * This limit can be overridden using ZSTD_DCtx_setParameter(,ZSTD_d_windowLogMax,).
                                           * The limit does not apply for one-pass decoders (such as ZSTD_decompress()), since no additional memory is allocated */


/* LDM parameter bounds */
#define ZSTD_LDM_HASHLOG_MIN      ZSTD_HASHLOG_MIN
#define ZSTD_LDM_HASHLOG_MAX      ZSTD_HASHLOG_MAX
#define ZSTD_LDM_MINMATCH_MIN        4
#define ZSTD_LDM_MINMATCH_MAX     4096
#define ZSTD_LDM_BUCKETSIZELOG_MIN   1
#define ZSTD_LDM_BUCKETSIZELOG_MAX   8
#define ZSTD_LDM_HASHRATELOG_MIN     0
#define ZSTD_LDM_HASHRATELOG_MAX (ZSTD_WINDOWLOG_MAX - ZSTD_HASHLOG_MIN)

/* Advanced parameter bounds */
#define ZSTD_TARGETCBLOCKSIZE_MIN   1340 /* suitable to fit into an ethernet / wifi / 4G transport frame */
#define ZSTD_TARGETCBLOCKSIZE_MAX   ZSTD_BLOCKSIZE_MAX
#define ZSTD_SRCSIZEHINT_MIN        0
#define ZSTD_SRCSIZEHINT_MAX        INT_MAX


/* ---  Advanced types  --- */

typedef struct ZSTD_CCtx_params_s ZSTD_CCtx_params;

typedef struct {
    unsigned int offset;      /* The offset of the match. (NOT the same as the offset code)
                               * If offset == 0 and matchLength == 0, this sequence represents the last
                               * literals in the block of litLength size.
                               */

    unsigned int litLength;   /* Literal length of the sequence. */
    unsigned int matchLength; /* Match length of the sequence. */

                              /* Note: Users of this API may provide a sequence with matchLength == litLength == offset == 0.
                               * In this case, we will treat the sequence as a marker for a block boundary.
                               */

    unsigned int rep;         /* Represents which repeat offset is represented by the field 'offset'.
                               * Ranges from [0, 3].
                               *
                               * Repeat offsets are essentially previous offsets from previous sequences sorted in
                               * recency order. For more detail, see doc/zstd_compression_format.md
                               *
                               * If rep == 0, then 'offset' does not contain a repeat offset.
                               * If rep > 0:
                               *  If litLength != 0:
                               *      rep == 1 --> offset == repeat_offset_1
                               *      rep == 2 --> offset == repeat_offset_2
                               *      rep == 3 --> offset == repeat_offset_3
                               *  If litLength == 0:
                               *      rep == 1 --> offset == repeat_offset_2
                               *      rep == 2 --> offset == repeat_offset_3
                               *      rep == 3 --> offset == repeat_offset_1 - 1
                               *
                               * Note: This field is optional. ZSTD_generateSequences() will calculate the value of
                               * 'rep', but repeat offsets do not necessarily need to be calculated from an external
                               * sequence provider perspective. For example, ZSTD_compressSequences() does not
                               * use this 'rep' field at all (as of now).
                               */
} ZSTD_Sequence;

typedef struct {
    unsigned windowLog;       /**< largest match distance : larger == more compression, more memory needed during decompression */
    unsigned chainLog;        /**< fully searched segment : larger == more compression, slower, more memory (useless for fast) */
    unsigned hashLog;         /**< dispatch table : larger == faster, more memory */
    unsigned searchLog;       /**< nb of searches : larger == more compression, slower */
    unsigned minMatch;        /**< match length searched : larger == faster decompression, sometimes less compression */
    unsigned targetLength;    /**< acceptable match size for optimal parser (only) : larger == more compression, slower */
    ZSTD_strategy strategy;   /**< see ZSTD_strategy definition above */
} ZSTD_compressionParameters;

typedef struct {
    int contentSizeFlag; /**< 1: content size will be in frame header (when known) */
    int checksumFlag;    /**< 1: generate a 32-bits checksum using XXH64 algorithm at end of frame, for error detection */
    int noDictIDFlag;    /**< 1: no dictID will be saved into frame header (dictID is only useful for dictionary compression) */
} ZSTD_frameParameters;

typedef struct {
    ZSTD_compressionParameters cParams;
    ZSTD_frameParameters fParams;
} ZSTD_parameters;

typedef enum {
    ZSTD_dct_auto = 0,       /* dictionary is "full" when starting with ZSTD_MAGIC_DICTIONARY, otherwise it is "rawContent" */
    ZSTD_dct_rawContent = 1, /* ensures dictionary is always loaded as rawContent, even if it starts with ZSTD_MAGIC_DICTIONARY */
    ZSTD_dct_fullDict = 2    /* refuses to load a dictionary if it does not respect Zstandard's specification, starting with ZSTD_MAGIC_DICTIONARY */
} ZSTD_dictContentType_e;

typedef enum {
    ZSTD_dlm_byCopy = 0,  /**< Copy dictionary content internally */
    ZSTD_dlm_byRef = 1    /**< Reference dictionary content -- the dictionary buffer must outlive its users. */
} ZSTD_dictLoadMethod_e;

typedef enum {
    ZSTD_f_zstd1 = 0,           /* zstd frame format, specified in zstd_compression_format.md (default) */
    ZSTD_f_zstd1_magicless = 1  /* Variant of zstd frame format, without initial 4-bytes magic number.
                                 * Useful to save 4 bytes per generated frame.
                                 * Decoder cannot recognise automatically this format, requiring this instruction. */
} ZSTD_format_e;

typedef enum {
    /* Note: this enum controls ZSTD_d_forceIgnoreChecksum */
    ZSTD_d_validateChecksum = 0,
    ZSTD_d_ignoreChecksum = 1
} ZSTD_forceIgnoreChecksum_e;

typedef enum {
    /* Note: this enum controls ZSTD_d_refMultipleDDicts */
    ZSTD_rmd_refSingleDDict = 0,
    ZSTD_rmd_refMultipleDDicts = 1
} ZSTD_refMultipleDDicts_e;

typedef enum {
    /* Note: this enum and the behavior it controls are effectively internal
     * implementation details of the compressor. They are expected to continue
     * to evolve and should be considered only in the context of extremely
     * advanced performance tuning.
     *
     * Zstd currently supports the use of a CDict in three ways:
     *
     * - The contents of the CDict can be copied into the working context. This
     *   means that the compression can search both the dictionary and input
     *   while operating on a single set of internal tables. This makes
     *   the compression faster per-byte of input. However, the initial copy of
     *   the CDict's tables incurs a fixed cost at the beginning of the
     *   compression. For small compressions (< 8 KB), that copy can dominate
     *   the cost of the compression.
     *
     * - The CDict's tables can be used in-place. In this model, compression is
     *   slower per input byte, because the compressor has to search two sets of
     *   tables. However, this model incurs no start-up cost (as long as the
     *   working context's tables can be reused). For small inputs, this can be
     *   faster than copying the CDict's tables.
     *
     * - The CDict's tables are not used at all, and instead we use the working
     *   context alone to reload the dictionary and use params based on the source
     *   size. See ZSTD_compress_insertDictionary() and ZSTD_compress_usingDict().
     *   This method is effective when the dictionary sizes are very small relative
     *   to the input size, and the input size is fairly large to begin with.
     *
     * Zstd has a simple internal heuristic that selects which strategy to use
     * at the beginning of a compression. However, if experimentation shows that
     * Zstd is making poor choices, it is possible to override that choice with
     * this enum.
     */
    ZSTD_dictDefaultAttach = 0, /* Use the default heuristic. */
    ZSTD_dictForceAttach   = 1, /* Never copy the dictionary. */
    ZSTD_dictForceCopy     = 2, /* Always copy the dictionary. */
    ZSTD_dictForceLoad     = 3  /* Always reload the dictionary */
} ZSTD_dictAttachPref_e;

typedef enum {
  ZSTD_lcm_auto = 0,          /**< Automatically determine the compression mode based on the compression level.
                               *   Negative compression levels will be uncompressed, and positive compression
                               *   levels will be compressed. */
  ZSTD_lcm_huffman = 1,       /**< Always attempt Huffman compression. Uncompressed literals will still be
                               *   emitted if Huffman compression is not profitable. */
  ZSTD_lcm_uncompressed = 2   /**< Always emit uncompressed literals. */
} ZSTD_literalCompressionMode_e;

typedef enum {
  /* Note: This enum controls features which are conditionally beneficial.
   * Zstd can take a decision on whether or not to enable the feature (ZSTD_ps_auto),
   * but setting the switch to ZSTD_ps_enable or ZSTD_ps_disable force enable/disable the feature.
   */
  ZSTD_ps_auto = 0,         /* Let the library automatically determine whether the feature shall be enabled */
  ZSTD_ps_enable = 1,       /* Force-enable the feature */
  ZSTD_ps_disable = 2       /* Do not use the feature */
} ZSTD_ParamSwitch_e;
#define ZSTD_paramSwitch_e ZSTD_ParamSwitch_e  /* old name */

/***************************************
*  Frame header and size functions
***************************************/

/*! ZSTD_findDecompressedSize() :
 *  `src` should point to the start of a series of ZSTD encoded and/or skippable frames
 *  `srcSize` must be the _exact_ size of this series
 *       (i.e. there should be a frame boundary at `src + srcSize`)
 *  @return : - decompressed size of all data in all successive frames
 *            - if the decompressed size cannot be determined: ZSTD_CONTENTSIZE_UNKNOWN
 *            - if an error occurred: ZSTD_CONTENTSIZE_ERROR
 *
 *   note 1 : decompressed size is an optional field, that may not be present, especially in streaming mode.
 *            When `return==ZSTD_CONTENTSIZE_UNKNOWN`, data to decompress could be any size.
 *            In which case, it's necessary to use streaming mode to decompress data.
 *   note 2 : decompressed size is always present when compression is done with ZSTD_compress()
 *   note 3 : decompressed size can be very large (64-bits value),
 *            potentially larger than what local system can handle as a single memory segment.
 *            In which case, it's necessary to use streaming mode to decompress data.
 *   note 4 : If source is untrusted, decompressed size could be wrong or intentionally modified.
 *            Always ensure result fits within application's authorized limits.
 *            Each application can set its own limits.
 *   note 5 : ZSTD_findDecompressedSize handles multiple frames, and so it must traverse the input to
 *            read each contained frame header.  This is fast as most of the data is skipped,
 *            however it does mean that all frame data must be present and valid. */
ZSTDLIB_STATIC_API unsigned long long ZSTD_findDecompressedSize(const void* src, size_t srcSize);

/*! ZSTD_decompressBound() :
 *  `src` should point to the start of a series of ZSTD encoded and/or skippable frames
 *  `srcSize` must be the _exact_ size of this series
 *       (i.e. there should be a frame boundary at `src + srcSize`)
 *  @return : - upper-bound for the decompressed size of all data in all successive frames
 *            - if an error occurred: ZSTD_CONTENTSIZE_ERROR
 *
 *  note 1  : an error can occur if `src` contains an invalid or incorrectly formatted frame.
 *  note 2  : the upper-bound is exact when the decompressed size field is available in every ZSTD encoded frame of `src`.
 *            in this case, `ZSTD_findDecompressedSize` and `ZSTD_decompressBound` return the same value.
 *  note 3  : when the decompressed size field isn't available, the upper-bound for that frame is calculated by:
 *              upper-bound = # blocks * min(128 KB, Window_Size)
 */
ZSTDLIB_STATIC_API unsigned long long ZSTD_decompressBound(const void* src, size_t srcSize);

/*! ZSTD_frameHeaderSize() :
 *  srcSize must be large enough, aka >= ZSTD_FRAMEHEADERSIZE_PREFIX.
 * @return : size of the Frame Header,
 *           or an error code (if srcSize is too small) */
ZSTDLIB_STATIC_API size_t ZSTD_frameHeaderSize(const void* src, size_t srcSize);

typedef enum { ZSTD_frame, ZSTD_skippableFrame } ZSTD_FrameType_e;
#define ZSTD_frameType_e ZSTD_FrameType_e /* old name */
typedef struct {
    unsigned long long frameContentSize; /* if == ZSTD_CONTENTSIZE_UNKNOWN, it means this field is not available. 0 means "empty" */
    unsigned long long windowSize;       /* can be very large, up to <= frameContentSize */
    unsigned blockSizeMax;
    ZSTD_FrameType_e frameType;          /* if == ZSTD_skippableFrame, frameContentSize is the size of skippable content */
    unsigned headerSize;
    unsigned dictID;                     /* for ZSTD_skippableFrame, contains the skippable magic variant [0-15] */
    unsigned checksumFlag;
    unsigned _reserved1;
    unsigned _reserved2;
} ZSTD_FrameHeader;
#define ZSTD_frameHeader ZSTD_FrameHeader /* old name */

/*! ZSTD_getFrameHeader() :
 *  decode Frame Header into `zfhPtr`, or requires larger `srcSize`.
 * @return : 0 => header is complete, `zfhPtr` is correctly filled,
 *          >0 => `srcSize` is too small, @return value is the wanted `srcSize` amount, `zfhPtr` is not filled,
 *           or an error code, which can be tested using ZSTD_isError() */
ZSTDLIB_STATIC_API size_t ZSTD_getFrameHeader(ZSTD_FrameHeader* zfhPtr, const void* src, size_t srcSize);
/*! ZSTD_getFrameHeader_advanced() :
 *  same as ZSTD_getFrameHeader(),
 *  with added capability to select a format (like ZSTD_f_zstd1_magicless) */
ZSTDLIB_STATIC_API size_t ZSTD_getFrameHeader_advanced(ZSTD_FrameHeader* zfhPtr, const void* src, size_t srcSize, ZSTD_format_e format);

/*! ZSTD_decompressionMargin() :
 * Zstd supports in-place decompression, where the input and output buffers overlap.
 * In this case, the output buffer must be at least (Margin + Output_Size) bytes large,
 * and the input buffer must be at the end of the output buffer.
 *
 *  _______________________ Output Buffer ________________________
 * |                                                              |
 * |                                        ____ Input Buffer ____|
 * |                                       |                      |
 * v                                       v                      v
 * |---------------------------------------|-----------|----------|
 * ^                                                   ^          ^
 * |___________________ Output_Size ___________________|_ Margin _|
 *
 * NOTE: See also ZSTD_DECOMPRESSION_MARGIN().
 * NOTE: This applies only to single-pass decompression through ZSTD_decompress() or
 * ZSTD_decompressDCtx().
 * NOTE: This function supports multi-frame input.
 *
 * @param src The compressed frame(s)
 * @param srcSize The size of the compressed frame(s)
 * @returns The decompression margin or an error that can be checked with ZSTD_isError().
 */
ZSTDLIB_STATIC_API size_t ZSTD_decompressionMargin(const void* src, size_t srcSize);

/*! ZSTD_DECOMPRESS_MARGIN() :
 * Similar to ZSTD_decompressionMargin(), but instead of computing the margin from
 * the compressed frame, compute it from the original size and the blockSizeLog.
 * See ZSTD_decompressionMargin() for details.
 *
 * WARNING: This macro does not support multi-frame input, the input must be a single
 * zstd frame. If you need that support use the function, or implement it yourself.
 *
 * @param originalSize The original uncompressed size of the data.
 * @param blockSize    The block size == MIN(windowSize, ZSTD_BLOCKSIZE_MAX).
 *                     Unless you explicitly set the windowLog smaller than
 *                     ZSTD_BLOCKSIZELOG_MAX you can just use ZSTD_BLOCKSIZE_MAX.
 */
#define ZSTD_DECOMPRESSION_MARGIN(originalSize, blockSize) ((size_t)(                                              \
        ZSTD_FRAMEHEADERSIZE_MAX                                                              /* Frame header */ + \
        4                                                                                         /* checksum */ + \
        ((originalSize) == 0 ? 0 : 3 * (((originalSize) + (blockSize) - 1) / blockSize)) /* 3 bytes per block */ + \
        (blockSize)                                                                    /* One block of margin */   \
    ))

typedef enum {
  ZSTD_sf_noBlockDelimiters = 0,         /* ZSTD_Sequence[] has no block delimiters, just sequences */
  ZSTD_sf_explicitBlockDelimiters = 1    /* ZSTD_Sequence[] contains explicit block delimiters */
} ZSTD_SequenceFormat_e;
#define ZSTD_sequenceFormat_e ZSTD_SequenceFormat_e /* old name */

/*! ZSTD_sequenceBound() :
 * `srcSize` : size of the input buffer
 *  @return : upper-bound for the number of sequences that can be generated
 *            from a buffer of srcSize bytes
 *
 *  note : returns number of sequences - to get bytes, multiply by sizeof(ZSTD_Sequence).
 */
ZSTDLIB_STATIC_API size_t ZSTD_sequenceBound(size_t srcSize);

/*! ZSTD_generateSequences() :
 * WARNING: This function is meant for debugging and informational purposes ONLY!
 * Its implementation is flawed, and it will be deleted in a future version.
 * It is not guaranteed to succeed, as there are several cases where it will give
 * up and fail. You should NOT use this function in production code.
 *
 * This function is deprecated, and will be removed in a future version.
 *
 * Generate sequences using ZSTD_compress2(), given a source buffer.
 *
 * @param zc The compression context to be used for ZSTD_compress2(). Set any
 *           compression parameters you need on this context.
 * @param outSeqs The output sequences buffer of size @p outSeqsSize
 * @param outSeqsCapacity The size of the output sequences buffer.
 *                    ZSTD_sequenceBound(srcSize) is an upper bound on the number
 *                    of sequences that can be generated.
 * @param src The source buffer to generate sequences from of size @p srcSize.
 * @param srcSize The size of the source buffer.
 *
 * Each block will end with a dummy sequence
 * with offset == 0, matchLength == 0, and litLength == length of last literals.
 * litLength may be == 0, and if so, then the sequence of (of: 0 ml: 0 ll: 0)
 * simply acts as a block delimiter.
 *
 * @returns The number of sequences generated, necessarily less than
 *          ZSTD_sequenceBound(srcSize), or an error code that can be checked
 *          with ZSTD_isError().
 */
ZSTD_DEPRECATED("For debugging only, will be replaced by ZSTD_extractSequences()")
ZSTDLIB_STATIC_API size_t
ZSTD_generateSequences(ZSTD_CCtx* zc,
                       ZSTD_Sequence* outSeqs, size_t outSeqsCapacity,
                       const void* src, size_t srcSize);

/*! ZSTD_mergeBlockDelimiters() :
 * Given an array of ZSTD_Sequence, remove all sequences that represent block delimiters/last literals
 * by merging them into the literals of the next sequence.
 *
 * As such, the final generated result has no explicit representation of block boundaries,
 * and the final last literals segment is not represented in the sequences.
 *
 * The output of this function can be fed into ZSTD_compressSequences() with CCtx
 * setting of ZSTD_c_blockDelimiters as ZSTD_sf_noBlockDelimiters
 * @return : number of sequences left after merging
 */
ZSTDLIB_STATIC_API size_t ZSTD_mergeBlockDelimiters(ZSTD_Sequence* sequences, size_t seqsSize);

/*! ZSTD_compressSequences() :
 * Compress an array of ZSTD_Sequence, associated with @src buffer, into dst.
 * @src contains the entire input (not just the literals).
 * If @srcSize > sum(sequence.length), the remaining bytes are considered all literals
 * If a dictionary is included, then the cctx should reference the dict (see: ZSTD_CCtx_refCDict(), ZSTD_CCtx_loadDictionary(), etc.).
 * The entire source is compressed into a single frame.
 *
 * The compression behavior changes based on cctx params. In particular:
 *    If ZSTD_c_blockDelimiters == ZSTD_sf_noBlockDelimiters, the array of ZSTD_Sequence is expected to contain
 *    no block delimiters (defined in ZSTD_Sequence). Block boundaries are roughly determined based on
 *    the block size derived from the cctx, and sequences may be split. This is the default setting.
 *
 *    If ZSTD_c_blockDelimiters == ZSTD_sf_explicitBlockDelimiters, the array of ZSTD_Sequence is expected to contain
 *    valid block delimiters (defined in ZSTD_Sequence). Behavior is undefined if no block delimiters are provided.
 *
 *    When ZSTD_c_blockDelimiters == ZSTD_sf_explicitBlockDelimiters, it's possible to decide generating repcodes
 *    using the advanced parameter ZSTD_c_repcodeResolution. Repcodes will improve compression ratio, though the benefit
 *    can vary greatly depending on Sequences. On the other hand, repcode resolution is an expensive operation.
 *    By default, it's disabled at low (<10) compression levels, and enabled above the threshold (>=10).
 *    ZSTD_c_repcodeResolution makes it possible to directly manage this processing in either direction.
 *
 *    If ZSTD_c_validateSequences == 0, this function blindly accepts the Sequences provided. Invalid Sequences cause undefined
 *    behavior. If ZSTD_c_validateSequences == 1, then the function will detect invalid Sequences (see doc/zstd_compression_format.md for
 *    specifics regarding offset/matchlength requirements) and then bail out and return an error.
 *
 *    In addition to the two adjustable experimental params, there are other important cctx params.
 *    - ZSTD_c_minMatch MUST be set as less than or equal to the smallest match generated by the match finder. It has a minimum value of ZSTD_MINMATCH_MIN.
 *    - ZSTD_c_compressionLevel accordingly adjusts the strength of the entropy coder, as it would in typical compression.
 *    - ZSTD_c_windowLog affects offset validation: this function will return an error at higher debug levels if a provided offset
 *      is larger than what the spec allows for a given window log and dictionary (if present). See: doc/zstd_compression_format.md
 *
 * Note: Repcodes are, as of now, always re-calculated within this function, ZSTD_Sequence.rep is effectively unused.
 * Dev Note: Once ability to ingest repcodes become available, the explicit block delims mode must respect those repcodes exactly,
 *         and cannot emit an RLE block that disagrees with the repcode history.
 * @return : final compressed size, or a ZSTD error code.
 */
ZSTDLIB_STATIC_API size_t
ZSTD_compressSequences(ZSTD_CCtx* cctx,
                       void* dst, size_t dstCapacity,
                 const ZSTD_Sequence* inSeqs, size_t inSeqsSize,
                 const void* src, size_t srcSize);


/*! ZSTD_compressSequencesAndLiterals() :
 * This is a variant of ZSTD_compressSequences() which,
 * instead of receiving (src,srcSize) as input parameter, receives (literals,litSize),
 * aka all the literals, already extracted and laid out into a single continuous buffer.
 * This can be useful if the process generating the sequences also happens to generate the buffer of literals,
 * thus skipping an extraction + caching stage.
 * It's a speed optimization, useful when the right conditions are met,
 * but it also features the following limitations:
 * - Only supports explicit delimiter mode
 * - Currently does not support Sequences validation (so input Sequences are trusted)
 * - Not compatible with frame checksum, which must be disabled
 * - If any block is incompressible, will fail and return an error
 * - @litSize must be == sum of all @.litLength fields in @inSeqs. Any discrepancy will generate an error.
 * - @litBufCapacity is the size of the underlying buffer into which literals are written, starting at address @literals.
 *   @litBufCapacity must be at least 8 bytes larger than @litSize.
 * - @decompressedSize must be correct, and correspond to the sum of all Sequences. Any discrepancy will generate an error.
 * @return : final compressed size, or a ZSTD error code.
 */
ZSTDLIB_STATIC_API size_t
ZSTD_compressSequencesAndLiterals(ZSTD_CCtx* cctx,
                                  void* dst, size_t dstCapacity,
                            const ZSTD_Sequence* inSeqs, size_t nbSequences,
                            const void* literals, size_t litSize, size_t litBufCapacity,
                            size_t decompressedSize);


/*! ZSTD_writeSkippableFrame() :
 * Generates a zstd skippable frame containing data given by src, and writes it to dst buffer.
 *
 * Skippable frames begin with a 4-byte magic number. There are 16 possible choices of magic number,
 * ranging from ZSTD_MAGIC_SKIPPABLE_START to ZSTD_MAGIC_SKIPPABLE_START+15.
 * As such, the parameter magicVariant controls the exact skippable frame magic number variant used,
 * so the magic number used will be ZSTD_MAGIC_SKIPPABLE_START + magicVariant.
 *
 * Returns an error if destination buffer is not large enough, if the source size is not representable
 * with a 4-byte unsigned int, or if the parameter magicVariant is greater than 15 (and therefore invalid).
 *
 * @return : number of bytes written or a ZSTD error.
 */
ZSTDLIB_STATIC_API size_t ZSTD_writeSkippableFrame(void* dst, size_t dstCapacity,
                                             const void* src, size_t srcSize,
                                                   unsigned magicVariant);

/*! ZSTD_readSkippableFrame() :
 * Retrieves the content of a zstd skippable frame starting at @src, and writes it to @dst buffer.
 *
 * The parameter @magicVariant will receive the magicVariant that was supplied when the frame was written,
 * i.e. magicNumber - ZSTD_MAGIC_SKIPPABLE_START.
 * This can be NULL if the caller is not interested in the magicVariant.
 *
 * Returns an error if destination buffer is not large enough, or if the frame is not skippable.
 *
 * @return : number of bytes written or a ZSTD error.
 */
ZSTDLIB_STATIC_API size_t ZSTD_readSkippableFrame(void* dst, size_t dstCapacity,
                                                  unsigned* magicVariant,
                                                  const void* src, size_t srcSize);

/*! ZSTD_isSkippableFrame() :
 *  Tells if the content of `buffer` starts with a valid Frame Identifier for a skippable frame.
 */
ZSTDLIB_STATIC_API unsigned ZSTD_isSkippableFrame(const void* buffer, size_t size);



/***************************************
*  Memory management
***************************************/

/*! ZSTD_estimate*() :
 *  These functions make it possible to estimate memory usage
 *  of a future {D,C}Ctx, before its creation.
 *  This is useful in combination with ZSTD_initStatic(),
 *  which makes it possible to employ a static buffer for ZSTD_CCtx* state.
 *
 *  ZSTD_estimateCCtxSize() will provide a memory budget large enough
 *  to compress data of any size using one-shot compression ZSTD_compressCCtx() or ZSTD_compress2()
 *  associated with any compression level up to max specified one.
 *  The estimate will assume the input may be arbitrarily large,
 *  which is the worst case.
 *
 *  Note that the size estimation is specific for one-shot compression,
 *  it is not valid for streaming (see ZSTD_estimateCStreamSize*())
 *  nor other potential ways of using a ZSTD_CCtx* state.
 *
 *  When srcSize can be bound by a known and rather "small" value,
 *  this knowledge can be used to provide a tighter budget estimation
 *  because the ZSTD_CCtx* state will need less memory for small inputs.
 *  This tighter estimation can be provided by employing more advanced functions
 *  ZSTD_estimateCCtxSize_usingCParams(), which can be used in tandem with ZSTD_getCParams(),
 *  and ZSTD_estimateCCtxSize_usingCCtxParams(), which can be used in tandem with ZSTD_CCtxParams_setParameter().
 *  Both can be used to estimate memory using custom compression parameters and arbitrary srcSize limits.
 *
 *  Note : only single-threaded compression is supported.
 *  ZSTD_estimateCCtxSize_usingCCtxParams() will return an error code if ZSTD_c_nbWorkers is >= 1.
 */
ZSTDLIB_STATIC_API size_t ZSTD_estimateCCtxSize(int maxCompressionLevel);
ZSTDLIB_STATIC_API size_t ZSTD_estimateCCtxSize_usingCParams(ZSTD_compressionParameters cParams);
ZSTDLIB_STATIC_API size_t ZSTD_estimateCCtxSize_usingCCtxParams(const ZSTD_CCtx_params* params);
ZSTDLIB_STATIC_API size_t ZSTD_estimateDCtxSize(void);

/*! ZSTD_estimateCStreamSize() :
 *  ZSTD_estimateCStreamSize() will provide a memory budget large enough for streaming compression
 *  using any compression level up to the max specified one.
 *  It will also consider src size to be arbitrarily "large", which is a worst case scenario.
 *  If srcSize is known to always be small, ZSTD_estimateCStreamSize_usingCParams() can provide a tighter estimation.
 *  ZSTD_estimateCStreamSize_usingCParams() can be used in tandem with ZSTD_getCParams() to create cParams from compressionLevel.
 *  ZSTD_estimateCStreamSize_usingCCtxParams() can be used in tandem with ZSTD_CCtxParams_setParameter(). Only single-threaded compression is supported. This function will return an error code if ZSTD_c_nbWorkers is >= 1.
 *  Note : CStream size estimation is only correct for single-threaded compression.
 *  ZSTD_estimateCStreamSize_usingCCtxParams() will return an error code if ZSTD_c_nbWorkers is >= 1.
 *  Note 2 : ZSTD_estimateCStreamSize* functions are not compatible with the Block-Level Sequence Producer API at this time.
 *  Size estimates assume that no external sequence producer is registered.
 *
 *  ZSTD_DStream memory budget depends on frame's window Size.
 *  This information can be passed manually, using ZSTD_estimateDStreamSize,
 *  or deducted from a valid frame Header, using ZSTD_estimateDStreamSize_fromFrame();
 *  Any frame requesting a window size larger than max specified one will be rejected.
 *  Note : if streaming is init with function ZSTD_init?Stream_usingDict(),
 *         an internal ?Dict will be created, which additional size is not estimated here.
 *         In this case, get total size by adding ZSTD_estimate?DictSize
 */
ZSTDLIB_STATIC_API size_t ZSTD_estimateCStreamSize(int maxCompressionLevel);
ZSTDLIB_STATIC_API size_t ZSTD_estimateCStreamSize_usingCParams(ZSTD_compressionParameters cParams);
ZSTDLIB_STATIC_API size_t ZSTD_estimateCStreamSize_usingCCtxParams(const ZSTD_CCtx_params* params);
ZSTDLIB_STATIC_API size_t ZSTD_estimateDStreamSize(size_t maxWindowSize);
ZSTDLIB_STATIC_API size_t ZSTD_estimateDStreamSize_fromFrame(const void* src, size_t srcSize);

/*! ZSTD_estimate?DictSize() :
 *  ZSTD_estimateCDictSize() will bet that src size is relatively "small", and content is copied, like ZSTD_createCDict().
 *  ZSTD_estimateCDictSize_advanced() makes it possible to control compression parameters precisely, like ZSTD_createCDict_advanced().
 *  Note : dictionaries created by reference (`ZSTD_dlm_byRef`) are logically smaller.
 */
ZSTDLIB_STATIC_API size_t ZSTD_estimateCDictSize(size_t dictSize, int compressionLevel);
ZSTDLIB_STATIC_API size_t ZSTD_estimateCDictSize_advanced(size_t dictSize, ZSTD_compressionParameters cParams, ZSTD_dictLoadMethod_e dictLoadMethod);
ZSTDLIB_STATIC_API size_t ZSTD_estimateDDictSize(size_t dictSize, ZSTD_dictLoadMethod_e dictLoadMethod);

/*! ZSTD_initStatic*() :
 *  Initialize an object using a pre-allocated fixed-size buffer.
 *  workspace: The memory area to emplace the object into.
 *             Provided pointer *must be 8-bytes aligned*.
 *             Buffer must outlive object.
 *  workspaceSize: Use ZSTD_estimate*Size() to determine
 *                 how large workspace must be to support target scenario.
 * @return : pointer to object (same address as workspace, just different type),
 *           or NULL if error (size too small, incorrect alignment, etc.)
 *  Note : zstd will never resize nor malloc() when using a static buffer.
 *         If the object requires more memory than available,
 *         zstd will just error out (typically ZSTD_error_memory_allocation).
 *  Note 2 : there is no corresponding "free" function.
 *           Since workspace is allocated externally, it must be freed externally too.
 *  Note 3 : cParams : use ZSTD_getCParams() to convert a compression level
 *           into its associated cParams.
 *  Limitation 1 : currently not compatible with internal dictionary creation, triggered by
 *                 ZSTD_CCtx_loadDictionary(), ZSTD_initCStream_usingDict() or ZSTD_initDStream_usingDict().
 *  Limitation 2 : static cctx currently not compatible with multi-threading.
 *  Limitation 3 : static dctx is incompatible with legacy support.
 */
ZSTDLIB_STATIC_API ZSTD_CCtx*    ZSTD_initStaticCCtx(void* workspace, size_t workspaceSize);
ZSTDLIB_STATIC_API ZSTD_CStream* ZSTD_initStaticCStream(void* workspace, size_t workspaceSize);    /**< same as ZSTD_initStaticCCtx() */

ZSTDLIB_STATIC_API ZSTD_DCtx*    ZSTD_initStaticDCtx(void* workspace, size_t workspaceSize);
ZSTDLIB_STATIC_API ZSTD_DStream* ZSTD_initStaticDStream(void* workspace, size_t workspaceSize);    /**< same as ZSTD_initStaticDCtx() */

ZSTDLIB_STATIC_API const ZSTD_CDict* ZSTD_initStaticCDict(
                                        void* workspace, size_t workspaceSize,
                                        const void* dict, size_t dictSize,
                                        ZSTD_dictLoadMethod_e dictLoadMethod,
                                        ZSTD_dictContentType_e dictContentType,
                                        ZSTD_compressionParameters cParams);

ZSTDLIB_STATIC_API const ZSTD_DDict* ZSTD_initStaticDDict(
                                        void* workspace, size_t workspaceSize,
                                        const void* dict, size_t dictSize,
                                        ZSTD_dictLoadMethod_e dictLoadMethod,
                                        ZSTD_dictContentType_e dictContentType);


/*! Custom memory allocation :
 *  These prototypes make it possible to pass your own allocation/free functions.
 *  ZSTD_customMem is provided at creation time, using ZSTD_create*_advanced() variants listed below.
 *  All allocation/free operations will be completed using these custom variants instead of regular <stdlib.h> ones.
 */
typedef void* (*ZSTD_allocFunction) (void* opaque, size_t size);
typedef void  (*ZSTD_freeFunction) (void* opaque, void* address);
typedef struct { ZSTD_allocFunction customAlloc; ZSTD_freeFunction customFree; void* opaque; } ZSTD_customMem;
static
#ifdef __GNUC__
__attribute__((__unused__))
#endif

#if defined(__clang__) && __clang_major__ >= 5
#pragma clang diagnostic push
#pragma clang diagnostic ignored "-Wzero-as-null-pointer-constant"
#endif
ZSTD_customMem const ZSTD_defaultCMem = { NULL, NULL, NULL };  /**< this constant defers to stdlib's functions */
#if defined(__clang__) && __clang_major__ >= 5
#pragma clang diagnostic pop
#endif

ZSTDLIB_STATIC_API ZSTD_CCtx*    ZSTD_createCCtx_advanced(ZSTD_customMem customMem);
ZSTDLIB_STATIC_API ZSTD_CStream* ZSTD_createCStream_advanced(ZSTD_customMem customMem);
ZSTDLIB_STATIC_API ZSTD_DCtx*    ZSTD_createDCtx_advanced(ZSTD_customMem customMem);
ZSTDLIB_STATIC_API ZSTD_DStream* ZSTD_createDStream_advanced(ZSTD_customMem customMem);

ZSTDLIB_STATIC_API ZSTD_CDict* ZSTD_createCDict_advanced(const void* dict, size_t dictSize,
                                                  ZSTD_dictLoadMethod_e dictLoadMethod,
                                                  ZSTD_dictContentType_e dictContentType,
                                                  ZSTD_compressionParameters cParams,
                                                  ZSTD_customMem customMem);

/*! Thread pool :
 *  These prototypes make it possible to share a thread pool among multiple compression contexts.
 *  This can limit resources for applications with multiple threads where each one uses
 *  a threaded compression mode (via ZSTD_c_nbWorkers parameter).
 *  ZSTD_createThreadPool creates a new thread pool with a given number of threads.
 *  Note that the lifetime of such pool must exist while being used.
 *  ZSTD_CCtx_refThreadPool assigns a thread pool to a context (use NULL argument value
 *  to use an internal thread pool).
 *  ZSTD_freeThreadPool frees a thread pool, accepts NULL pointer.
 */
typedef struct POOL_ctx_s ZSTD_threadPool;
ZSTDLIB_STATIC_API ZSTD_threadPool* ZSTD_createThreadPool(size_t numThreads);
ZSTDLIB_STATIC_API void ZSTD_freeThreadPool (ZSTD_threadPool* pool);  /* accept NULL pointer */
ZSTDLIB_STATIC_API size_t ZSTD_CCtx_refThreadPool(ZSTD_CCtx* cctx, ZSTD_threadPool* pool);


/*
 * This API is temporary and is expected to change or disappear in the future!
 */
ZSTDLIB_STATIC_API ZSTD_CDict* ZSTD_createCDict_advanced2(
    const void* dict, size_t dictSize,
    ZSTD_dictLoadMethod_e dictLoadMethod,
    ZSTD_dictContentType_e dictContentType,
    const ZSTD_CCtx_params* cctxParams,
    ZSTD_customMem customMem);

ZSTDLIB_STATIC_API ZSTD_DDict* ZSTD_createDDict_advanced(
    const void* dict, size_t dictSize,
    ZSTD_dictLoadMethod_e dictLoadMethod,
    ZSTD_dictContentType_e dictContentType,
    ZSTD_customMem customMem);


/***************************************
*  Advanced compression functions
***************************************/

/*! ZSTD_createCDict_byReference() :
 *  Create a digested dictionary for compression
 *  Dictionary content is just referenced, not duplicated.
 *  As a consequence, `dictBuffer` **must** outlive CDict,
 *  and its content must remain unmodified throughout the lifetime of CDict.
 *  note: equivalent to ZSTD_createCDict_advanced(), with dictLoadMethod==ZSTD_dlm_byRef */
ZSTDLIB_STATIC_API ZSTD_CDict* ZSTD_createCDict_byReference(const void* dictBuffer, size_t dictSize, int compressionLevel);

/*! ZSTD_getCParams() :
 * @return ZSTD_compressionParameters structure for a selected compression level and estimated srcSize.
 * `estimatedSrcSize` value is optional, select 0 if not known */
ZSTDLIB_STATIC_API ZSTD_compressionParameters ZSTD_getCParams(int compressionLevel, unsigned long long estimatedSrcSize, size_t dictSize);

/*! ZSTD_getParams() :
 *  same as ZSTD_getCParams(), but @return a full `ZSTD_parameters` object instead of sub-component `ZSTD_compressionParameters`.
 *  All fields of `ZSTD_frameParameters` are set to default : contentSize=1, checksum=0, noDictID=0 */
ZSTDLIB_STATIC_API ZSTD_parameters ZSTD_getParams(int compressionLevel, unsigned long long estimatedSrcSize, size_t dictSize);

/*! ZSTD_checkCParams() :
 *  Ensure param values remain within authorized range.
 * @return 0 on success, or an error code (can be checked with ZSTD_isError()) */
ZSTDLIB_STATIC_API size_t ZSTD_checkCParams(ZSTD_compressionParameters params);

/*! ZSTD_adjustCParams() :
 *  optimize params for a given `srcSize` and `dictSize`.
 * `srcSize` can be unknown, in which case use ZSTD_CONTENTSIZE_UNKNOWN.
 * `dictSize` must be `0` when there is no dictionary.
 *  cPar can be invalid : all parameters will be clamped within valid range in the @return struct.
 *  This function never fails (wide contract) */
ZSTDLIB_STATIC_API ZSTD_compressionParameters ZSTD_adjustCParams(ZSTD_compressionParameters cPar, unsigned long long srcSize, size_t dictSize);

/*! ZSTD_CCtx_setCParams() :
 *  Set all parameters provided within @p cparams into the working @p cctx.
 *  Note : if modifying parameters during compression (MT mode only),
 *         note that changes to the .windowLog parameter will be ignored.
 * @return 0 on success, or an error code (can be checked with ZSTD_isError()).
 *         On failure, no parameters are updated.
 */
ZSTDLIB_STATIC_API size_t ZSTD_CCtx_setCParams(ZSTD_CCtx* cctx, ZSTD_compressionParameters cparams);

/*! ZSTD_CCtx_setFParams() :
 *  Set all parameters provided within @p fparams into the working @p cctx.
 * @return 0 on success, or an error code (can be checked with ZSTD_isError()).
 */
ZSTDLIB_STATIC_API size_t ZSTD_CCtx_setFParams(ZSTD_CCtx* cctx, ZSTD_frameParameters fparams);

/*! ZSTD_CCtx_setParams() :
 *  Set all parameters provided within @p params into the working @p cctx.
 * @return 0 on success, or an error code (can be checked with ZSTD_isError()).
 */
ZSTDLIB_STATIC_API size_t ZSTD_CCtx_setParams(ZSTD_CCtx* cctx, ZSTD_parameters params);

/*! ZSTD_compress_advanced() :
 *  Note : this function is now DEPRECATED.
 *         It can be replaced by ZSTD_compress2(), in combination with ZSTD_CCtx_setParameter() and other parameter setters.
 *  This prototype will generate compilation warnings. */
ZSTD_DEPRECATED("use ZSTD_compress2")
ZSTDLIB_STATIC_API
size_t ZSTD_compress_advanced(ZSTD_CCtx* cctx,
                              void* dst, size_t dstCapacity,
                        const void* src, size_t srcSize,
                        const void* dict,size_t dictSize,
                              ZSTD_parameters params);

/*! ZSTD_compress_usingCDict_advanced() :
 *  Note : this function is now DEPRECATED.
 *         It can be replaced by ZSTD_compress2(), in combination with ZSTD_CCtx_loadDictionary() and other parameter setters.
 *  This prototype will generate compilation warnings. */
ZSTD_DEPRECATED("use ZSTD_compress2 with ZSTD_CCtx_loadDictionary")
ZSTDLIB_STATIC_API
size_t ZSTD_compress_usingCDict_advanced(ZSTD_CCtx* cctx,
                                              void* dst, size_t dstCapacity,
                                        const void* src, size_t srcSize,
                                        const ZSTD_CDict* cdict,
                                              ZSTD_frameParameters fParams);


/*! ZSTD_CCtx_loadDictionary_byReference() :
 *  Same as ZSTD_CCtx_loadDictionary(), but dictionary content is referenced, instead of being copied into CCtx.
 *  It saves some memory, but also requires that `dict` outlives its usage within `cctx` */
ZSTDLIB_STATIC_API size_t ZSTD_CCtx_loadDictionary_byReference(ZSTD_CCtx* cctx, const void* dict, size_t dictSize);

/*! ZSTD_CCtx_loadDictionary_advanced() :
 *  Same as ZSTD_CCtx_loadDictionary(), but gives finer control over
 *  how to load the dictionary (by copy ? by reference ?)
 *  and how to interpret it (automatic ? force raw mode ? full mode only ?) */
ZSTDLIB_STATIC_API size_t ZSTD_CCtx_loadDictionary_advanced(ZSTD_CCtx* cctx, const void* dict, size_t dictSize, ZSTD_dictLoadMethod_e dictLoadMethod, ZSTD_dictContentType_e dictContentType);

/*! ZSTD_CCtx_refPrefix_advanced() :
 *  Same as ZSTD_CCtx_refPrefix(), but gives finer control over
 *  how to interpret prefix content (automatic ? force raw mode (default) ? full mode only ?) */
ZSTDLIB_STATIC_API size_t ZSTD_CCtx_refPrefix_advanced(ZSTD_CCtx* cctx, const void* prefix, size_t prefixSize, ZSTD_dictContentType_e dictContentType);

/* ===   experimental parameters   === */
/* these parameters can be used with ZSTD_setParameter()
 * they are not guaranteed to remain supported in the future */

 /* Enables rsyncable mode,
  * which makes compressed files more rsync friendly
  * by adding periodic synchronization points to the compressed data.
  * The target average block size is ZSTD_c_jobSize / 2.
  * It's possible to modify the job size to increase or decrease
  * the granularity of the synchronization point.
  * Once the jobSize is smaller than the window size,
  * it will result in compression ratio degradation.
  * NOTE 1: rsyncable mode only works when multithreading is enabled.
  * NOTE 2: rsyncable performs poorly in combination with long range mode,
  * since it will decrease the effectiveness of synchronization points,
  * though mileage may vary.
  * NOTE 3: Rsyncable mode limits maximum compression speed to ~400 MB/s.
  * If the selected compression level is already running significantly slower,
  * the overall speed won't be significantly impacted.
  */
 #define ZSTD_c_rsyncable ZSTD_c_experimentalParam1

/* Select a compression format.
 * The value must be of type ZSTD_format_e.
 * See ZSTD_format_e enum definition for details */
#define ZSTD_c_format ZSTD_c_experimentalParam2

/* Force back-reference distances to remain < windowSize,
 * even when referencing into Dictionary content (default:0) */
#define ZSTD_c_forceMaxWindow ZSTD_c_experimentalParam3

/* Controls whether the contents of a CDict
 * are used in place, or copied into the working context.
 * Accepts values from the ZSTD_dictAttachPref_e enum.
 * See the comments on that enum for an explanation of the feature. */
#define ZSTD_c_forceAttachDict ZSTD_c_experimentalParam4

/* Controlled with ZSTD_ParamSwitch_e enum.
 * Default is ZSTD_ps_auto.
 * Set to ZSTD_ps_disable to never compress literals.
 * Set to ZSTD_ps_enable to always compress literals. (Note: uncompressed literals
 * may still be emitted if huffman is not beneficial to use.)
 *
 * By default, in ZSTD_ps_auto, the library will decide at runtime whether to use
 * literals compression based on the compression parameters - specifically,
 * negative compression levels do not use literal compression.
 */
#define ZSTD_c_literalCompressionMode ZSTD_c_experimentalParam5

/* User's best guess of source size.
 * Hint is not valid when srcSizeHint == 0.
 * There is no guarantee that hint is close to actual source size,
 * but compression ratio may regress significantly if guess considerably underestimates */
#define ZSTD_c_srcSizeHint ZSTD_c_experimentalParam7

/* Controls whether the new and experimental "dedicated dictionary search
 * structure" can be used. This feature is still rough around the edges, be
 * prepared for surprising behavior!
 *
 * How to use it:
 *
 * When using a CDict, whether to use this feature or not is controlled at
 * CDict creation, and it must be set in a CCtxParams set passed into that
 * construction (via ZSTD_createCDict_advanced2()). A compression will then
 * use the feature or not based on how the CDict was constructed; the value of
 * this param, set in the CCtx, will have no effect.
 *
 * However, when a dictionary buffer is passed into a CCtx, such as via
 * ZSTD_CCtx_loadDictionary(), this param can be set on the CCtx to control
 * whether the CDict that is created internally can use the feature or not.
 *
 * What it does:
 *
 * Normally, the internal data structures of the CDict are analogous to what
 * would be stored in a CCtx after compressing the contents of a dictionary.
 * To an approximation, a compression using a dictionary can then use those
 * data structures to simply continue what is effectively a streaming
 * compression where the simulated compression of the dictionary left off.
 * Which is to say, the search structures in the CDict are normally the same
 * format as in the CCtx.
 *
 * It is possible to do better, since the CDict is not like a CCtx: the search
 * structures are written once during CDict creation, and then are only read
 * after that, while the search structures in the CCtx are both read and
 * written as the compression goes along. This means we can choose a search
 * structure for the dictionary that is read-optimized.
 *
 * This feature enables the use of that different structure.
 *
 * Note that some of the members of the ZSTD_compressionParameters struct have
 * different semantics and constraints in the dedicated search structure. It is
 * highly recommended that you simply set a compression level in the CCtxParams
 * you pass into the CDict creation call, and avoid messing with the cParams
 * directly.
 *
 * Effects:
 *
 * This will only have any effect when the selected ZSTD_strategy
 * implementation supports this feature. Currently, that's limited to
 * ZSTD_greedy, ZSTD_lazy, and ZSTD_lazy2.
 *
 * Note that this means that the CDict tables can no longer be copied into the
 * CCtx, so the dict attachment mode ZSTD_dictForceCopy will no longer be
 * usable. The dictionary can only be attached or reloaded.
 *
 * In general, you should expect compression to be faster--sometimes very much
 * so--and CDict creation to be slightly slower. Eventually, we will probably
 * make this mode the default.
 */
#define ZSTD_c_enableDedicatedDictSearch ZSTD_c_experimentalParam8

/* ZSTD_c_stableInBuffer
 * Experimental parameter.
 * Default is 0 == disabled. Set to 1 to enable.
 *
 * Tells the compressor that input data presented with ZSTD_inBuffer
 * will ALWAYS be the same between calls.
 * Technically, the @src pointer must never be changed,
 * and the @pos field can only be updated by zstd.
 * However, it's possible to increase the @size field,
 * allowing scenarios where more data can be appended after compressions starts.
 * These conditions are checked by the compressor,
 * and compression will fail if they are not respected.
 * Also, data in the ZSTD_inBuffer within the range [src, src + pos)
 * MUST not be modified during compression or it will result in data corruption.
 *
 * When this flag is enabled zstd won't allocate an input window buffer,
 * because the user guarantees it can reference the ZSTD_inBuffer until
 * the frame is complete. But, it will still allocate an output buffer
 * large enough to fit a block (see ZSTD_c_stableOutBuffer). This will also
 * avoid the memcpy() from the input buffer to the input window buffer.
 *
 * NOTE: So long as the ZSTD_inBuffer always points to valid memory, using
 * this flag is ALWAYS memory safe, and will never access out-of-bounds
 * memory. However, compression WILL fail if conditions are not respected.
 *
 * WARNING: The data in the ZSTD_inBuffer in the range [src, src + pos) MUST
 * not be modified during compression or it will result in data corruption.
 * This is because zstd needs to reference data in the ZSTD_inBuffer to find
 * matches. Normally zstd maintains its own window buffer for this purpose,
 * but passing this flag tells zstd to rely on user provided buffer instead.
 */
#define ZSTD_c_stableInBuffer ZSTD_c_experimentalParam9

/* ZSTD_c_stableOutBuffer
 * Experimental parameter.
 * Default is 0 == disabled. Set to 1 to enable.
 *
 * Tells he compressor that the ZSTD_outBuffer will not be resized between
 * calls. Specifically: (out.size - out.pos) will never grow. This gives the
 * compressor the freedom to say: If the compressed data doesn't fit in the
 * output buffer then return ZSTD_error_dstSizeTooSmall. This allows us to
 * always decompress directly into the output buffer, instead of decompressing
 * into an internal buffer and copying to the output buffer.
 *
 * When this flag is enabled zstd won't allocate an output buffer, because
 * it can write directly to the ZSTD_outBuffer. It will still allocate the
 * input window buffer (see ZSTD_c_stableInBuffer).
 *
 * Zstd will check that (out.size - out.pos) never grows and return an error
 * if it does. While not strictly necessary, this should prevent surprises.
 */
#define ZSTD_c_stableOutBuffer ZSTD_c_experimentalParam10

/* ZSTD_c_blockDelimiters
 * Default is 0 == ZSTD_sf_noBlockDelimiters.
 *
 * For use with sequence compression API: ZSTD_compressSequences().
 *
 * Designates whether or not the given array of ZSTD_Sequence contains block delimiters
 * and last literals, which are defined as sequences with offset == 0 and matchLength == 0.
 * See the definition of ZSTD_Sequence for more specifics.
 */
#define ZSTD_c_blockDelimiters ZSTD_c_experimentalParam11

/* ZSTD_c_validateSequences
 * Default is 0 == disabled. Set to 1 to enable sequence validation.
 *
 * For use with sequence compression API: ZSTD_compressSequences*().
 * Designates whether or not provided sequences are validated within ZSTD_compressSequences*()
 * during function execution.
 *
 * When Sequence validation is disabled (default), Sequences are compressed as-is,
 * so they must correct, otherwise it would result in a corruption error.
 *
 * Sequence validation adds some protection, by ensuring that all values respect boundary conditions.
 * If a Sequence is detected invalid (see doc/zstd_compression_format.md for
 * specifics regarding offset/matchlength requirements) then the function will bail out and
 * return an error.
 */
#define ZSTD_c_validateSequences ZSTD_c_experimentalParam12

/* ZSTD_c_blockSplitterLevel
 * note: this parameter only influences the first splitter stage,
 *       which is active before producing the sequences.
 *       ZSTD_c_splitAfterSequences controls the next splitter stage,
 *       which is active after sequence production.
 *       Note that both can be combined.
 * Allowed values are between 0 and ZSTD_BLOCKSPLITTER_LEVEL_MAX included.
 * 0 means "auto", which will select a value depending on current ZSTD_c_strategy.
 * 1 means no splitting.
 * Then, values from 2 to 6 are sorted in increasing cpu load order.
 *
 * Note that currently the first block is never split,
 * to ensure expansion guarantees in presence of incompressible data.
 */
#define ZSTD_BLOCKSPLITTER_LEVEL_MAX 6
#define ZSTD_c_blockSplitterLevel ZSTD_c_experimentalParam20

/* ZSTD_c_splitAfterSequences
 * This is a stronger splitter algorithm,
 * based on actual sequences previously produced by the selected parser.
 * It's also slower, and as a consequence, mostly used for high compression levels.
 * While the post-splitter does overlap with the pre-splitter,
 * both can nonetheless be combined,
 * notably with ZSTD_c_blockSplitterLevel at ZSTD_BLOCKSPLITTER_LEVEL_MAX,
 * resulting in higher compression ratio than just one of them.
 *
 * Default is ZSTD_ps_auto.
 * Set to ZSTD_ps_disable to never use block splitter.
 * Set to ZSTD_ps_enable to always use block splitter.
 *
 * By default, in ZSTD_ps_auto, the library will decide at runtime whether to use
 * block splitting based on the compression parameters.
 */
#define ZSTD_c_splitAfterSequences ZSTD_c_experimentalParam13

/* ZSTD_c_useRowMatchFinder
 * Controlled with ZSTD_ParamSwitch_e enum.
 * Default is ZSTD_ps_auto.
 * Set to ZSTD_ps_disable to never use row-based matchfinder.
 * Set to ZSTD_ps_enable to force usage of row-based matchfinder.
 *
 * By default, in ZSTD_ps_auto, the library will decide at runtime whether to use
 * the row-based matchfinder based on support for SIMD instructions and the window log.
 * Note that this only pertains to compression strategies: greedy, lazy, and lazy2
 */
#define ZSTD_c_useRowMatchFinder ZSTD_c_experimentalParam14

/* ZSTD_c_deterministicRefPrefix
 * Default is 0 == disabled. Set to 1 to enable.
 *
 * Zstd produces different results for prefix compression when the prefix is
 * directly adjacent to the data about to be compressed vs. when it isn't.
 * This is because zstd detects that the two buffers are contiguous and it can
 * use a more efficient match finding algorithm. However, this produces different
 * results than when the two buffers are non-contiguous. This flag forces zstd
 * to always load the prefix in non-contiguous mode, even if it happens to be
 * adjacent to the data, to guarantee determinism.
 *
 * If you really care about determinism when using a dictionary or prefix,
 * like when doing delta compression, you should select this option. It comes
 * at a speed penalty of about ~2.5% if the dictionary and data happened to be
 * contiguous, and is free if they weren't contiguous. We don't expect that
 * intentionally making the dictionary and data contiguous will be worth the
 * cost to memcpy() the data.
 */
#define ZSTD_c_deterministicRefPrefix ZSTD_c_experimentalParam15

/* ZSTD_c_prefetchCDictTables
 * Controlled with ZSTD_ParamSwitch_e enum. Default is ZSTD_ps_auto.
 *
 * In some situations, zstd uses CDict tables in-place rather than copying them
 * into the working context. (See docs on ZSTD_dictAttachPref_e above for details).
 * In such situations, compression speed is seriously impacted when CDict tables are
 * "cold" (outside CPU cache). This parameter instructs zstd to prefetch CDict tables
 * when they are used in-place.
 *
 * For sufficiently small inputs, the cost of the prefetch will outweigh the benefit.
 * For sufficiently large inputs, zstd will by default memcpy() CDict tables
 * into the working context, so there is no need to prefetch. This parameter is
 * targeted at a middle range of input sizes, where a prefetch is cheap enough to be
 * useful but memcpy() is too expensive. The exact range of input sizes where this
 * makes sense is best determined by careful experimentation.
 *
 * Note: for this parameter, ZSTD_ps_auto is currently equivalent to ZSTD_ps_disable,
 * but in the future zstd may conditionally enable this feature via an auto-detection
 * heuristic for cold CDicts.
 * Use ZSTD_ps_disable to opt out of prefetching under any circumstances.
 */
#define ZSTD_c_prefetchCDictTables ZSTD_c_experimentalParam16

/* ZSTD_c_enableSeqProducerFallback
 * Allowed values are 0 (disable) and 1 (enable). The default setting is 0.
 *
 * Controls whether zstd will fall back to an internal sequence producer if an
 * external sequence producer is registered and returns an error code. This fallback
 * is block-by-block: the internal sequence producer will only be called for blocks
 * where the external sequence producer returns an error code. Fallback parsing will
 * follow any other cParam settings, such as compression level, the same as in a
 * normal (fully-internal) compression operation.
 *
 * The user is strongly encouraged to read the full Block-Level Sequence Producer API
 * documentation (below) before setting this parameter. */
#define ZSTD_c_enableSeqProducerFallback ZSTD_c_experimentalParam17

/* ZSTD_c_maxBlockSize
 * Allowed values are between 1KB and ZSTD_BLOCKSIZE_MAX (128KB).
 * The default is ZSTD_BLOCKSIZE_MAX, and setting to 0 will set to the default.
 *
 * This parameter can be used to set an upper bound on the blocksize
 * that overrides the default ZSTD_BLOCKSIZE_MAX. It cannot be used to set upper
 * bounds greater than ZSTD_BLOCKSIZE_MAX or bounds lower than 1KB (will make
 * compressBound() inaccurate). Only currently meant to be used for testing.
 */
#define ZSTD_c_maxBlockSize ZSTD_c_experimentalParam18

/* ZSTD_c_repcodeResolution
 * This parameter only has an effect if ZSTD_c_blockDelimiters is
 * set to ZSTD_sf_explicitBlockDelimiters (may change in the future).
 *
 * This parameter affects how zstd parses external sequences,
 * provided via the ZSTD_compressSequences*() API
 * or from an external block-level sequence producer.
 *
 * If set to ZSTD_ps_enable, the library will check for repeated offsets within
 * external sequences, even if those repcodes are not explicitly indicated in
 * the "rep" field. Note that this is the only way to exploit repcode matches
 * while using compressSequences*() or an external sequence producer, since zstd
 * currently ignores the "rep" field of external sequences.
 *
 * If set to ZSTD_ps_disable, the library will not exploit repeated offsets in
 * external sequences, regardless of whether the "rep" field has been set. This
 * reduces sequence compression overhead by about 25% while sacrificing some
 * compression ratio.
 *
 * The default value is ZSTD_ps_auto, for which the library will enable/disable
 * based on compression level (currently: level<10 disables, level>=10 enables).
 */
#define ZSTD_c_repcodeResolution ZSTD_c_experimentalParam19
#define ZSTD_c_searchForExternalRepcodes ZSTD_c_experimentalParam19 /* older name */


/*! ZSTD_CCtx_getParameter() :
 *  Get the requested compression parameter value, selected by enum ZSTD_cParameter,
 *  and store it into int* value.
 * @return : 0, or an error code (which can be tested with ZSTD_isError()).
 */
ZSTDLIB_STATIC_API size_t ZSTD_CCtx_getParameter(const ZSTD_CCtx* cctx, ZSTD_cParameter param, int* value);


/*! ZSTD_CCtx_params :
 *  Quick howto :
 *  - ZSTD_createCCtxParams() : Create a ZSTD_CCtx_params structure
 *  - ZSTD_CCtxParams_setParameter() : Push parameters one by one into
 *                                     an existing ZSTD_CCtx_params structure.
 *                                     This is similar to
 *                                     ZSTD_CCtx_setParameter().
 *  - ZSTD_CCtx_setParametersUsingCCtxParams() : Apply parameters to
 *                                    an existing CCtx.
 *                                    These parameters will be applied to
 *                                    all subsequent frames.
 *  - ZSTD_compressStream2() : Do compression using the CCtx.
 *  - ZSTD_freeCCtxParams() : Free the memory, accept NULL pointer.
 *
 *  This can be used with ZSTD_estimateCCtxSize_advanced_usingCCtxParams()
 *  for static allocation of CCtx for single-threaded compression.
 */
ZSTDLIB_STATIC_API ZSTD_CCtx_params* ZSTD_createCCtxParams(void);
ZSTDLIB_STATIC_API size_t ZSTD_freeCCtxParams(ZSTD_CCtx_params* params);  /* accept NULL pointer */

/*! ZSTD_CCtxParams_reset() :
 *  Reset params to default values.
 */
ZSTDLIB_STATIC_API size_t ZSTD_CCtxParams_reset(ZSTD_CCtx_params* params);

/*! ZSTD_CCtxParams_init() :
 *  Initializes the compression parameters of cctxParams according to
 *  compression level. All other parameters are reset to their default values.
 */
ZSTDLIB_STATIC_API size_t ZSTD_CCtxParams_init(ZSTD_CCtx_params* cctxParams, int compressionLevel);

/*! ZSTD_CCtxParams_init_advanced() :
 *  Initializes the compression and frame parameters of cctxParams according to
 *  params. All other parameters are reset to their default values.
 */
ZSTDLIB_STATIC_API size_t ZSTD_CCtxParams_init_advanced(ZSTD_CCtx_params* cctxParams, ZSTD_parameters params);

/*! ZSTD_CCtxParams_setParameter() : Requires v1.4.0+
 *  Similar to ZSTD_CCtx_setParameter.
 *  Set one compression parameter, selected by enum ZSTD_cParameter.
 *  Parameters must be applied to a ZSTD_CCtx using
 *  ZSTD_CCtx_setParametersUsingCCtxParams().
 * @result : a code representing success or failure (which can be tested with
 *           ZSTD_isError()).
 */
ZSTDLIB_STATIC_API size_t ZSTD_CCtxParams_setParameter(ZSTD_CCtx_params* params, ZSTD_cParameter param, int value);

/*! ZSTD_CCtxParams_getParameter() :
 * Similar to ZSTD_CCtx_getParameter.
 * Get the requested value of one compression parameter, selected by enum ZSTD_cParameter.
 * @result : 0, or an error code (which can be tested with ZSTD_isError()).
 */
ZSTDLIB_STATIC_API size_t ZSTD_CCtxParams_getParameter(const ZSTD_CCtx_params* params, ZSTD_cParameter param, int* value);

/*! ZSTD_CCtx_setParametersUsingCCtxParams() :
 *  Apply a set of ZSTD_CCtx_params to the compression context.
 *  This can be done even after compression is started,
 *    if nbWorkers==0, this will have no impact until a new compression is started.
 *    if nbWorkers>=1, new parameters will be picked up at next job,
 *       with a few restrictions (windowLog, pledgedSrcSize, nbWorkers, jobSize, and overlapLog are not updated).
 */
ZSTDLIB_STATIC_API size_t ZSTD_CCtx_setParametersUsingCCtxParams(
        ZSTD_CCtx* cctx, const ZSTD_CCtx_params* params);

/*! ZSTD_compressStream2_simpleArgs() :
 *  Same as ZSTD_compressStream2(),
 *  but using only integral types as arguments.
 *  This variant might be helpful for binders from dynamic languages
 *  which have troubles handling structures containing memory pointers.
 */
ZSTDLIB_STATIC_API size_t ZSTD_compressStream2_simpleArgs (
                            ZSTD_CCtx* cctx,
                            void* dst, size_t dstCapacity, size_t* dstPos,
                      const void* src, size_t srcSize, size_t* srcPos,
                            ZSTD_EndDirective endOp);


/***************************************
*  Advanced decompression functions
***************************************/

/*! ZSTD_isFrame() :
 *  Tells if the content of `buffer` starts with a valid Frame Identifier.
 *  Note : Frame Identifier is 4 bytes. If `size < 4`, @return will always be 0.
 *  Note 2 : Legacy Frame Identifiers are considered valid only if Legacy Support is enabled.
 *  Note 3 : Skippable Frame Identifiers are considered valid. */
ZSTDLIB_STATIC_API unsigned ZSTD_isFrame(const void* buffer, size_t size);

/*! ZSTD_createDDict_byReference() :
 *  Create a digested dictionary, ready to start decompression operation without startup delay.
 *  Dictionary content is referenced, and therefore stays in dictBuffer.
 *  It is important that dictBuffer outlives DDict,
 *  it must remain read accessible throughout the lifetime of DDict */
ZSTDLIB_STATIC_API ZSTD_DDict* ZSTD_createDDict_byReference(const void* dictBuffer, size_t dictSize);

/*! ZSTD_DCtx_loadDictionary_byReference() :
 *  Same as ZSTD_DCtx_loadDictionary(),
 *  but references `dict` content instead of copying it into `dctx`.
 *  This saves memory if `dict` remains around.,
 *  However, it's imperative that `dict` remains accessible (and unmodified) while being used, so it must outlive decompression. */
ZSTDLIB_STATIC_API size_t ZSTD_DCtx_loadDictionary_byReference(ZSTD_DCtx* dctx, const void* dict, size_t dictSize);

/*! ZSTD_DCtx_loadDictionary_advanced() :
 *  Same as ZSTD_DCtx_loadDictionary(),
 *  but gives direct control over
 *  how to load the dictionary (by copy ? by reference ?)
 *  and how to interpret it (automatic ? force raw mode ? full mode only ?). */
ZSTDLIB_STATIC_API size_t ZSTD_DCtx_loadDictionary_advanced(ZSTD_DCtx* dctx, const void* dict, size_t dictSize, ZSTD_dictLoadMethod_e dictLoadMethod, ZSTD_dictContentType_e dictContentType);

/*! ZSTD_DCtx_refPrefix_advanced() :
 *  Same as ZSTD_DCtx_refPrefix(), but gives finer control over
 *  how to interpret prefix content (automatic ? force raw mode (default) ? full mode only ?) */
ZSTDLIB_STATIC_API size_t ZSTD_DCtx_refPrefix_advanced(ZSTD_DCtx* dctx, const void* prefix, size_t prefixSize, ZSTD_dictContentType_e dictContentType);

/*! ZSTD_DCtx_setMaxWindowSize() :
 *  Refuses allocating internal buffers for frames requiring a window size larger than provided limit.
 *  This protects a decoder context from reserving too much memory for itself (potential attack scenario).
 *  This parameter is only useful in streaming mode, since no internal buffer is allocated in single-pass mode.
 *  By default, a decompression context accepts all window sizes <= (1 << ZSTD_WINDOWLOG_LIMIT_DEFAULT)
 * @return : 0, or an error code (which can be tested using ZSTD_isError()).
 */
ZSTDLIB_STATIC_API size_t ZSTD_DCtx_setMaxWindowSize(ZSTD_DCtx* dctx, size_t maxWindowSize);

/*! ZSTD_DCtx_getParameter() :
 *  Get the requested decompression parameter value, selected by enum ZSTD_dParameter,
 *  and store it into int* value.
 * @return : 0, or an error code (which can be tested with ZSTD_isError()).
 */
ZSTDLIB_STATIC_API size_t ZSTD_DCtx_getParameter(ZSTD_DCtx* dctx, ZSTD_dParameter param, int* value);

/* ZSTD_d_format
 * experimental parameter,
 * allowing selection between ZSTD_format_e input compression formats
 */
#define ZSTD_d_format ZSTD_d_experimentalParam1
/* ZSTD_d_stableOutBuffer
 * Experimental parameter.
 * Default is 0 == disabled. Set to 1 to enable.
 *
 * Tells the decompressor that the ZSTD_outBuffer will ALWAYS be the same
 * between calls, except for the modifications that zstd makes to pos (the
 * caller must not modify pos). This is checked by the decompressor, and
 * decompression will fail if it ever changes. Therefore the ZSTD_outBuffer
 * MUST be large enough to fit the entire decompressed frame. This will be
 * checked when the frame content size is known. The data in the ZSTD_outBuffer
 * in the range [dst, dst + pos) MUST not be modified during decompression
 * or you will get data corruption.
 *
 * When this flag is enabled zstd won't allocate an output buffer, because
 * it can write directly to the ZSTD_outBuffer, but it will still allocate
 * an input buffer large enough to fit any compressed block. This will also
 * avoid the memcpy() from the internal output buffer to the ZSTD_outBuffer.
 * If you need to avoid the input buffer allocation use the buffer-less
 * streaming API.
 *
 * NOTE: So long as the ZSTD_outBuffer always points to valid memory, using
 * this flag is ALWAYS memory safe, and will never access out-of-bounds
 * memory. However, decompression WILL fail if you violate the preconditions.
 *
 * WARNING: The data in the ZSTD_outBuffer in the range [dst, dst + pos) MUST
 * not be modified during decompression or you will get data corruption. This
 * is because zstd needs to reference data in the ZSTD_outBuffer to regenerate
 * matches. Normally zstd maintains its own buffer for this purpose, but passing
 * this flag tells zstd to use the user provided buffer.
 */
#define ZSTD_d_stableOutBuffer ZSTD_d_experimentalParam2

/* ZSTD_d_forceIgnoreChecksum
 * Experimental parameter.
 * Default is 0 == disabled. Set to 1 to enable
 *
 * Tells the decompressor to skip checksum validation during decompression, regardless
 * of whether checksumming was specified during compression. This offers some
 * slight performance benefits, and may be useful for debugging.
 * Param has values of type ZSTD_forceIgnoreChecksum_e
 */
#define ZSTD_d_forceIgnoreChecksum ZSTD_d_experimentalParam3

/* ZSTD_d_refMultipleDDicts
 * Experimental parameter.
 * Default is 0 == disabled. Set to 1 to enable
 *
 * If enabled and dctx is allocated on the heap, then additional memory will be allocated
 * to store references to multiple ZSTD_DDict. That is, multiple calls of ZSTD_refDDict()
 * using a given ZSTD_DCtx, rather than overwriting the previous DDict reference, will instead
 * store all references. At decompression time, the appropriate dictID is selected
 * from the set of DDicts based on the dictID in the frame.
 *
 * Usage is simply calling ZSTD_refDDict() on multiple dict buffers.
 *
 * Param has values of byte ZSTD_refMultipleDDicts_e
 *
 * WARNING: Enabling this parameter and calling ZSTD_DCtx_refDDict(), will trigger memory
 * allocation for the hash table. ZSTD_freeDCtx() also frees this memory.
 * Memory is allocated as per ZSTD_DCtx::customMem.
 *
 * Although this function allocates memory for the table, the user is still responsible for
 * memory management of the underlying ZSTD_DDict* themselves.
 */
#define ZSTD_d_refMultipleDDicts ZSTD_d_experimentalParam4

/* ZSTD_d_disableHuffmanAssembly
 * Set to 1 to disable the Huffman assembly implementation.
 * The default value is 0, which allows zstd to use the Huffman assembly
 * implementation if available.
 *
 * This parameter can be used to disable Huffman assembly at runtime.
 * If you want to disable it at compile time you can define the macro
 * ZSTD_DISABLE_ASM.
 */
#define ZSTD_d_disableHuffmanAssembly ZSTD_d_experimentalParam5

/* ZSTD_d_maxBlockSize
 * Allowed values are between 1KB and ZSTD_BLOCKSIZE_MAX (128KB).
 * The default is ZSTD_BLOCKSIZE_MAX, and setting to 0 will set to the default.
 *
 * Forces the decompressor to reject blocks whose content size is
 * larger than the configured maxBlockSize. When maxBlockSize is
 * larger than the windowSize, the windowSize is used instead.
 * This saves memory on the decoder when you know all blocks are small.
 *
 * This option is typically used in conjunction with ZSTD_c_maxBlockSize.
 *
 * WARNING: This causes the decoder to reject otherwise valid frames
 * that have block sizes larger than the configured maxBlockSize.
 */
#define ZSTD_d_maxBlockSize ZSTD_d_experimentalParam6


/*! ZSTD_DCtx_setFormat() :
 *  This function is REDUNDANT. Prefer ZSTD_DCtx_setParameter().
 *  Instruct the decoder context about what kind of data to decode next.
 *  This instruction is mandatory to decode data without a fully-formed header,
 *  such ZSTD_f_zstd1_magicless for example.
 * @return : 0, or an error code (which can be tested using ZSTD_isError()). */
ZSTD_DEPRECATED("use ZSTD_DCtx_setParameter() instead")
ZSTDLIB_STATIC_API
size_t ZSTD_DCtx_setFormat(ZSTD_DCtx* dctx, ZSTD_format_e format);

/*! ZSTD_decompressStream_simpleArgs() :
 *  Same as ZSTD_decompressStream(),
 *  but using only integral types as arguments.
 *  This can be helpful for binders from dynamic languages
 *  which have troubles handling structures containing memory pointers.
 */
ZSTDLIB_STATIC_API size_t ZSTD_decompressStream_simpleArgs (
                            ZSTD_DCtx* dctx,
                            void* dst, size_t dstCapacity, size_t* dstPos,
                      const void* src, size_t srcSize, size_t* srcPos);


/********************************************************************
*  Advanced streaming functions
*  Warning : most of these functions are now redundant with the Advanced API.
*  Once Advanced API reaches "stable" status,
*  redundant functions will be deprecated, and then at some point removed.
********************************************************************/

/*=====   Advanced Streaming compression functions  =====*/

/*! ZSTD_initCStream_srcSize() :
 * This function is DEPRECATED, and equivalent to:
 *     ZSTD_CCtx_reset(zcs, ZSTD_reset_session_only);
 *     ZSTD_CCtx_refCDict(zcs, NULL); // clear the dictionary (if any)
 *     ZSTD_CCtx_setParameter(zcs, ZSTD_c_compressionLevel, compressionLevel);
 *     ZSTD_CCtx_setPledgedSrcSize(zcs, pledgedSrcSize);
 *
 * pledgedSrcSize must be correct. If it is not known at init time, use
 * ZSTD_CONTENTSIZE_UNKNOWN. Note that, for compatibility with older programs,
 * "0" also disables frame content size field. It may be enabled in the future.
 * This prototype will generate compilation warnings.
 */
ZSTD_DEPRECATED("use ZSTD_CCtx_reset, see zstd.h for detailed instructions")
ZSTDLIB_STATIC_API
size_t ZSTD_initCStream_srcSize(ZSTD_CStream* zcs,
                         int compressionLevel,
                         unsigned long long pledgedSrcSize);

/*! ZSTD_initCStream_usingDict() :
 * This function is DEPRECATED, and is equivalent to:
 *     ZSTD_CCtx_reset(zcs, ZSTD_reset_session_only);
 *     ZSTD_CCtx_setParameter(zcs, ZSTD_c_compressionLevel, compressionLevel);
 *     ZSTD_CCtx_loadDictionary(zcs, dict, dictSize);
 *
 * Creates of an internal CDict (incompatible with static CCtx), except if
 * dict == NULL or dictSize < 8, in which case no dict is used.
 * Note: dict is loaded with ZSTD_dct_auto (treated as a full zstd dictionary if
 * it begins with ZSTD_MAGIC_DICTIONARY, else as raw content) and ZSTD_dlm_byCopy.
 * This prototype will generate compilation warnings.
 */
ZSTD_DEPRECATED("use ZSTD_CCtx_reset, see zstd.h for detailed instructions")
ZSTDLIB_STATIC_API
size_t ZSTD_initCStream_usingDict(ZSTD_CStream* zcs,
                     const void* dict, size_t dictSize,
                           int compressionLevel);

/*! ZSTD_initCStream_advanced() :
 * This function is DEPRECATED, and is equivalent to:
 *     ZSTD_CCtx_reset(zcs, ZSTD_reset_session_only);
 *     ZSTD_CCtx_setParams(zcs, params);
 *     ZSTD_CCtx_setPledgedSrcSize(zcs, pledgedSrcSize);
 *     ZSTD_CCtx_loadDictionary(zcs, dict, dictSize);
 *
 * dict is loaded with ZSTD_dct_auto and ZSTD_dlm_byCopy.
 * pledgedSrcSize must be correct.
 * If srcSize is not known at init time, use value ZSTD_CONTENTSIZE_UNKNOWN.
 * This prototype will generate compilation warnings.
 */
ZSTD_DEPRECATED("use ZSTD_CCtx_reset, see zstd.h for detailed instructions")
ZSTDLIB_STATIC_API
size_t ZSTD_initCStream_advanced(ZSTD_CStream* zcs,
                    const void* dict, size_t dictSize,
                          ZSTD_parameters params,
                          unsigned long long pledgedSrcSize);

/*! ZSTD_initCStream_usingCDict() :
 * This function is DEPRECATED, and equivalent to:
 *     ZSTD_CCtx_reset(zcs, ZSTD_reset_session_only);
 *     ZSTD_CCtx_refCDict(zcs, cdict);
 *
 * note : cdict will just be referenced, and must outlive compression session
 * This prototype will generate compilation warnings.
 */
ZSTD_DEPRECATED("use ZSTD_CCtx_reset and ZSTD_CCtx_refCDict, see zstd.h for detailed instructions")
ZSTDLIB_STATIC_API
size_t ZSTD_initCStream_usingCDict(ZSTD_CStream* zcs, const ZSTD_CDict* cdict);

/*! ZSTD_initCStream_usingCDict_advanced() :
 *   This function is DEPRECATED, and is equivalent to:
 *     ZSTD_CCtx_reset(zcs, ZSTD_reset_session_only);
 *     ZSTD_CCtx_setFParams(zcs, fParams);
 *     ZSTD_CCtx_setPledgedSrcSize(zcs, pledgedSrcSize);
 *     ZSTD_CCtx_refCDict(zcs, cdict);
 *
 * same as ZSTD_initCStream_usingCDict(), with control over frame parameters.
 * pledgedSrcSize must be correct. If srcSize is not known at init time, use
 * value ZSTD_CONTENTSIZE_UNKNOWN.
 * This prototype will generate compilation warnings.
 */
ZSTD_DEPRECATED("use ZSTD_CCtx_reset and ZSTD_CCtx_refCDict, see zstd.h for detailed instructions")
ZSTDLIB_STATIC_API
size_t ZSTD_initCStream_usingCDict_advanced(ZSTD_CStream* zcs,
                               const ZSTD_CDict* cdict,
                                     ZSTD_frameParameters fParams,
                                     unsigned long long pledgedSrcSize);

/*! ZSTD_resetCStream() :
 * This function is DEPRECATED, and is equivalent to:
 *     ZSTD_CCtx_reset(zcs, ZSTD_reset_session_only);
 *     ZSTD_CCtx_setPledgedSrcSize(zcs, pledgedSrcSize);
 * Note: ZSTD_resetCStream() interprets pledgedSrcSize == 0 as ZSTD_CONTENTSIZE_UNKNOWN, but
 *       ZSTD_CCtx_setPledgedSrcSize() does not do the same, so ZSTD_CONTENTSIZE_UNKNOWN must be
 *       explicitly specified.
 *
 *  start a new frame, using same parameters from previous frame.
 *  This is typically useful to skip dictionary loading stage, since it will reuse it in-place.
 *  Note that zcs must be init at least once before using ZSTD_resetCStream().
 *  If pledgedSrcSize is not known at reset time, use macro ZSTD_CONTENTSIZE_UNKNOWN.
 *  If pledgedSrcSize > 0, its value must be correct, as it will be written in header, and controlled at the end.
 *  For the time being, pledgedSrcSize==0 is interpreted as "srcSize unknown" for compatibility with older programs,
 *  but it will change to mean "empty" in future version, so use macro ZSTD_CONTENTSIZE_UNKNOWN instead.
 * @return : 0, or an error code (which can be tested using ZSTD_isError())
 *  This prototype will generate compilation warnings.
 */
ZSTD_DEPRECATED("use ZSTD_CCtx_reset, see zstd.h for detailed instructions")
ZSTDLIB_STATIC_API
size_t ZSTD_resetCStream(ZSTD_CStream* zcs, unsigned long long pledgedSrcSize);


typedef struct {
    unsigned long long ingested;   /* nb input bytes read and buffered */
    unsigned long long consumed;   /* nb input bytes actually compressed */
    unsigned long long produced;   /* nb of compressed bytes generated and buffered */
    unsigned long long flushed;    /* nb of compressed bytes flushed : not provided; can be tracked from caller side */
    unsigned currentJobID;         /* MT only : latest started job nb */
    unsigned nbActiveWorkers;      /* MT only : nb of workers actively compressing at probe time */
} ZSTD_frameProgression;

/* ZSTD_getFrameProgression() :
 * tells how much data has been ingested (read from input)
 * consumed (input actually compressed) and produced (output) for current frame.
 * Note : (ingested - consumed) is amount of input data buffered internally, not yet compressed.
 * Aggregates progression inside active worker threads.
 */
ZSTDLIB_STATIC_API ZSTD_frameProgression ZSTD_getFrameProgression(const ZSTD_CCtx* cctx);

/*! ZSTD_toFlushNow() :
 *  Tell how many bytes are ready to be flushed immediately.
 *  Useful for multithreading scenarios (nbWorkers >= 1).
 *  Probe the oldest active job, defined as oldest job not yet entirely flushed,
 *  and check its output buffer.
 * @return : amount of data stored in oldest job and ready to be flushed immediately.
 *  if @return == 0, it means either :
 *  + there is no active job (could be checked with ZSTD_frameProgression()), or
 *  + oldest job is still actively compressing data,
 *    but everything it has produced has also been flushed so far,
 *    therefore flush speed is limited by production speed of oldest job
 *    irrespective of the speed of concurrent (and newer) jobs.
 */
ZSTDLIB_STATIC_API size_t ZSTD_toFlushNow(ZSTD_CCtx* cctx);


/*=====   Advanced Streaming decompression functions  =====*/

/*!
 * This function is deprecated, and is equivalent to:
 *
 *     ZSTD_DCtx_reset(zds, ZSTD_reset_session_only);
 *     ZSTD_DCtx_loadDictionary(zds, dict, dictSize);
 *
 * note: no dictionary will be used if dict == NULL or dictSize < 8
 */
ZSTD_DEPRECATED("use ZSTD_DCtx_reset + ZSTD_DCtx_loadDictionary, see zstd.h for detailed instructions")
ZSTDLIB_STATIC_API size_t ZSTD_initDStream_usingDict(ZSTD_DStream* zds, const void* dict, size_t dictSize);

/*!
 * This function is deprecated, and is equivalent to:
 *
 *     ZSTD_DCtx_reset(zds, ZSTD_reset_session_only);
 *     ZSTD_DCtx_refDDict(zds, ddict);
 *
 * note : ddict is referenced, it must outlive decompression session
 */
ZSTD_DEPRECATED("use ZSTD_DCtx_reset + ZSTD_DCtx_refDDict, see zstd.h for detailed instructions")
ZSTDLIB_STATIC_API size_t ZSTD_initDStream_usingDDict(ZSTD_DStream* zds, const ZSTD_DDict* ddict);

/*!
 * This function is deprecated, and is equivalent to:
 *
 *     ZSTD_DCtx_reset(zds, ZSTD_reset_session_only);
 *
 * reuse decompression parameters from previous init; saves dictionary loading
 */
ZSTD_DEPRECATED("use ZSTD_DCtx_reset, see zstd.h for detailed instructions")
ZSTDLIB_STATIC_API size_t ZSTD_resetDStream(ZSTD_DStream* zds);


/* ********************* BLOCK-LEVEL SEQUENCE PRODUCER API *********************
 *
 * *** OVERVIEW ***
 * The Block-Level Sequence Producer API allows users to provide their own custom
 * sequence producer which libzstd invokes to process each block. The produced list
 * of sequences (literals and matches) is then post-processed by libzstd to produce
 * valid compressed blocks.
 *
 * This block-level offload API is a more granular complement of the existing
 * frame-level offload API compressSequences() (introduced in v1.5.1). It offers
 * an easier migration story for applications already integrated with libzstd: the
 * user application continues to invoke the same compression functions
 * ZSTD_compress2() or ZSTD_compressStream2() as usual, and transparently benefits
 * from the specific advantages of the external sequence producer. For example,
 * the sequence producer could be tuned to take advantage of known characteristics
 * of the input, to offer better speed / ratio, or could leverage hardware
 * acceleration not available within libzstd itself.
 *
 * See contrib/externalSequenceProducer for an example program employing the
 * Block-Level Sequence Producer API.
 *
 * *** USAGE ***
 * The user is responsible for implementing a function of type
 * ZSTD_sequenceProducer_F. For each block, zstd will pass the following
 * arguments to the user-provided function:
 *
 *   - sequenceProducerState: a pointer to a user-managed state for the sequence
 *     producer.
 *
 *   - outSeqs, outSeqsCapacity: an output buffer for the sequence producer.
 *     outSeqsCapacity is guaranteed >= ZSTD_sequenceBound(srcSize). The memory
 *     backing outSeqs is managed by the CCtx.
 *
 *   - src, srcSize: an input buffer for the sequence producer to parse.
 *     srcSize is guaranteed to be <= ZSTD_BLOCKSIZE_MAX.
 *
 *   - dict, dictSize: a history buffer, which may be empty, which the sequence
 *     producer may reference as it parses the src buffer. Currently, zstd will
 *     always pass dictSize == 0 into external sequence producers, but this will
 *     change in the future.
 *
 *   - compressionLevel: a signed integer representing the zstd compression level
 *     set by the user for the current operation. The sequence producer may choose
 *     to use this information to change its compression strategy and speed/ratio
 *     tradeoff. Note: the compression level does not reflect zstd parameters set
 *     through the advanced API.
 *
 *   - windowSize: a size_t representing the maximum allowed offset for external
 *     sequences. Note that sequence offsets are sometimes allowed to exceed the
 *     windowSize if a dictionary is present, see doc/zstd_compression_format.md
 *     for details.
 *
 * The user-provided function shall return a size_t representing the number of
 * sequences written to outSeqs. This return value will be treated as an error
 * code if it is greater than outSeqsCapacity. The return value must be non-zero
 * if srcSize is non-zero. The ZSTD_SEQUENCE_PRODUCER_ERROR macro is provided
 * for convenience, but any value greater than outSeqsCapacity will be treated as
 * an error code.
 *
 * If the user-provided function does not return an error code, the sequences
 * written to outSeqs must be a valid parse of the src buffer. Data corruption may
 * occur if the parse is not valid. A parse is defined to be valid if the
 * following conditions hold:
 *   - The sum of matchLengths and literalLengths must equal srcSize.
 *   - All sequences in the parse, except for the final sequence, must have
 *     matchLength >= ZSTD_MINMATCH_MIN. The final sequence must have
 *     matchLength >= ZSTD_MINMATCH_MIN or matchLength == 0.
 *   - All offsets must respect the windowSize parameter as specified in
 *     doc/zstd_compression_format.md.
 *   - If the final sequence has matchLength == 0, it must also have offset == 0.
 *
 * zstd will only validate these conditions (and fail compression if they do not
 * hold) if the ZSTD_c_validateSequences cParam is enabled. Note that sequence
 * validation has a performance cost.
 *
 * If the user-provided function returns an error, zstd will either fall back
 * to an internal sequence producer or fail the compression operation. The user can
 * choose between the two behaviors by setting the ZSTD_c_enableSeqProducerFallback
 * cParam. Fallback compression will follow any other cParam settings, such as
 * compression level, the same as in a normal compression operation.
 *
 * The user shall instruct zstd to use a particular ZSTD_sequenceProducer_F
 * function by calling
 *         ZSTD_registerSequenceProducer(cctx,
 *                                       sequenceProducerState,
 *                                       sequenceProducer)
 * This setting will persist until the next parameter reset of the CCtx.
 *
 * The sequenceProducerState must be initialized by the user before calling
 * ZSTD_registerSequenceProducer(). The user is responsible for destroying the
 * sequenceProducerState.
 *
 * *** LIMITATIONS ***
 * This API is compatible with all zstd compression APIs which respect advanced parameters.
 * However, there are three limitations:
 *
 * First, the ZSTD_c_enableLongDistanceMatching cParam is not currently supported.
 * COMPRESSION WILL FAIL if it is enabled and the user tries to compress with a block-level
 * external sequence producer.
 *   - Note that ZSTD_c_enableLongDistanceMatching is auto-enabled by default in some
 *     cases (see its documentation for details). Users must explicitly set
 *     ZSTD_c_enableLongDistanceMatching to ZSTD_ps_disable in such cases if an external
 *     sequence producer is registered.
 *   - As of this writing, ZSTD_c_enableLongDistanceMatching is disabled by default
 *     whenever ZSTD_c_windowLog < 128MB, but that's subject to change. Users should
 *     check the docs on ZSTD_c_enableLongDistanceMatching whenever the Block-Level Sequence
 *     Producer API is used in conjunction with advanced settings (like ZSTD_c_windowLog).
 *
 * Second, history buffers are not currently supported. Concretely, zstd will always pass
 * dictSize == 0 to the external sequence producer (for now). This has two implications:
 *   - Dictionaries are not currently supported. Compression will *not* fail if the user
 *     references a dictionary, but the dictionary won't have any effect.
 *   - Stream history is not currently supported. All advanced compression APIs, including
 *     streaming APIs, work with external sequence producers, but each block is treated as
 *     an independent chunk without history from previous blocks.
 *
 * Third, multi-threading within a single compression is not currently supported. In other words,
 * COMPRESSION WILL FAIL if ZSTD_c_nbWorkers > 0 and an external sequence producer is registered.
 * Multi-threading across compressions is fine: simply create one CCtx per thread.
 *
 * Long-term, we plan to overcome all three limitations. There is no technical blocker to
 * overcoming them. It is purely a question of engineering effort.
 */

#define ZSTD_SEQUENCE_PRODUCER_ERROR ((size_t)(-1))

typedef size_t (*ZSTD_sequenceProducer_F) (
  void* sequenceProducerState,
  ZSTD_Sequence* outSeqs, size_t outSeqsCapacity,
  const void* src, size_t srcSize,
  const void* dict, size_t dictSize,
  int compressionLevel,
  size_t windowSize
);

/*! ZSTD_registerSequenceProducer() :
 * Instruct zstd to use a block-level external sequence producer function.
 *
 * The sequenceProducerState must be initialized by the caller, and the caller is
 * responsible for managing its lifetime. This parameter is sticky across
 * compressions. It will remain set until the user explicitly resets compression
 * parameters.
 *
 * Sequence producer registration is considered to be an "advanced parameter",
 * part of the "advanced API". This means it will only have an effect on compression
 * APIs which respect advanced parameters, such as compress2() and compressStream2().
 * Older compression APIs such as compressCCtx(), which predate the introduction of
 * "advanced parameters", will ignore any external sequence producer setting.
 *
 * The sequence producer can be "cleared" by registering a NULL function pointer. This
 * removes all limitations described above in the "LIMITATIONS" section of the API docs.
 *
 * The user is strongly encouraged to read the full API documentation (above) before
 * calling this function. */
ZSTDLIB_STATIC_API void
ZSTD_registerSequenceProducer(
  ZSTD_CCtx* cctx,
  void* sequenceProducerState,
  ZSTD_sequenceProducer_F sequenceProducer
);

/*! ZSTD_CCtxParams_registerSequenceProducer() :
 * Same as ZSTD_registerSequenceProducer(), but operates on ZSTD_CCtx_params.
 * This is used for accurate size estimation with ZSTD_estimateCCtxSize_usingCCtxParams(),
 * which is needed when creating a ZSTD_CCtx with ZSTD_initStaticCCtx().
 *
 * If you are using the external sequence producer API in a scenario where ZSTD_initStaticCCtx()
 * is required, then this function is for you. Otherwise, you probably don't need it.
 *
 * See tests/zstreamtest.c for example usage. */
ZSTDLIB_STATIC_API void
ZSTD_CCtxParams_registerSequenceProducer(
  ZSTD_CCtx_params* params,
  void* sequenceProducerState,
  ZSTD_sequenceProducer_F sequenceProducer
);


/*********************************************************************
*  Buffer-less and synchronous inner streaming functions (DEPRECATED)
*
*  This API is deprecated, and will be removed in a future version.
*  It allows streaming (de)compression with user allocated buffers.
*  However, it is hard to use, and not as well tested as the rest of
*  our API.
*
*  Please use the normal streaming API instead: ZSTD_compressStream2,
*  and ZSTD_decompressStream.
*  If there is functionality that you need, but it doesn't provide,
*  please open an issue on our GitHub.
********************************************************************* */

/**
  Buffer-less streaming compression (synchronous mode)

  A ZSTD_CCtx object is required to track streaming operations.
  Use ZSTD_createCCtx() / ZSTD_freeCCtx() to manage resource.
  ZSTD_CCtx object can be reused multiple times within successive compression operations.

  Start by initializing a context.
  Use ZSTD_compressBegin(), or ZSTD_compressBegin_usingDict() for dictionary compression.

  Then, consume your input using ZSTD_compressContinue().
  There are some important considerations to keep in mind when using this advanced function :
  - ZSTD_compressContinue() has no internal buffer. It uses externally provided buffers only.
  - Interface is synchronous : input is consumed entirely and produces 1+ compressed blocks.
  - Caller must ensure there is enough space in `dst` to store compressed data under worst case scenario.
    Worst case evaluation is provided by ZSTD_compressBound().
    ZSTD_compressContinue() doesn't guarantee recover after a failed compression.
  - ZSTD_compressContinue() presumes prior input ***is still accessible and unmodified*** (up to maximum distance size, see WindowLog).
    It remembers all previous contiguous blocks, plus one separated memory segment (which can itself consists of multiple contiguous blocks)
  - ZSTD_compressContinue() detects that prior input has been overwritten when `src` buffer overlaps.
    In which case, it will "discard" the relevant memory section from its history.

  Finish a frame with ZSTD_compressEnd(), which will write the last block(s) and optional checksum.
  It's possible to use srcSize==0, in which case, it will write a final empty block to end the frame.
  Without last block mark, frames are considered unfinished (hence corrupted) by compliant decoders.

  `ZSTD_CCtx` object can be reused (ZSTD_compressBegin()) to compress again.
*/

/*=====   Buffer-less streaming compression functions  =====*/
ZSTD_DEPRECATED("The buffer-less API is deprecated in favor of the normal streaming API. See docs.")
ZSTDLIB_STATIC_API size_t ZSTD_compressBegin(ZSTD_CCtx* cctx, int compressionLevel);
ZSTD_DEPRECATED("The buffer-less API is deprecated in favor of the normal streaming API. See docs.")
ZSTDLIB_STATIC_API size_t ZSTD_compressBegin_usingDict(ZSTD_CCtx* cctx, const void* dict, size_t dictSize, int compressionLevel);
ZSTD_DEPRECATED("The buffer-less API is deprecated in favor of the normal streaming API. See docs.")
ZSTDLIB_STATIC_API size_t ZSTD_compressBegin_usingCDict(ZSTD_CCtx* cctx, const ZSTD_CDict* cdict); /**< note: fails if cdict==NULL */

ZSTD_DEPRECATED("This function will likely be removed in a future release. It is misleading and has very limited utility.")
ZSTDLIB_STATIC_API
size_t ZSTD_copyCCtx(ZSTD_CCtx* cctx, const ZSTD_CCtx* preparedCCtx, unsigned long long pledgedSrcSize); /**<  note: if pledgedSrcSize is not known, use ZSTD_CONTENTSIZE_UNKNOWN */

ZSTD_DEPRECATED("The buffer-less API is deprecated in favor of the normal streaming API. See docs.")
ZSTDLIB_STATIC_API size_t ZSTD_compressContinue(ZSTD_CCtx* cctx, void* dst, size_t dstCapacity, const void* src, size_t srcSize);
ZSTD_DEPRECATED("The buffer-less API is deprecated in favor of the normal streaming API. See docs.")
ZSTDLIB_STATIC_API size_t ZSTD_compressEnd(ZSTD_CCtx* cctx, void* dst, size_t dstCapacity, const void* src, size_t srcSize);

/* The ZSTD_compressBegin_advanced() and ZSTD_compressBegin_usingCDict_advanced() are now DEPRECATED and will generate a compiler warning */
ZSTD_DEPRECATED("use advanced API to access custom parameters")
ZSTDLIB_STATIC_API
size_t ZSTD_compressBegin_advanced(ZSTD_CCtx* cctx, const void* dict, size_t dictSize, ZSTD_parameters params, unsigned long long pledgedSrcSize); /**< pledgedSrcSize : If srcSize is not known at init time, use ZSTD_CONTENTSIZE_UNKNOWN */
ZSTD_DEPRECATED("use advanced API to access custom parameters")
ZSTDLIB_STATIC_API
size_t ZSTD_compressBegin_usingCDict_advanced(ZSTD_CCtx* const cctx, const ZSTD_CDict* const cdict, ZSTD_frameParameters const fParams, unsigned long long const pledgedSrcSize);   /* compression parameters are already set within cdict. pledgedSrcSize must be correct. If srcSize is not known, use macro ZSTD_CONTENTSIZE_UNKNOWN */
/**
  Buffer-less streaming decompression (synchronous mode)

  A ZSTD_DCtx object is required to track streaming operations.
  Use ZSTD_createDCtx() / ZSTD_freeDCtx() to manage it.
  A ZSTD_DCtx object can be reused multiple times.

  First typical operation is to retrieve frame parameters, using ZSTD_getFrameHeader().
  Frame header is extracted from the beginning of compressed frame, so providing only the frame's beginning is enough.
  Data fragment must be large enough to ensure successful decoding.
 `ZSTD_frameHeaderSize_max` bytes is guaranteed to always be large enough.
  result  : 0 : successful decoding, the `ZSTD_frameHeader` structure is correctly filled.
           >0 : `srcSize` is too small, please provide at least result bytes on next attempt.
           errorCode, which can be tested using ZSTD_isError().

  It fills a ZSTD_FrameHeader structure with important information to correctly decode the frame,
  such as the dictionary ID, content size, or maximum back-reference distance (`windowSize`).
  Note that these values could be wrong, either because of data corruption, or because a 3rd party deliberately spoofs false information.
  As a consequence, check that values remain within valid application range.
  For example, do not allocate memory blindly, check that `windowSize` is within expectation.
  Each application can set its own limits, depending on local restrictions.
  For extended interoperability, it is recommended to support `windowSize` of at least 8 MB.

  ZSTD_decompressContinue() needs previous data blocks during decompression, up to `windowSize` bytes.
  ZSTD_decompressContinue() is very sensitive to contiguity,
  if 2 blocks don't follow each other, make sure that either the compressor breaks contiguity at the same place,
  or that previous contiguous segment is large enough to properly handle maximum back-reference distance.
  There are multiple ways to guarantee this condition.

  The most memory efficient way is to use a round buffer of sufficient size.
  Sufficient size is determined by invoking ZSTD_decodingBufferSize_min(),
  which can return an error code if required value is too large for current system (in 32-bits mode).
  In a round buffer methodology, ZSTD_decompressContinue() decompresses each block next to previous one,
  up to the moment there is not enough room left in the buffer to guarantee decoding another full block,
  which maximum size is provided in `ZSTD_frameHeader` structure, field `blockSizeMax`.
  At which point, decoding can resume from the beginning of the buffer.
  Note that already decoded data stored in the buffer should be flushed before being overwritten.

  There are alternatives possible, for example using two or more buffers of size `windowSize` each, though they consume more memory.

  Finally, if you control the compression process, you can also ignore all buffer size rules,
  as long as the encoder and decoder progress in "lock-step",
  aka use exactly the same buffer sizes, break contiguity at the same place, etc.

  Once buffers are setup, start decompression, with ZSTD_decompressBegin().
  If decompression requires a dictionary, use ZSTD_decompressBegin_usingDict() or ZSTD_decompressBegin_usingDDict().

  Then use ZSTD_nextSrcSizeToDecompress() and ZSTD_decompressContinue() alternatively.
  ZSTD_nextSrcSizeToDecompress() tells how many bytes to provide as 'srcSize' to ZSTD_decompressContinue().
  ZSTD_decompressContinue() requires this _exact_ amount of bytes, or it will fail.

  result of ZSTD_decompressContinue() is the number of bytes regenerated within 'dst' (necessarily <= dstCapacity).
  It can be zero : it just means ZSTD_decompressContinue() has decoded some metadata item.
  It can also be an error code, which can be tested with ZSTD_isError().

  A frame is fully decoded when ZSTD_nextSrcSizeToDecompress() returns zero.
  Context can then be reset to start a new decompression.

  Note : it's possible to know if next input to present is a header or a block, using ZSTD_nextInputType().
  This information is not required to properly decode a frame.

  == Special case : skippable frames ==

  Skippable frames allow integration of user-defined data into a flow of concatenated frames.
  Skippable frames will be ignored (skipped) by decompressor.
  The format of skippable frames is as follows :
  a) Skippable frame ID - 4 Bytes, Little endian format, any value from 0x184D2A50 to 0x184D2A5F
  b) Frame Size - 4 Bytes, Little endian format, unsigned 32-bits
  c) Frame Content - any content (User Data) of length equal to Frame Size
  For skippable frames ZSTD_getFrameHeader() returns zfhPtr->frameType==ZSTD_skippableFrame.
  For skippable frames ZSTD_decompressContinue() always returns 0 : it only skips the content.
*/

/*=====   Buffer-less streaming decompression functions  =====*/

ZSTDLIB_STATIC_API size_t ZSTD_decodingBufferSize_min(unsigned long long windowSize, unsigned long long frameContentSize);  /**< when frame content size is not known, pass in frameContentSize == ZSTD_CONTENTSIZE_UNKNOWN */

ZSTDLIB_STATIC_API size_t ZSTD_decompressBegin(ZSTD_DCtx* dctx);
ZSTDLIB_STATIC_API size_t ZSTD_decompressBegin_usingDict(ZSTD_DCtx* dctx, const void* dict, size_t dictSize);
ZSTDLIB_STATIC_API size_t ZSTD_decompressBegin_usingDDict(ZSTD_DCtx* dctx, const ZSTD_DDict* ddict);

ZSTDLIB_STATIC_API size_t ZSTD_nextSrcSizeToDecompress(ZSTD_DCtx* dctx);
ZSTDLIB_STATIC_API size_t ZSTD_decompressContinue(ZSTD_DCtx* dctx, void* dst, size_t dstCapacity, const void* src, size_t srcSize);

/* misc */
ZSTD_DEPRECATED("This function will likely be removed in the next minor release. It is misleading and has very limited utility.")
ZSTDLIB_STATIC_API void   ZSTD_copyDCtx(ZSTD_DCtx* dctx, const ZSTD_DCtx* preparedDCtx);
typedef enum { ZSTDnit_frameHeader, ZSTDnit_blockHeader, ZSTDnit_block, ZSTDnit_lastBlock, ZSTDnit_checksum, ZSTDnit_skippableFrame } ZSTD_nextInputType_e;
ZSTDLIB_STATIC_API ZSTD_nextInputType_e ZSTD_nextInputType(ZSTD_DCtx* dctx);




/* ========================================= */
/**       Block level API (DEPRECATED)       */
/* ========================================= */

/*!

    This API is deprecated in favor of the regular compression API.
    You can get the frame header down to 2 bytes by setting:
      - ZSTD_c_format = ZSTD_f_zstd1_magicless
      - ZSTD_c_contentSizeFlag = 0
      - ZSTD_c_checksumFlag = 0
      - ZSTD_c_dictIDFlag = 0

    This API is not as well tested as our normal API, so we recommend not using it.
    We will be removing it in a future version. If the normal API doesn't provide
    the functionality you need, please open a GitHub issue.

    Block functions produce and decode raw zstd blocks, without frame metadata.
    Frame metadata cost is typically ~12 bytes, which can be non-negligible for very small blocks (< 100 bytes).
    But users will have to take in charge needed metadata to regenerate data, such as compressed and content sizes.

    A few rules to respect :
    - Compressing and decompressing require a context structure
      + Use ZSTD_createCCtx() and ZSTD_createDCtx()
    - It is necessary to init context before starting
      + compression : any ZSTD_compressBegin*() variant, including with dictionary
      + decompression : any ZSTD_decompressBegin*() variant, including with dictionary
    - Block size is limited, it must be <= ZSTD_getBlockSize() <= ZSTD_BLOCKSIZE_MAX == 128 KB
      + If input is larger than a block size, it's necessary to split input data into multiple blocks
      + For inputs larger than a single block, consider using regular ZSTD_compress() instead.
        Frame metadata is not that costly, and quickly becomes negligible as source size grows larger than a block.
    - When a block is considered not compressible enough, ZSTD_compressBlock() result will be 0 (zero) !
      ===> In which case, nothing is produced into `dst` !
      + User __must__ test for such outcome and deal directly with uncompressed data
      + A block cannot be declared incompressible if ZSTD_compressBlock() return value was != 0.
        Doing so would mess up with statistics history, leading to potential data corruption.
      + ZSTD_decompressBlock() _doesn't accept uncompressed data as input_ !!
      + In case of multiple successive blocks, should some of them be uncompressed,
        decoder must be informed of their existence in order to follow proper history.
        Use ZSTD_insertBlock() for such a case.
*/

/*=====   Raw zstd block functions  =====*/
ZSTD_DEPRECATED("The block API is deprecated in favor of the normal compression API. See docs.")
ZSTDLIB_STATIC_API size_t ZSTD_getBlockSize   (const ZSTD_CCtx* cctx);
ZSTD_DEPRECATED("The block API is deprecated in favor of the normal compression API. See docs.")
ZSTDLIB_STATIC_API size_t ZSTD_compressBlock  (ZSTD_CCtx* cctx, void* dst, size_t dstCapacity, const void* src, size_t srcSize);
ZSTD_DEPRECATED("The block API is deprecated in favor of the normal compression API. See docs.")
ZSTDLIB_STATIC_API size_t ZSTD_decompressBlock(ZSTD_DCtx* dctx, void* dst, size_t dstCapacity, const void* src, size_t srcSize);
ZSTD_DEPRECATED("The block API is deprecated in favor of the normal compression API. See docs.")
ZSTDLIB_STATIC_API size_t ZSTD_insertBlock    (ZSTD_DCtx* dctx, const void* blockStart, size_t blockSize);  /**< insert uncompressed block into `dctx` history. Useful for multi-blocks decompression. */

#if defined (__cplusplus)
}
#endif

#endif   /* ZSTD_H_ZSTD_STATIC_LINKING_ONLY */
```

--- file: target/debug/build/zstd-sys-e95a61b68c71fb17/out/include/zstd_errors.h ---
```h
/*
 * Copyright (c) Meta Platforms, Inc. and affiliates.
 * All rights reserved.
 *
 * This source code is licensed under both the BSD-style license (found in the
 * LICENSE file in the root directory of this source tree) and the GPLv2 (found
 * in the COPYING file in the root directory of this source tree).
 * You may select, at your option, one of the above-listed licenses.
 */

#ifndef ZSTD_ERRORS_H_398273423
#define ZSTD_ERRORS_H_398273423

#if defined (__cplusplus)
extern "C" {
#endif

/* =====   ZSTDERRORLIB_API : control library symbols visibility   ===== */
#ifndef ZSTDERRORLIB_VISIBLE
   /* Backwards compatibility with old macro name */
#  ifdef ZSTDERRORLIB_VISIBILITY
#    define ZSTDERRORLIB_VISIBLE ZSTDERRORLIB_VISIBILITY
#  elif defined(__GNUC__) && (__GNUC__ >= 4) && !defined(__MINGW32__)
#    define ZSTDERRORLIB_VISIBLE __attribute__ ((visibility ("default")))
#  else
#    define ZSTDERRORLIB_VISIBLE
#  endif
#endif

#ifndef ZSTDERRORLIB_HIDDEN
#  if defined(__GNUC__) && (__GNUC__ >= 4) && !defined(__MINGW32__)
#    define ZSTDERRORLIB_HIDDEN __attribute__ ((visibility ("hidden")))
#  else
#    define ZSTDERRORLIB_HIDDEN
#  endif
#endif

#if defined(ZSTD_DLL_EXPORT) && (ZSTD_DLL_EXPORT==1)
#  define ZSTDERRORLIB_API __declspec(dllexport) ZSTDERRORLIB_VISIBLE
#elif defined(ZSTD_DLL_IMPORT) && (ZSTD_DLL_IMPORT==1)
#  define ZSTDERRORLIB_API __declspec(dllimport) ZSTDERRORLIB_VISIBLE /* It isn't required but allows to generate better code, saving a function pointer load from the IAT and an indirect jump.*/
#else
#  define ZSTDERRORLIB_API ZSTDERRORLIB_VISIBLE
#endif

/*-*********************************************
 *  Error codes list
 *-*********************************************
 *  Error codes _values_ are pinned down since v1.3.1 only.
 *  Therefore, don't rely on values if you may link to any version < v1.3.1.
 *
 *  Only values < 100 are considered stable.
 *
 *  note 1 : this API shall be used with static linking only.
 *           dynamic linking is not yet officially supported.
 *  note 2 : Prefer relying on the enum than on its value whenever possible
 *           This is the only supported way to use the error list < v1.3.1
 *  note 3 : ZSTD_isError() is always correct, whatever the library version.
 **********************************************/
typedef enum {
  ZSTD_error_no_error = 0,
  ZSTD_error_GENERIC  = 1,
  ZSTD_error_prefix_unknown                = 10,
  ZSTD_error_version_unsupported           = 12,
  ZSTD_error_frameParameter_unsupported    = 14,
  ZSTD_error_frameParameter_windowTooLarge = 16,
  ZSTD_error_corruption_detected = 20,
  ZSTD_error_checksum_wrong      = 22,
  ZSTD_error_literals_headerWrong = 24,
  ZSTD_error_dictionary_corrupted      = 30,
  ZSTD_error_dictionary_wrong          = 32,
  ZSTD_error_dictionaryCreation_failed = 34,
  ZSTD_error_parameter_unsupported   = 40,
  ZSTD_error_parameter_combination_unsupported = 41,
  ZSTD_error_parameter_outOfBound    = 42,
  ZSTD_error_tableLog_tooLarge       = 44,
  ZSTD_error_maxSymbolValue_tooLarge = 46,
  ZSTD_error_maxSymbolValue_tooSmall = 48,
  ZSTD_error_cannotProduce_uncompressedBlock = 49,
  ZSTD_error_stabilityCondition_notRespected = 50,
  ZSTD_error_stage_wrong       = 60,
  ZSTD_error_init_missing      = 62,
  ZSTD_error_memory_allocation = 64,
  ZSTD_error_workSpace_tooSmall= 66,
  ZSTD_error_dstSize_tooSmall = 70,
  ZSTD_error_srcSize_wrong    = 72,
  ZSTD_error_dstBuffer_null   = 74,
  ZSTD_error_noForwardProgress_destFull = 80,
  ZSTD_error_noForwardProgress_inputEmpty = 82,
  /* following error codes are __NOT STABLE__, they can be removed or changed in future versions */
  ZSTD_error_frameIndex_tooLarge = 100,
  ZSTD_error_seekableIO          = 102,
  ZSTD_error_dstBuffer_wrong     = 104,
  ZSTD_error_srcBuffer_wrong     = 105,
  ZSTD_error_sequenceProducer_failed = 106,
  ZSTD_error_externalSequences_invalid = 107,
  ZSTD_error_maxCode = 120  /* never EVER use this value directly, it can change in future versions! Use ZSTD_isError() instead */
} ZSTD_ErrorCode;

ZSTDERRORLIB_API const char* ZSTD_getErrorString(ZSTD_ErrorCode code);   /**< Same as ZSTD_getErrorName, but using a `ZSTD_ErrorCode` enum argument */


#if defined (__cplusplus)
}
#endif

#endif /* ZSTD_ERRORS_H_398273423 */
```

